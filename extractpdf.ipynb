{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting charset-normalizer>=2.0.0 (from pdfminer.six)\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pycparser, charset-normalizer, cffi, cryptography, pdfminer.six\n",
      "Successfully installed cffi-1.17.1 charset-normalizer-3.4.1 cryptography-44.0.2 pdfminer.six-20240706 pycparser-2.22\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "papers_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text('papers/Sensing_Systems_for_Respiration_Monitoring_A_Technical_Systematic_Review.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Review\\nSensing Systems for Respiration Monitoring:\\nA Technical Systematic Review\\n\\nErik Vanegas\\n\\n, Raul Igual *\\n\\nand Inmaculada Plaza\\n\\nEduQTech, Electrical/Electronics Engineering and Communications Department, EUP Teruel,\\nUniversidad de Zaragoza, 44003 Teruel, Spain; 790974@unizar.es (E.V.); inmap@unizar.es (I.P.)\\n* Correspondence: rigual@unizar.es\\n\\nReceived: 9 August 2020; Accepted: 16 September 2020; Published: 22 September 2020\\n\\nAbstract: Respiratory monitoring is essential in sleep studies, sport training, patient monitoring,\\nor health at work, among other applications. This paper presents a comprehensive systematic\\nreview of respiration sensing systems. After several systematic searches in scientiﬁc repositories,\\nthe 198 most relevant papers in this ﬁeld were analyzed in detail. Diﬀerent items were examined:\\nsensing technique and sensor, respiration parameter, sensor location and size, general system setup,\\ncommunication protocol, processing station, energy autonomy and power consumption, sensor\\nvalidation, processing algorithm, performance evaluation, and analysis software. As a result, several\\ntrends and the remaining research challenges of respiration sensors were identiﬁed. Long-term\\nevaluations and usability tests should be performed. Researchers designed custom experiments to\\nvalidate the sensing systems, making it diﬃcult to compare results. Therefore, another challenge is to\\nhave a common validation framework to fairly compare sensor performance. The implementation\\nof energy-saving strategies, the incorporation of energy harvesting techniques, the calculation of\\nvolume parameters of breathing, or the eﬀective integration of respiration sensors into clothing are\\nother remaining research eﬀorts. Addressing these and other challenges outlined in the paper is a\\nrequired step to obtain a feasible, robust, aﬀordable, and unobtrusive respiration sensing system.\\n\\nKeywords:\\nsystematic review; comprehensive review; technical review\\n\\nrespiratory monitoring; respiration sensor; breathing sensor; sensor comparison;\\n\\n1. Introduction\\n\\nContinuous monitoring of physiological variables is essential for health and well-being applications.\\nOne of the most interesting physiological variables is respiration. Breathing information is useful for\\nhealth condition assessment [1]. It can help diagnose respiratory diseases, such as asthma, sleep apnea,\\nand chronic obstructive pulmonary diseases (chronic bronchitis, emphysema, and non-reversible\\nasthma) [2]. It is also used to identify heart failure or heart attack [3] and may serve as an indicator\\nof changes in the nervous system, cardiovascular system, or excretory system, among others [4].\\nOnce a disease has been diagnosed, breathing monitoring may be used during the treatment or for the\\nsurveillance of patients. It also plays a relevant role in the monitoring of newborn babies. Some of\\nthem are born under delicate conditions, and this monitoring may avoid any casualty due to infant\\nsleep apnea [5]. Older people suﬀering from age-related conditions and diseases, like Parkinson or\\ndementia [6], and sedentary patients could also beneﬁt from unobtrusive health surveillance [7].\\n\\nBreathing monitoring is also applicable to the ﬁeld of work health and safety at work [8].\\nFirstly, having breathing information from workers can be helpful in assessing work-related risks to\\nplan preventive actions to be undertaken before a work disease appears. The analysis of respiratory\\ninformation may lead to the design of safer work places. Secondly, respiratory monitoring may help\\n\\nSensors 2020, 20, 5446; doi:10.3390/s20185446\\n\\nwww.mdpi.com/journal/sensors\\n\\nsensors(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)\\x0cSensors 2020, 20, 5446\\n\\n2 of 84\\n\\nprevent job accidents and is especially useful for jobs, such as plane piloting, industrial machine drivers,\\ncar, bus, or train drivers, who can beneﬁt from having breathing information on real time [9].\\n\\nRespiratory monitoring has also been applied in the analysis of human emotions [10,11].\\nRespiratory rate (RR) can be associated with emotions, such as fear, stress, anger, happiness, sadness,\\nor surprise [12]. This can be used to prevent mental diseases and in the treatment of patients with\\nmental disorders. Human emotions are also useful in psychological studies, for example, to assess or\\nunderstand consumer and social trends [13]. They have also been applied in assessing the level of\\nsafety of drivers [14] by monitoring their emotional state. They were also used in the computer science\\nﬁeld to improve software engineering processes, overcoming the limitations of usability questionnaires\\nand helping to provide more personalized web experiences. For example, they can be used to obtain\\ninformation about consumer behavior on websites and their interactions. Respiratory monitoring may\\ncontribute to real time recognition of emotions, which is an area of active research in the video game\\nindustry to generate dynamic gaming experiences [15]. There are also applications in the education\\nﬁeld and e-Learning. Some emotional states have positive eﬀects on learning processes, while others\\nhinder them. It is possible to personalize the learning process by providing the most eﬀective resources\\nfor each emotional state [16].\\n\\nRespiratory information is also applied in the sports ﬁeld to monitor the performance of athletes\\nduring their activities [17,18]. This information can be used to optimize their training or to prevent\\nhealth problems. Similarly, it is used in Magnetic Resonance Imaging (MRI) machines to guarantee the\\ngood conditions of patients throughout the process [19] and to reduce their level of stress [20].\\n\\nAnother less common application of respiratory sensing is the evaluation of the health of combat\\nsoldiers [21,22]. This has a double utility: it provides information on the integrity of soldiers and\\nallows collecting ﬁeld information. Breathing monitoring has also been used for emergency situations,\\nsuch as rescue of or searching for people, in which breathing information is required in a non-contact\\nway for faster and more eﬀective intervention [23].\\n\\nFigure 1 shows an overview of the applications of respiration monitoring.\\n\\nFigure 1. Most common application ﬁelds of sensing systems to monitor breathing.\\n\\nTo perform respiratory monitoring, several approaches were proposed in the literature [24].\\nMonitoring systems use sensors to measure breathing parameters. There are large diﬀerences\\namong approaches depending on sensing techniques and sensors, breathing parameters, sensor\\nlocations, system setups, communication protocols, processing stations, energy autonomy and power\\n\\nSensors 2020, 20, x FOR PEER REVIEW 2 of 89  Breathing monitoring is also applicable to the field of work health and safety at work [8]. Firstly, having breathing information from workers can be helpful in assessing work-related risks to plan preventive actions to be undertaken before a work disease appears. The analysis of respiratory information may lead to the design of safer work places. Secondly, respiratory monitoring may help prevent job accidents and is especially useful for jobs, such as plane piloting, industrial machine drivers, car, bus, or train drivers, who can benefit from having breathing information on real time [9].  Respiratory monitoring has also been applied in the analysis of human emotions [10,11]. Respiratory rate (RR) can be associated with emotions, such as fear, stress, anger, happiness, sadness, or surprise [12]. This can be used to prevent mental diseases and in the treatment of patients with mental disorders. Human emotions are also useful in psychological studies, for example, to assess or understand consumer and social trends [13]. They have also been applied in assessing the level of safety of drivers [14] by monitoring their emotional state. They were also used in the computer science field to improve software engineering processes, overcoming the limitations of usability questionnaires and helping to provide more personalized web experiences. For example, they can be used to obtain information about consumer behavior on websites and their interactions. Respiratory monitoring may contribute to real time recognition of emotions, which is an area of active research in the video game industry to generate dynamic gaming experiences [15]. There are also applications in the education field and e-Learning. Some emotional states have positive effects on learning processes, while others hinder them. It is possible to personalize the learning process by providing the most effective resources for each emotional state [16]. Respiratory information is also applied in the sports field to monitor the performance of athletes during their activities [17,18]. This information can be used to optimize their training or to prevent health problems. Similarly, it is used in Magnetic Resonance Imaging (MRI) machines to guarantee the good conditions of patients throughout the process [19] and to reduce their level of stress [20]. Another less common application of respiratory sensing is the evaluation of the health of combat soldiers [21,22]. This has a double utility: it provides information on the integrity of soldiers and allows collecting field information. Breathing monitoring has also been used for emergency situations, such as rescue of or searching for people, in which breathing information is required in a non-contact way for faster and more effective intervention [23].  Figure 1 shows an overview of the applications of respiration monitoring.  Figure 1. Most common application fields of sensing systems to monitor breathing. To perform respiratory monitoring, several approaches were proposed in the literature [24]. Monitoring systems use sensors to measure breathing parameters. There are large differences among \\x0cSensors 2020, 20, 5446\\n\\n3 of 84\\n\\nconsumption, ﬁeld of application, algorithms used to process sensor data, software of analysis,\\nand performance evaluation, among others. Given that the number of studies and approaches has\\nincreased dramatically in recent years, it may be useful to review existing systems, discussing trends,\\nchallenges and issues in this ﬁeld.\\n\\nThere are several existing reviews in the ﬁeld of wearable sensors. For example, the survey\\nof Mukhopadhyay et al. [25] focused on wearable sensors to monitor human activity continuously.\\nThey described the typical architecture of a human activity monitoring system based on sensors,\\nmicrocontrollers, communication modules, and remote processing. The paper outlined transmission\\ntechnologies and energy harvesting issues and predicted an increase in interest in wearable devices in\\nthe near future. Similarly, the work of Nag et al. [26] reviewed ﬂexible wearable sensors to monitor\\nphysiological parameters. The study focused on the materials used to manufacture sensors based on\\ndiﬀerent factors, such as application, material availability, cost, or manufacturing techniques. Diﬀerent\\noperating principles were identiﬁed: electromechanical, pressure and strain, chemical, and magnetic\\nﬁeld-based, among others. The transmission technologies used in the sensing systems and their\\npossible applications were also reviewed in detail. Finally, the paper identiﬁed several challenges\\nand future opportunities. The most relevant was the expected reduction in the cost of manufacturing\\nﬂexible sensing systems. However, this paper focused exclusively on ﬂexible sensing systems, and no\\nreview of other technologies was performed. In addition, it did not speciﬁcally address respiration\\nsensing, but instead considered sensors for any type of physiological parameter. Similarly, the reviews\\nof Chung et al. [27] and Bandodkar et al. [28] also focused on wearable ﬂexible sensors, but speciﬁcally\\ntargeted at sweat analysis. Meanwhile, the review of Lopez-Nava et al. [29] addressed inertial sensors\\nfor human motion analysis. Diﬀerent aspects were studied: sensor type, number of sensing devices\\nand their combination, processing algorithms, measured motion units, systems used for comparison,\\nand number of test subjects and their age range, among others. The review identiﬁed a trend toward\\nlow-cost wearable systems.\\n\\nSeshadri et al. [30] presented a work focused on wearable sensors to monitor athletes’ internal\\nand external workload. The paper addressed wearable devices for athletes comprehensively, including\\nphysical performance, physiological and mental status, and biochemical composition. RR was\\nconsidered as one more physiological parameter. In fact, sensors to measure position, motion, impact,\\nbiomechanical forces, heart rate, muscle oxygen saturation, and sleep quality were also considered.\\nThe paper concluded that wearable sensors had the potential to minimize the onset of injuries and\\nevaluate athlete performance in real time.\\n\\nAroganam et al. [31] reviewed wearable sensors for sport applications excluding professional\\nsports. Communication technologies, battery life, and applications were widely discussed. The paper\\nconcluded that inertial and Global Positioning System (GPS) sensors were predominant in sport\\nwearables. A gap was detected in user experience studies of existing devices. Meanwhile,\\nAl-Eidan et al. [32] presented a systematic review on wrist-worn wearable sensors. They focused\\non user interface, interaction, and use studies of the sensing systems. Processing techniques were\\nalso analyzed showing high variability among them and including machine learning techniques and\\nthreshold-based methods. Similarly, validation experiments lasted from 2 s to 14 weeks and most of the\\nexperiments were performed under laboratory conditions. Few studies presented real-world setups\\nwith target users. Other aspects analyzed were sampling frequencies and features extracted. Challenges\\nof wrist-based systems were identiﬁed in relation to weight, battery life, lack of standardization, safety,\\nuser acceptance, or design.\\n\\nMansoor et al. [33] performed a review on wearable sensors for older adults. The review focused\\non sensor target population, sensor type, application area, data processing, and usability. Fourteen\\npapers were analyzed. They identiﬁed barriers, such as inaccurate sensors, battery issues, restriction\\nof movements, lack of interoperability, and low usability. The paper concluded that these technical\\nchallenges should be resolved for successful use of wearable devices.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n4 of 84\\n\\nHeikenfeld et al. [34] conducted a review on wearable sensors that interfaced with the epidermis.\\nWearable sensors were classiﬁed into four broad groups: mechanical, electrical, optical, and chemical.\\nSeveral subgroups were identiﬁed within each category. Body-to-signal transduction, actual devices\\nand demonstrations, and unmet challenges were discussed. The paper concluded that, in general,\\nsensing categories had remained isolated from each other in commercial products, and strategies were\\nstill needed to easily attach and detach disposable systems.\\n\\nWitte and Zarnekow [35] reviewed wearable sensors for medical applications. Ninety-seven\\npapers were analyzed in relation to disease treatments, ﬁelds of application, vital parameters measured,\\nand target patients. The paper identiﬁed a trend toward heart and mental diseases monitoring. Sensors\\nwere used for monitoring or diagnosis, collecting physical activity data, or heart rate data. The work\\nof Pantelopoulos et al. [36] surveyed wearable biosensor systems for health monitoring. The design\\nof multiparameter physiological sensing systems was discussed in detail. Meanwhile, the study of\\nLiang et al. [37] addressed wearable mobile medical monitoring systems. Emphasis was placed on\\ndevices based on wireless sensing networks, and special attention was given to textile technologies.\\nFinally, the paper of Charlton et al. [38] reviewed the estimation of the RR using two diﬀerent signals:\\nthe electrocardiogram (ECG) and the pulse oximetry (photoplethysmogram, PPG).\\n\\nA recent review on contact-based sensors to measure RR was published by Massaroni et al. [24].\\nThis paper identiﬁed seven contact-based techniques: measuring of respiratory airﬂow, respiratory\\nsounds, air temperature, air humidity, air components, chest wall movements, and modulation cardiac\\nactivity. Several possible sensors could be used for each technique. Some of the sensors identiﬁed in the\\nreview were ﬂowmeters, anemometers, ﬁber optic sensors, microphones, thermistors, thermocouples,\\npyroelectric sensors, capacitive sensors, resistive sensors, nanocrystal and nanoparticles sensors,\\ninfrared, inductive, transthoracic, inertial, ECG sensors, and PPG sensors, among others. The paper\\npresented a detailed description of each sensing technology, focusing on metrological properties and\\noperating principles. Equations were provided for most sensors. In addition, the study compared the\\noptimal techniques for clinical settings (respiratory airﬂow, air temperature, air components, chest\\nwall movements, and modulation of cardiac activities), occupational settings (respiratory airﬂow,\\nair components, and chest wall movements) and sport and exercise (respiratory airﬂow and chest wall\\nmovements). These techniques were considered optimal for controlled environments.\\n\\nA previous work on respiration sensors was published by AL-Khalidi et al. [39]. This paper\\ncovered both non-contact and contact-based methods and provided a general description of several\\nsensing techniques. On the one hand, contact-based technologies included ﬁve sensing methods:\\nacoustic, airﬂow detection, chest and abdominal movement measuring, transcutaneous CO2 monitoring,\\noximetry prove (SpO2), and electrocardiogram derived methods. On the other hand, non-contact\\ntechnologies included radar-based detection, optical methods, thermal sensors, and thermal imaging.\\nThe paper concluded that non-contact RR monitoring had advantages over contact methods since they\\ncaused the least discomfort to patients.\\n\\nThree other related surveys were published, to the best of our knowledge. The review by\\nvan Loon et al. [40] studied respiratory monitoring from a hospital perspective without analyzing\\ntechnical items. The review of Rajala and Lekkala [41] focused exclusively in the ﬁlm-type sensor\\nmaterials polyvinylideneﬂuoride (PVDF) and electro-mechanical ﬁlm (EMFi), while the recent review\\nof Massaroni et al. [42] analyzed ﬁber Bragg grating sensors for cardiorespiratory monitoring.\\n\\nIn this paper, we present a survey on sensing systems for respiratory monitoring. This paper has\\n\\nseveral novelties with respect to the existing reviews in the state of the art:\\n\\n•\\n\\nThis review is not exclusively focused on sensor metrological properties or operating principles.\\nInstead, this paper also reviews all the diﬀerent aspects involved in the design and development\\nof a respiration sensing system: communication protocols, processing stations, energy autonomy\\nand power consumption, general system setups, sensor location and size, breathing parameters,\\nvalidation methods, details of the test experiments, processing algorithms, software used for\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n5 of 84\\n\\nanalysis, and performance evaluation. To the best of our knowledge, this is the ﬁrst review paper\\nthat analyzes all these aspects in breathing sensors.\\nThis paper does not focus exclusively on RR. In addition, sensors that measure other breathing\\nparameters are also surveyed.\\nUnlike previous reviews, this survey is systematic. Studies on respiration sensors were obtained\\nusing objective selection criteria. They were then subjected to detailed analysis.\\n\\n•\\n\\n•\\n\\nTherefore, this paper provides a comprehensive overview of all aspects to consider in the design\\nof respiratory sensing systems. It aims to help engineers and researchers to identify the diﬀerent\\noptions at each design stage.\\n\\nThe structure of this review is as follows: Section 2 presents the study design, selection criteria,\\nand organization of the review results; Section 3 describes the results of the literature search, which are\\nclassiﬁed into diﬀerent groups, the items of analysis and the results of the analysis of those items\\nfor each study; Section 4 discusses the trends in respiratory monitoring, the issues in the design of\\nrespiration sensors, and the current challenges in this ﬁeld, highlighting the research opportunities;\\nand, ﬁnally, Section 5 draws some conclusions.\\n\\n2. Materials and Methods\\n\\n2.1. Search and Selection Procedure\\n\\nA systematic search of the literature was carried out to identify relevant papers in the ﬁeld of\\nsensors for respiratory monitoring. The IEEE (Institute of Electrical and Electronics Engineers) Explore\\nand Google Scholar were used for this review. IEEE Explore is a reference in engineering studies and\\nGoogle Scholar provides a broader perspective to complement the results. Four sets of keywords were\\nselected to perform the searches. To identify these keywords, a preliminary study was conducted\\nthat examined key studies in this ﬁeld. As a result, the ﬁve search terms selected were the following:\\n(1) “breathing” plus “monitoring”, (2) “respiratory” plus “monitoring”, (3) “breathing” plus “sensor”,\\n(4) “respiratory” plus “sensor”, and (5) “respiration” plus “sensor”.\\n\\nTo analyze the most recent research, articles from 2010 to 2019 were considered. Searches were\\nconducted in February 2019 and repeated in March 2020. The sort by relevance of IEEE Xplore and\\nGoogle Scholar was used to obtain the most relevant articles ﬁrst. According to the oﬃcial IEEE Xplore\\nwebsite, the search results are “sorted by how well they match the search query as determined by IEEE\\nXplore” [43]. Regarding the relevance criteria of Google Scholar, its oﬃcial website points out that the\\nrank is made by “weighting the full text of each document, where it was published, who it was written\\nby, as well as how often and how recently it has been cited in other scholarly literature” [44]. Journals,\\nmagazines, and conferences were considered in the searches. As a result of the ﬁve searches in the two\\nrepositories, more than a million results were obtained. For each search and repository, the 100 most\\nrelevant papers were selected, resulting in 1000 studies. This number is high enough to provide a\\ncomprehensive review of the topic. The title and abstract of all these studies were examined and\\nthose not related to the subject of the review were discarded, resulting in 236 papers. Then, a second\\nselection was made based on the content of the papers, discarding those that did not deal with sensors\\nfor respiratory monitoring. Finally, 198 papers were obtained. All of them were subjected to a detailed\\nanalysis that is presented in Section 3. Figure 2 (top) shows an overview of the selection procedure.\\nFigure 2 (bottom) presents the PRISMA diagram that details the item selection process [45].\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n6 of 84\\n\\nFigure 2. Literature search results and selection procedure (top). PRISMA diagram (bottom).\\n\\nSensors 2020, 20, x FOR PEER REVIEW 6 of 89   Figure 2. Literature search results and selection procedure (top). PRISMA diagram (bottom).   \\x0cSensors 2020, 20, 5446\\n\\n7 of 84\\n\\n2.2. Organization of the Results\\n\\nThe search results were analyzed in detail.\\n\\nFor that, papers were divided into two\\ncategories: wearable systems and environmental systems. This is a typical classiﬁcation found\\nin several sensor-related studies [24,46]. Wearable methods require individuals to carry the sensors,\\nwhile environmental methods place them around subjects. The wearable category includes 113 studies,\\nwhile the environmental category comprises the remaining 85 studies.\\n\\nDiﬀerent aspects of respiratory sensing systems were analyzed for each paper. The items\\nselected can be divided into four categories (Figure 3): (1) sensor and breathing parameter, (2) data\\ntransmission and power consumption, (3) experiments performed for sensor validation, and (4) sensor\\nmeasurement processing.\\n\\nThe category “sensor and breathing parameter” includes the following items of analysis:\\n\\n(1.1) sensing technique and sensor, (1.2) breathing parameter, and (1.3) sensor location and size.\\n\\nFour items are included in the category “data transmission and power consumption”: (2.1) general\\nsystem setup, (2.2) communication protocol, (2.3) processing station, and (2.4) energy autonomy and\\npower consumption.\\n\\nThe category “sensor validation” comprises several items related to the design of experiments to\\n\\nvalidate the sensors (they are listed in Section 3.3).\\n\\nThree items are included in the “sensor measurement processing” category: (4.1) performance\\n\\nevaluation, (4.2) processing algorithm, and (4.3) software used for the analysis.\\n\\nFor each category, we ﬁrst describe in detail the diﬀerent items of analysis, except item (1.1)\\n“sensing technique and sensor”, which was described extensively in the review of Massaroni et al. [24].\\nThen, we provide the value of those items for each study selected for both categories (wearable and\\nenvironmental). Results were subjected to critical analysis and discussion.\\n\\nFigure 3. Analysis structure.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 7 of 89  2.2. Organization of the Results The search results were analyzed in detail. For that, papers were divided into two categories: wearable systems and environmental systems. This is a typical classification found in several sensor-related studies [24,46]. Wearable methods require individuals to carry the sensors, while environmental methods place them around subjects. The wearable category includes 113 studies, while the environmental category comprises the remaining 85 studies. Different aspects of respiratory sensing systems were analyzed for each paper. The items selected can be divided into four categories (Figure 3): (1) sensor and breathing parameter, (2) data transmission and power consumption, (3) experiments performed for sensor validation, and (4) sensor measurement processing. The category “sensor and breathing parameter” includes the following items of analysis: (1.1) sensing technique and sensor, (1.2) breathing parameter, and (1.3) sensor location and size.  Four items are included in the category “data transmission and power consumption”: (2.1) general system setup, (2.2) communication protocol, (2.3) processing station, and (2.4) energy autonomy and power consumption. The category “sensor validation” comprises several items related to the design of experiments to validate the sensors (they are listed in Section 3.3).  Three items are included in the “sensor measurement processing” category: (4.1) performance evaluation, (4.2) processing algorithm, and (4.3) software used for the analysis. For each category, we first describe in detail the different items of analysis, except item (1.1) “sensing technique and sensor”, which was described extensively in the review of Massaroni et al. [24]. Then, we provide the value of those items for each study selected for both categories (wearable and environmental). Results were subjected to critical analysis and discussion.  Figure 3. Analysis structure. \\x0cSensors 2020, 20, 5446\\n\\n3. Results\\n\\n8 of 84\\n\\nThis section has been structured around the four categories of analysis introduced in Section 2.2.\\nFirst, the items of analysis and their possible values are described in detail for each category\\n(Sections 3.1.1, 3.2.1, 3.3.1 and 3.4.1). Then, the values of those items provided in the studies\\nselected are analyzed and discussed (Sections 3.1.2, 3.2.2, 3.3.2 and 3.4.2).\\n\\n3.1. Sensor and Breathing Parameter\\n\\n3.1.1. Items of Analysis\\n\\nThis category includes the following items of analysis: sensing technique and sensor, breathing\\n\\nparameter, and sensor location and size.\\n\\nSensing Technique and Sensor\\n\\nAccording to the review of Massaroni et al. [24], two diﬀerent dimensions can be observed in the\\noperating principle: the technique selected to obtain respiration information and the sensor used to\\ncapture that information. For each possible technique, there are several sensors available.\\n\\nTo classify the papers analyzed in this review, the classiﬁcation established in the work of\\nIt was expanded to also cover environmental breathing sensors.\\n\\nMassaroni et al. [24] was used.\\nThe techniques and sensors identiﬁed were:\\n\\n•\\n\\n•\\n•\\n\\n•\\n\\n•\\n\\n•\\n\\nTechnique based on measurements of respiratory airﬂow. Possible sensors are diﬀerential\\nﬂowmeters, turbine ﬂowmeters, hot wire anemometers, photoelectric sensors, and ﬁber\\noptic sensors.\\nTechnique based on measurements of respiratory sounds. Possible sensors are microphones.\\nTechnique based on measurements of air temperature. Possible sensors are thermistors,\\nthermocouples, pyroelectric sensors, ﬁber optic sensors, infrared sensors, and cameras.\\nTechnique based on measurements of air humidity. Possible sensors are capacitive sensors, resistive\\nsensors, nanocrystal and nanoparticles sensors, impedance sensors, and ﬁber optic sensors.\\nTechnique based on measurements of chest wall movements. Three diﬀerent types of measurement\\nwere identiﬁed in this technique:\\n\\n(cid:35)\\n\\n(cid:35)\\n(cid:35)\\n\\nStrain measurements: Possible sensors are resistive sensors, capacitive sensors,\\ninductive sensor, ﬁber optic sensors, piezoelectric sensors, pyroelectric sensors,\\nand triboelectric nanogenerator.\\nImpedance measurements: Possible sensors are transthoracic impedance sensors.\\nMovement measurements: Possible sensors are accelerometers, gyroscopes and\\nmagnetometers, frequency shift sensors, DC (direct current) generators, ultrasonic\\nproximity sensors, cameras, optical sensors, inductive sensors, and Kinect sensors.\\n\\nTechnique based on measurements of modulation cardiac activity. Possible sensors are ECG\\nsensors (for biopotential measurements), PPG sensors (for light intensity measurements), radar\\nsensors, and Wi-Fi transmitters and receivers.\\n\\nEquations and details of the diﬀerent sensors are included in the reference review paper [24].\\n\\nBreathing Parameters\\n\\nBreathing parameters are the metrics provided as output of the sensing process. Possible breathing\\n\\nparameters are the following:\\n\\n•\\n\\nRespiratory rate (RR): Number of breaths (inspiration and expiration cycles) performed by a subject\\nin one minute (Figure 4). It is measured in breaths/min (bpm). Other metrics derived from the RR\\ncan also be calculated [10]:\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n9 of 84\\n\\nBreathing period: Time duration of a breathing cycle(s).\\nInspiratory time: Part of the breathing period that corresponds to inspiration (s). According\\nto Figure 4A, it can be obtained as tb\\nExpiratory time: Part of the breathing period that corresponds to expiration (s). According\\nto Figure 4A, it can be obtained as td\\n\\n− ta\\n\\n− tc\\n\\n(cid:35)\\n(cid:35)\\n\\n(cid:35)\\n\\n•\\n\\nVolume parameters: Metrics that provide volume information obtained from inhaled or exhaled\\nair during breathing. Volume metrics comprise a set of sub-metrics related to the volume of\\nair available in the lungs [47]. Some of the metrics that could be found in the breathing sensor\\nstudies were:\\n\\n− Vn| = |Vn − Vn−1\\n\\nTidal volume (TV): It is the volume of air inhaled or exhaled during normal respiration\\n(without forcing breathing). It is measured in liters (L). From the volume versus time\\nsignal represented in Figure 4B, the TV for a given breathing period could be calculated\\n|, where Vn is the air volume associated with the n\\nas TV = |Vn−1\\nrespiration peak or valley.\\nMinute volume (MV): It is the volume of air inhaled or exhaled by a subject in one minute\\nduring normal breathing. It is measured in L/min. It can be roughly obtained from the\\nTV and the RR as MV = TV·RR. From the representation of Figure 4B, the MV can be\\n− Vi|; ∀i ∈ Z : i ∈ [2, n] : 2|i , where n is the number of peaks\\n\\ncalculated as MV =\\n\\n|Vi−1\\n\\nn(cid:80)\\ni=2\\n\\n− Va)/(tb\\n\\n(or valleys) in the air volume curve that can be found in one minute of breathing.\\nPeak inspiration ﬂow (PIF): According to Warner and Patel [47], it is the maximum ﬂow at\\nwhich a given tidal volume breath can be delivered. It is measured in L/min. From the\\n− ta), where (Va, ta) is\\nrepresentation of Figure 4B, it can be obtained as PIF = (Vb\\nthe point associated with the valley in the time-volume curve before inspiration, and (Vb, tb)\\nis the point related to the peak of inspiration at which the given tidal volume is delivered.\\nExhalation ﬂow rate (EFR): Volume of air exhaled per time unit. It is expressed in L/s\\nand can be calculated as EFR = (Volume o f exhaled air)/(Exhalation time) [48]. From the\\n− t3), where (V3, t3)\\nrepresentation of Figure 4B, it can be obtained as EFR = (V3\\nis the point corresponding to a peak of the time-volume curve, and (V4, t4) is the next\\nvalley of the curve.\\nThere are other air volume metrics, such as peak expiratory ﬂow (maximum ﬂow at\\nwhich a given tidal volume can be exhaled; it can be obtained as (Vc − Vd)/(td\\n− tc) from\\nFigure 4B), vital capacity (volume of air expired after deep inhalation; it can be obtained as\\nVe − V f from Figure 4B), or forced vital capacity (same as vital capacity but maximizing\\nthe expiratory eﬀort; it can be obtained as Vg − Vh from Figure 4B), among others [49].\\nThey have barely been used in breathing sensor studies.\\nCompartmental volume: Instead of considering air volume, this metric measures the change\\nin volume of breathing-related body parts, like chest, thorax, or abdomen [49].\\n\\n− V4)/(t4\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n•\\n\\nRespiration patterns: There are studies in which the purpose is to identify patterns in the signals\\nobtained from the recording of respiration instead of providing a particular breathing parameter.\\nCommon patterns identiﬁed are abnormal breathing [50–52], apnea episodes [50,51,53,54],\\nKussmaul’s respiration, Cheyne-Stokes breathing, Biot’s respiration, Cheyne-Stokes variant,\\nor dysrhythmic breathing, among others [53]. There are also studies that identiﬁed the type\\nof breathing (heavy or shallow breathing, mouth breathing, abdominal breathing, or chest\\nbreathing) [53].\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n10 of 84\\n\\nSensor Location and Size\\n\\nSensor location and size play a relevant role in system usability and can determine the acceptability\\nof the technology by its potential users [55,56]. Figure 5 shows possible locations for wearable systems.\\nThe locations are chest (diaphragm or pectoral muscle), abdomen, waist, arm, forearm, ﬁnger, mouth\\n(including mouth mask), nose (nasal bridge, above lip or nostril), wrist, neck (suprasternal notch area),\\nor back. Regarding environmental systems, sensors can be located at a ﬁxed distance from the subject,\\ncan be integrated into an object commonly used by the subject (pillow, mat, mattress, etc.), or can be\\ndistributed on nodes, among others. The location of a sensor largely depends on its operating principle\\nand the speciﬁc application.\\n\\nFigure 4. Graphical explanation of the diﬀerent breathing parameters. Signal (A) could come directly\\nfrom the ADC (analog-to-digital converter) of the sensing system, although it is also possible that it\\nrepresents physical respiration magnitudes. This ﬁgure shows a general representation that is not\\ncontextualized to a speciﬁc sensing system. The same goes for signal (B).\\n\\nSensors 2020, 20, x FOR PEER REVIEW 10 of 89  distance from the subject, can be integrated into an object commonly used by the subject (pillow, mat, mattress, etc.), or can be distributed on nodes, among others. The location of a sensor largely depends on its operating principle and the specific application.  Figure 4. Graphical explanation of the different breathing parameters. Signal (A) could come directly from the ADC (analog-to-digital converter) of the sensing system, although it is also possible that it represents physical respiration magnitudes. This figure shows a general representation that is not contextualized to a specific sensing system. The same goes for signal (B). \\x0cSensors 2020, 20, 5446\\n\\n11 of 84\\n\\nFigure 5. Most common sensor locations for respiration monitoring. The sensors shown are for\\ncontextualization purposes.\\n\\n3.1.2. Results of the Analysis\\n\\nTable 1 presents the results of the analysis of the items technique, sensor, parameter, and location\\nand size for the studies in the wearable category, while Table 2 shows the results for the\\nenvironmental papers.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 11 of 89   Figure 5. Most common sensor locations for respiration monitoring. The sensors shown are for contextualization purposes. 3.1.2. Results of the Analysis Table 1 presents the results of the analysis of the items technique, sensor, parameter, and location and size for the studies in the wearable category, while Table 2 shows the results for the environmental papers.   \\x0cSensors 2020, 20, 5446\\n\\n12 of 84\\n\\nTable 1. Analysis of techniques, sensors, breathing parameters, and sensor locations and sizes for\\nstudies of the wearable category.\\n\\nStudy 1\\n\\nTechnique\\n\\nSensor\\n\\nMeasured\\nParameter\\n\\nLocation\\n\\nSize\\n\\nAitkulov 2019 [57,58]\\n\\nChest wall movements\\n\\nFiber optic\\n\\nBalasubramaniyam\\n2019 [59]\\n\\nChest wall movements\\n\\nResistive\\n\\nBricout 2019 [60]\\n\\nChest wall movements\\n\\nAccelerometer\\n\\nChu 2019 [61]\\n\\nChest wall movements\\n\\nResistive\\n\\nElfaramawy 2019 [62]\\n\\nChest wall/abdomen\\nmovements\\n\\nAccelerometer\\nGyroscope\\nMagnetometer\\n\\nFajkus 2019 [63]\\n\\nRespiratory air ﬂow\\n\\nFiber optic\\n\\nHurtado 2019 [64]\\n\\nAir temperature\\n\\nPyroelectric\\n\\nJayarathna 2019 [65]\\n\\nChest wall movements\\n\\nResistive\\n\\nKano 2019 [66]\\n\\nAir humidity\\n\\nKaracocuk 2019 [67]\\n\\nChest wall movements\\n\\nMassaroni 2019 [68]\\n\\nRespiratory air ﬂow\\n(pressure)\\n\\nNanocrystal\\nand\\nnanoparticles\\n\\nAccelerometer\\nGyroscope\\nDiﬀerential\\npressure\\n\\nMassaroni 2019 [69]\\n\\nChest wall movements\\n\\nResistive\\n\\nNguyen 2019 [70]\\n\\nPresti 2019 [71]\\n\\nPresti 2019 [72]\\n\\nRespiratory air ﬂow\\n(vibration)\\n\\nRespiratory air ﬂow\\nChest/abdomen\\nmovements\\n\\nDiﬀerential\\npressure sensor\\n\\nFiber optic\\n\\nFiber optic\\n\\nPuranik 2019 [73]\\n\\nChest wall movements\\n\\nGyroscope\\n\\nSoomro 2019 [74]\\n\\nAir humidity\\n\\nImpedance\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\nTV\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nMV\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nMonitoring\\nof breathing\\n\\nMonitoring\\nof breathing\\n\\n-\\n\\n-\\n\\n-\\n\\n26.67 × 65.53 mm\\n\\n30 × 16 × 20 mm\\n\\n-\\n\\n36 mm diameter\\n(PCB)\\n\\n-\\n\\nChest\\n\\nAbdomen (shirt)\\n\\nChest\\nAbdomen\\n\\nChest\\n\\nChest\\nAbdomen\\n\\nNose (nasal oxygen\\ncannula)\\n\\nNose (below)\\n\\nChest (shirt)\\n\\nMouth mask\\n\\nChest (front and\\nback)\\n\\nNose (nostril)\\n\\nChest and\\nabdomen\\n(shirt, front and\\nback)\\n\\nNose (nasal bridge)\\n\\nCervical spine\\n\\n90 × 24 × 1 mm\\n\\nChest\\n\\nChest\\nAbdomen\\n\\nNose (below)\\n\\nXiao 2019 [75]\\n\\nAir humidity\\n\\nResistive\\n\\nMonitoring\\nof breathing\\n\\nMouth mask\\n(2–3 cm from nose)\\n\\nYuasa 2019 [76]\\n\\nRespiratory sounds\\nChest wall movements\\n\\nMicrophoneOptical\\n\\nRR\\n\\nChest\\n(adhesive gel)\\n\\nZhang 2019 [77]\\n\\nChest wall movements\\n\\nTriboelectric\\nnanogenerator\\n\\nRR\\n\\nAbdomen\\n\\nDan 2018 [78]\\n\\nChest wall movements\\n\\nAccelerometer\\n\\nRR\\nRespiratory\\nphase\\n\\nNeck (Suprasternal\\nnotch area)\\n\\nKoyama 2018 [79]\\n\\nChest wall movements\\n\\nMalik 2018 [80]\\n\\nAir humidity\\n\\nFiber Optic\\nsensor\\n\\nRR\\n\\nCapacitive\\nsensor\\n\\nMonitoring\\nof breathing\\n\\nAbdomen\\n(Cardigan,\\ngarment)\\n\\nMouth mask\\n\\nMartin 2018 [81]\\n\\nRespiratory sounds\\n\\nMicrophone\\n\\nRR\\n\\nHead (inside ear)\\n\\nPang 2018 [82]\\n\\nAir humidity\\n\\nNanocrystal\\nand\\nNanoparticles\\nsensor\\n\\nMonitoring\\nof breathing\\n\\nMouth mask\\n\\n1 Note: The analysis for studies published before 2018 [2,3,17,21,49,83–162] is included in Appendix A (Table A1).\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n13 of 84\\n\\nTable 2. Analysis of sensing techniques, sensors, breathing parameters, and sensor location and size\\nfor studies of the environmental category.\\n\\nStudy 1\\n\\nTechnique\\n\\nSensor\\n\\nMeasured\\nParameter\\n\\nLocation\\n\\nSize\\n\\nAl-Wahedi 2019 [163]\\n\\nChen 2019 [164]\\n\\nModulation cardiac\\nactivity\\n\\nModulation cardiac\\nactivity\\n\\nRadar\\n\\nRadar\\n\\nGunaratne 2019 [165]\\n\\nChest wall movements\\n\\nPiezoelectric\\n\\nGuo 2019 [166]\\n\\nChest wall movements\\n\\nCapacitive\\n\\nIsono 2019 [167]\\n\\nChest wall movements\\n\\nPiezoelectric\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nDistance from\\nsubject\\n(20–75 cm away)\\n\\nMat (below bed)\\n\\nMat\\n\\nMat\\n\\nOthers\\n(under bed legs)\\n\\nIvanovs 2019 [168]\\n\\nChest wall movements\\nModulation cardiac\\nactivity\\n\\nCamera\\nRadar\\n\\nRespiration\\ndetection\\n\\n-\\n\\nJoshi 2019 [169]\\n\\nChest wall movements\\n\\nCapacitive\\n\\nKrej 2019 [170]\\n\\nChest wall movements\\n\\nFiber optic\\n\\nLorato 2019 [171]\\n\\nAir temperature\\n\\nCamera\\n\\nMassaroni 2019 [172]\\n\\nChest wall movements\\n\\nCamera\\n\\nPark 2019 [173]\\n\\nChest wall movements\\n\\nPiezoelectric\\n\\nWalterscheid 2019\\n[174]\\n\\nModulation cardiac\\nactivity\\n\\nWang 2019 [175]\\n\\nModulation cardiac\\nactivity\\n\\nRadar\\n\\nRadar\\n\\nXu 2019 [176]\\n\\nRespiratory sounds\\n\\nMicrophone\\n\\nYang 2019 [177]\\n\\nModulation cardiac\\nactivity\\n\\nRadar\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nMat (below baby\\nmattress)\\n\\nMat\\n\\nDistance from\\nsubject\\n(side and front,\\n10–50 cm away)\\n\\nDistance from\\nsubject\\n(1.2 m away)\\n\\nUser’s mat\\n(Chest region)\\n\\nDistance from\\nsubject\\n(3.3–4.2 m away)\\n\\nDistance from\\nsubject\\n(50 cm away)\\n\\nOthers (instrument\\npanel of vehicle)\\n\\nDistance from\\nsubject\\n(1.5 m height,\\n0–3 m away)\\n\\n7 × 7 cm\\n(each sensor)\\n\\n580 × 300 × 0.4 mm\\n\\n40 × 750 × 0.25 mm\\n\\nChen 2018 [178]\\n\\nModulation cardiac\\nactivity\\n\\nWi-Fi\\ntransmitter and\\nreceiver\\n\\nRR\\nRespiration\\ndetection\\n\\nNodes\\n\\n-\\n\\nChen 2018 [179]\\n\\nChest wall movements\\n\\nPiezoelectric\\n\\nRR\\n\\nMat\\n\\nMassaroni 2018 [180]\\n\\nChest wall movements\\n\\nCamera\\n\\nRR\\nRespiratory\\npattern\\n\\nMassaroni 2018 [181]\\n\\nChest wall movements\\n\\nFiber optic\\n\\nRR\\n\\nDistance from\\nsubject\\n(1.2 m away)\\n\\nOthers (inside\\nventilator duct)\\n\\n2 × 35 cm\\n\\n-\\n\\n3 cm\\n\\nSadek 2018 [182]\\n\\nChest wall movements\\n\\nFiber optic\\n\\nRR\\nRespiratory\\npattern\\n\\nMat\\n\\n20 × 50 cm\\n\\n1 Note: The analysis for studies published before 2018 [5–7,9,10,19,48,50–54,183–234] is included in Appendix A\\n(Table A2).\\n\\nIn relation to the sensing techniques and sensors, Figures 6 and 7 show the main results\\nfor the wearable and environmental categories, respectively. Most authors chose to detect chest\\nwall movements (60%). For the environmental category, modulation of cardiac activity was also\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n14 of 84\\n\\nvery common [5,7,50,52,54,163,164,168,174,175,177,178,189,190,196–199,205–207,213,214,219,221,223–\\n226,229,232,233]. Meanwhile, air temperature and air humidity were the second [2,64,91,104,107,116,\\n120,128,133,145,153–156,162] and third [66,74,75,80,82,89,97,101,137,138] most widely implemented\\ntechniques in the wearable category, at great distance. In this category, ﬁber optic sensors were used in\\nalmost 19% of the studies, resistive sensors in 15%, accelerometers in more than 11%, and capacitive\\nsensors in more than 9%. Great variability in sensors can be found in studies of this category,\\nas there is no predominant type. This contrasts with the environmental category since radars are\\nused in more than 33% of the studies, being the leading technology followed by cameras (18%)\\nand ﬁber optic sensors (14%). There are types of sensors, such as magnetometers, gyroscopes,\\nmicrophones, optical sensors, inductive sensors, or thermistors, in which its use is very limited in both\\ncategories [62,73,76,77,81,91,95,106,107,115,119,120,131,135,156,160,162,185,193,217].\\n\\nFigure 6. Distribution of sensing techniques (left) and sensors (right) used in the studies of the\\nwearable category.\\n\\nFigure 7. Distribution of sensing techniques (left) and sensors (right) used in the studies of the\\nenvironmental category.\\n\\nRegarding breathing parameters (Figure 8), RR was obtained in 60% of the wearable studies and in\\n79% of the environmental studies. It was the most widely used parameter by far. Other metrics based\\non the analysis of the magnitude versus time curve, such as breathing period or expiratory/inspiratory\\ntimes, were barely used (2% in the wearable category) [94,103]. The representation of the volume\\n\\nSensors 2020, 20, x FOR PEER REVIEW 14 of 89  height, 0–3 m away) Chen 2018 [178] Modulation cardiac activity Wi-Fi transmitter and receiver RR Respiration detection Nodes - Chen 2018 [179] Chest wall movements Piezoelectric  RR Mat 2 × 35 cm Massaroni 2018 [180] Chest wall movements Camera RR Respiratory pattern Distance from subject (1.2 m away) - Massaroni 2018 [181] Chest wall movements Fiber optic RR Others (inside ventilator duct) 3 cm Sadek 2018 [182] Chest wall movements Fiber optic RR Respiratory pattern Mat 20 × 50 cm 1 Note: The analysis for studies published before 2018 [5–7,9,10,19,48,50–54,183–234] is included in Appendix A (Table A2). In relation to the sensing techniques and sensors, Figures 6 and 7 show the main results for the wearable and environmental categories, respectively. Most authors chose to detect chest wall movements (60%). For the environmental category, modulation of cardiac activity was also very common [5,7,50,52,54,163,164,168,174,175,177,178,189,190,196–199,205–207,213,214,219,221,223–226,229,232,233]. Meanwhile, air temperature and air humidity were the second [2,64,91,104,107,116,120,128,133,145,153–156,162] and third [66,74,75,80,82,89,97,101,137,138] most widely implemented techniques in the wearable category, at great distance. In this category, fiber optic sensors were used in almost 19% of the studies, resistive sensors in 15%, accelerometers in more than 11%, and capacitive sensors in more than 9%. Great variability in sensors can be found in studies of this category, as there is no predominant type. This contrasts with the environmental category since radars are used in more than 33% of the studies, being the leading technology followed by cameras (18%) and fiber optic sensors (14%). There are types of sensors, such as magnetometers, gyroscopes, microphones, optical sensors, inductive sensors, or thermistors, in which its use is very limited in both categories [62,73,76,77,81,91,95,106,107,115,119,120,131,135,156,160,162,185,193,217].   Figure 6. Distribution of sensing techniques (left) and sensors (right) used in the studies of the wearable category. Respiratory Air flow, 5Respiratory sounds, 4Air temperature, 13Air humidity, 10Chest wall movements, 74Modulation cardiac activity, 70510152025Fiber opticResistiveAccelerometerCapacitiveNanocrystal nanoparticlesPyroelectricGyroscopeECGPiezoelectricThermistorMicrophonePPGOthersNumber of studiesSensors 2020, 20, x FOR PEER REVIEW 15 of 89    Figure 7. Distribution of sensing techniques (left) and sensors (right) used in the studies of the environmental category. Regarding breathing parameters (Figure 8), RR was obtained in 60% of the wearable studies and in 79% of the environmental studies. It was the most widely used parameter by far. Other metrics based on the analysis of the magnitude versus time curve, such as breathing period or expiratory/inspiratory times, were barely used (2% in the wearable category) [94,103]. The representation of the volume versus time curve or the use of volumetric parameters was not common. They appeared in 10% of the studies of the wearable category [2,17,49,61,67,111,113,116,122,127,147] and in 5% of the studies of the environmental group [48,51,52,215]. Among the possible volume metrics, tidal volume was the most common in the wearable category [2,17,49,61,111,113,116,122,127], while it was found in one study of the environmental category [52]. The rest of the metrics (MV, vital capacity, peak inspiratory flow, peak expiratory flow, and compartmental volume) were used in isolated cases. A considerable number of studies detected respiratory patterns in both wearable [17,143,152,159] and environmental categories [10,19,50–54,180,182,194,218]. The most common approach was to detect abnormal breathing patterns to identify respiratory disorders, such as apnea. This was especially common in environmental systems.  Air temperature, 5Chest wall movements, 45Modulation cardiac activity, 32Others, 2051015202530Number of studies01020304050607080OthersCompartmental volumeRespiration frequencyPeak inspiration flowRespiratory periodRespiratory patternsMinute ventilationTidal volumeMonitoring of breathingRespiratory rateNumber of studies\\x0cSensors 2020, 20, 5446\\n\\n15 of 84\\n\\nversus time curve or the use of volumetric parameters was not common. They appeared in 10% of\\nthe studies of the wearable category [2,17,49,61,67,111,113,116,122,127,147] and in 5% of the studies\\nof the environmental group [48,51,52,215]. Among the possible volume metrics, tidal volume was\\nthe most common in the wearable category [2,17,49,61,111,113,116,122,127], while it was found in\\none study of the environmental category [52]. The rest of the metrics (MV, vital capacity, peak\\ninspiratory ﬂow, peak expiratory ﬂow, and compartmental volume) were used in isolated cases.\\nA considerable number of studies detected respiratory patterns in both wearable [17,143,152,159] and\\nenvironmental categories [10,19,50–54,180,182,194,218]. The most common approach was to detect\\nabnormal breathing patterns to identify respiratory disorders, such as apnea. This was especially\\ncommon in environmental systems.\\n\\nFigure 8. Number of studies obtaining the diﬀerent respiratory parameters for the wearable (top) and\\nenvironmental (bottom) categories.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 15 of 89    Figure 7. Distribution of sensing techniques (left) and sensors (right) used in the studies of the environmental category. Regarding breathing parameters (Figure 8), RR was obtained in 60% of the wearable studies and in 79% of the environmental studies. It was the most widely used parameter by far. Other metrics based on the analysis of the magnitude versus time curve, such as breathing period or expiratory/inspiratory times, were barely used (2% in the wearable category) [94,103]. The representation of the volume versus time curve or the use of volumetric parameters was not common. They appeared in 10% of the studies of the wearable category [2,17,49,61,67,111,113,116,122,127,147] and in 5% of the studies of the environmental group [48,51,52,215]. Among the possible volume metrics, tidal volume was the most common in the wearable category [2,17,49,61,111,113,116,122,127], while it was found in one study of the environmental category [52]. The rest of the metrics (MV, vital capacity, peak inspiratory flow, peak expiratory flow, and compartmental volume) were used in isolated cases. A considerable number of studies detected respiratory patterns in both wearable [17,143,152,159] and environmental categories [10,19,50–54,180,182,194,218]. The most common approach was to detect abnormal breathing patterns to identify respiratory disorders, such as apnea. This was especially common in environmental systems.  Air temperature, 5Chest wall movements, 45Modulation cardiac activity, 32Others, 2051015202530Number of studies01020304050607080OthersCompartmental volumeRespiration frequencyPeak inspiration flowRespiratory periodRespiratory patternsMinute ventilationTidal volumeMonitoring of breathingRespiratory rateNumber of studiesSensors 2020, 20, x FOR PEER REVIEW 16 of 89   Figure 8. Number of studies obtaining the different respiratory parameters for the wearable (top) and environmental (bottom) categories. Regarding sensor location, most wearable studies placed them on the chest or abdomen (Figure 9). This was the most common trend by far. It was also common that sensors were embedded in shirts at chest or abdomen level [21,49,59,65,69,84,85,94,108,113,123,142,143,151,235]. This was the location selected by 15% of the studies. Nose or mouth were also widely used locations to place the sensors. As a particular case of sensors placed in the nose or mouth, several researchers integrated them into a mask [66,75,80,82,92,101,107,137,156]. This contrasts with locations, like fingers, waist, arms, or wrists, in which use was residual [93,115,117,118,126,139,157].  Figure 10 shows the locations adopted in the environmental studies. On the one hand, the most common approach was to place the sensor at a fixed distance from the subject. Fifty-two% of the studies used this setup. On the other hand, Figure 10 shows that placing the sensors as nodes without precise control of the distance between the sensor and the subject was adopted by 6% of the studies. Meanwhile, 29% of the studies integrated the sensors into mats or pillows [9,19,164–166,169,170,173,179,182,183,186,194,201–203,210–212,217,218,220,227,230,231,236] to measure breathing parameters during rest activities mainly. The rest of the environmental locations shown in Table 2 were only used in isolated cases.  Figure 9. Distribution of sensor location for the wearable studies. 010203040506070OthersPeak expiratory flowPeak inspiration flowVital capacityTidal volumeExhalation flow rateMonitoring of breathingRespiratory patternsRespiratory rateNumber of studies010203040506070Number of studies\\x0cSensors 2020, 20, 5446\\n\\n16 of 84\\n\\nRegarding sensor location, most wearable studies placed them on the chest or abdomen (Figure 9).\\nThis was the most common trend by far. It was also common that sensors were embedded in shirts\\nat chest or abdomen level [21,49,59,65,69,84,85,94,108,113,123,142,143,151,235]. This was the location\\nselected by 15% of the studies. Nose or mouth were also widely used locations to place the sensors.\\nAs a particular case of sensors placed in the nose or mouth, several researchers integrated them into a\\nmask [66,75,80,82,92,101,107,137,156]. This contrasts with locations, like ﬁngers, waist, arms, or wrists,\\nin which use was residual [93,115,117,118,126,139,157].\\n\\nFigure 10 shows the locations adopted in the environmental studies. On the one hand, the most\\ncommon approach was to place the sensor at a ﬁxed distance from the subject. Fifty-two% of the\\nstudies used this setup. On the other hand, Figure 10 shows that placing the sensors as nodes without\\nprecise control of the distance between the sensor and the subject was adopted by 6% of the studies.\\nMeanwhile, 29% of the studies integrated the sensors into mats or pillows [9,19,164–166,169,170,173,179,\\n182,183,186,194,201–203,210–212,217,218,220,227,230,231,236] to measure breathing parameters during\\nrest activities mainly. The rest of the environmental locations shown in Table 2 were only used in\\nisolated cases.\\n\\nFigure 9. Distribution of sensor location for the wearable studies.\\n\\nFigure 10. Distribution of sensor location for the environmental studies.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 16 of 89   Figure 8. Number of studies obtaining the different respiratory parameters for the wearable (top) and environmental (bottom) categories. Regarding sensor location, most wearable studies placed them on the chest or abdomen (Figure 9). This was the most common trend by far. It was also common that sensors were embedded in shirts at chest or abdomen level [21,49,59,65,69,84,85,94,108,113,123,142,143,151,235]. This was the location selected by 15% of the studies. Nose or mouth were also widely used locations to place the sensors. As a particular case of sensors placed in the nose or mouth, several researchers integrated them into a mask [66,75,80,82,92,101,107,137,156]. This contrasts with locations, like fingers, waist, arms, or wrists, in which use was residual [93,115,117,118,126,139,157].  Figure 10 shows the locations adopted in the environmental studies. On the one hand, the most common approach was to place the sensor at a fixed distance from the subject. Fifty-two% of the studies used this setup. On the other hand, Figure 10 shows that placing the sensors as nodes without precise control of the distance between the sensor and the subject was adopted by 6% of the studies. Meanwhile, 29% of the studies integrated the sensors into mats or pillows [9,19,164–166,169,170,173,179,182,183,186,194,201–203,210–212,217,218,220,227,230,231,236] to measure breathing parameters during rest activities mainly. The rest of the environmental locations shown in Table 2 were only used in isolated cases.  Figure 9. Distribution of sensor location for the wearable studies. 010203040506070OthersPeak expiratory flowPeak inspiration flowVital capacityTidal volumeExhalation flow rateMonitoring of breathingRespiratory patternsRespiratory rateNumber of studies010203040506070Number of studiesSensors 2020, 20, x FOR PEER REVIEW 17 of 89   Figure 10. Distribution of sensor location for the environmental studies. 3.2. Data Transmission and Power Consumption 3.2.1. Items of Analysis This category includes the following items of analysis: general system setup, communication protocol, processing station, and energy autonomy and power consumption. General System Setup Different configurations can be found in systems for respiratory monitoring depending on the data transmission architecture. Systems can be roughly divided into two categories (Figure 11): (A) those that perform data processing on a centralized processing platform and (B) those that perform data processing near the remote sensing unit. • Systems that perform centralized processing: Data processing is done in a centralized system that does not need to be close to the subject being monitored. The magnitude values registered by the sensors are acquired and conditioned [24] and then transmitted to a centralized processing unit. Three different approaches can be found depending on the specific point where the acquisition & conditioning module and transmission module are placed: o The acquisition & conditioning and transmission modules are in the same package as the sensing unit (cases 1.x of Figure 11A, ∀(cid:1876)∈[1..2]). o The acquisition & conditioning module is in the same package as the sensing unit, but the transmission module is placed externally (cases 2.x of Figure 11A, ∀(cid:1876)∈[1..2]). o Both the acquisition & conditioning and transmission modules are not included in the same package as the sensing unit (cases 3.x of Figure 11A, ∀(cid:1876)∈[1..2]). For all three approaches, data visualization can be done in two different ways: next to the processing unit of the registered signals (cases 1.1, 2.1, and 3.1 of Figure 11A) or at a different point (cases 2.1, 2.2, and 3.2 of Figure 11A). • Systems that perform remote processing: Processing of breathing signals to determine the respiratory parameters of interest is performed near the subject whose breathing is being monitored. Three different setups are possible depending on whether the acquisition & conditioning module and the processing module are included in the same package as the sensing unit: o The acquisition & conditioning circuits, the microcontroller for the processing and the data transmission module are placed in the same package as the sensing unit (cases 4.x of Figure 11B, ∀(cid:1876)∈[1..2]).  0510152025303540Distance fromsubject(front/above)User's mat/pillowNodesOthersNot specifiedNumber of studies\\x0cSensors 2020, 20, 5446\\n\\n17 of 84\\n\\n3.2. Data Transmission and Power Consumption\\n\\n3.2.1. Items of Analysis\\n\\nThis category includes the following items of analysis: general system setup, communication\\n\\nprotocol, processing station, and energy autonomy and power consumption.\\n\\nGeneral System Setup\\n\\nDiﬀerent conﬁgurations can be found in systems for respiratory monitoring depending on the data\\ntransmission architecture. Systems can be roughly divided into two categories (Figure 11): (A) those\\nthat perform data processing on a centralized processing platform and (B) those that perform data\\nprocessing near the remote sensing unit.\\n\\n•\\n\\nSystems that perform centralized processing: Data processing is done in a centralized system that\\ndoes not need to be close to the subject being monitored. The magnitude values registered by the\\nsensors are acquired and conditioned [24] and then transmitted to a centralized processing unit.\\nThree diﬀerent approaches can be found depending on the speciﬁc point where the acquisition &\\nconditioning module and transmission module are placed:\\n\\nThe acquisition & conditioning and transmission modules are in the same package as the\\nsensing unit (cases 1.x of Figure 11A, ∀x ∈ [1..2]).\\nThe acquisition & conditioning module is in the same package as the sensing unit, but the\\ntransmission module is placed externally (cases 2.x of Figure 11A, ∀x ∈ [1..2]).\\nBoth the acquisition & conditioning and transmission modules are not included in the\\nsame package as the sensing unit (cases 3.x of Figure 11A, ∀x ∈ [1..2]).\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\nFor all three approaches, data visualization can be done in two diﬀerent ways: next to the\\nprocessing unit of the registered signals (cases 1.1, 2.1, and 3.1 of Figure 11A) or at a diﬀerent point\\n(cases 2.1, 2.2, and 3.2 of Figure 11A).\\n\\n•\\n\\nSystems that perform remote processing: Processing of breathing signals to determine the respiratory\\nparameters of interest is performed near the subject whose breathing is being monitored.\\nThree diﬀerent setups are possible depending on whether the acquisition & conditioning module\\nand the processing module are included in the same package as the sensing unit:\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\nThe acquisition & conditioning circuits, the microcontroller for the processing and the\\ndata transmission module are placed in the same package as the sensing unit (cases 4.x of\\nFigure 11B, ∀x ∈ [1..2]).\\nThe acquisition & conditioning circuits are placed in the same package as the sensing\\nunit. However, the microcontroller in charge of the processing and the data transmission\\nmodule are placed in an external package, which is not compactly integrated with the\\nsensing module (cases 5.x of Figure 11B, ∀x ∈ [1..2]).\\nThe acquisition & conditioning circuits, the microprocessor and the data transmission\\nmodule are placed in a diﬀerent package than the sensing unit (cases 6.x of Figure 11B,\\n∀x ∈ [1..2]).\\n\\nRegarding data visualization, it can be done in two diﬀerent ways: remotely without the need for\\ndata transmission (in this case, the data transmission module is not included) (cases 4.1, 5.1, and 6.1 of\\nFigure 11B) or in a central unit (cases 4.2, 5.2, and 6.2 of Figure 11B).\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n18 of 84\\n\\nFigure 11. Representation of possible setups of respiratory sensing systems. (A) perform data processing\\non a centralized processing platform and (B) perform data processing near the remote sensing unit.\\n\\nCommunication Protocol\\n\\nCommunication between the diﬀerent modules of the system can be classiﬁed according to\\n\\nwhether it is wired or wireless:\\n\\n• Wired transmission: All system elements (sensing, acquisition, conditioning, transmission,\\nprocessing, and visualization) are physically connected. The USB (universal serial bus) protocol is\\nthe most common way of transmitting the acquired respiratory signals.\\n\\n• Wireless transmission: Subjects wear the sensing system without cable connections to other\\nelements of the system. The transmission and reception of measurements is carried out through a\\n\\nSensors 2020, 20, x FOR PEER REVIEW 18 of 89  o The acquisition & conditioning circuits are placed in the same package as the sensing unit. However, the microcontroller in charge of the processing and the data transmission module are placed in an external package, which is not compactly integrated with the sensing module (cases 5.x of Figure 11B, ∀(cid:1876)∈[1..2]). o The acquisition & conditioning circuits, the microprocessor and the data transmission module are placed in a different package than the sensing unit (cases 6.x of Figure 11B, ∀(cid:1876)∈[1..2]). Regarding data visualization, it can be done in two different ways: remotely without the need for data transmission (in this case, the data transmission module is not included) (cases 4.1, 5.1, and 6.1 of Figure 11B) or in a central unit (cases 4.2, 5.2, and 6.2 of Figure 11B).  Figure 11. Representation of possible setups of respiratory sensing systems. \\x0cSensors 2020, 20, 5446\\n\\n19 of 84\\n\\nwireless transmission technology. Therefore, the usability of the system increases [55]. Diﬀerent\\ntransmission technologies can be found in existing studies [237]:\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\n(cid:35)\\n\\nBluetooth: It is a standard and communication protocol for personal area networks. It is\\nsuitable for applications that require continuous data transmission with a medium data\\ntransmission rate (up to 1 Mbps). It uses a radio communication system, which means that\\nthe transmitting and receiving devices do not need to be in line of sight. It operates in the\\n2.4–2.485 GHz band with a low transmission distance (1 to 100 m, typically). There are ﬁve\\nBluetooth classes (1, 1.5, 2, 3, and 4). Most Bluetooth-based respiration monitoring systems\\nuse class 2 or higher. This means that the transmission distance is short (less than 10 m,\\nin general), but the power consumption is also moderate [237].\\nWi-Fi: This technology is generally used for local area networks instead of personal\\narea networks, like Bluetooth. It has much higher data transmission rates and power\\nconsumption is also higher. At a typical 2.4 GHz operating frequency, it can consume\\na maximum of 100 mW. Wi-Fi operating band is in the 2.4–5 GHz range. In general,\\nthe transmission range is between 50 m and 100 m, although it can be greatly extended in\\nsome conditions. This technology is suitable for applications where constant high-speed\\ndata transmission is required, the transmission distance is relatively large, and power\\nconsumption is not an issue [238].\\nGSM/GPRS: Global System for Mobile Communications (GSM) is a standard for mobile\\ncommunication that belongs to the second-generation (2G) of digital cellular networks.\\nIt requires base stations to which the mobile devices connect. The coverage range of base\\nstations varies from a few meters to dozen of kilometers. Within this 2G technology, it is\\nalso possible to ﬁnd the General Packet Radio Service (GPRS), which is data-oriented.\\nThe transmission rate of GPRS is low (around 120 kbps, although this rate is usually lower\\nin real conditions) with a limitation of 2 W of power consumption. The frequency band of\\nthis technology is in the range of 850–1900 MHz [239].\\nZigbee: It is a speciﬁcation of several high-level communication protocols. Zigbee is used\\nfor the creation of personal area networks that do not need high data transmission rates.\\nZigBee can operate in the industrial, medical and scientiﬁc radio bands, which may vary\\namong countries. This is the reason why it generally works in the 2.4 GHz band that is\\navailable worldwide. If the system operates in the 2.4 GHz band, its data transmission rate\\nis 250 kbps. Devices using this technology are generally inexpensive since the required\\nmicroprocessor is simple due to the low transmission rate of Zigbee. Power consumption is\\nlow since nodes can be asleep until some information is received. It is useful for applications\\nthat do not require constant transmission. The range of transmission distance is similar to\\nthat of Bluetooth technology [237].\\nRadio frequency: These modules are suitable for applications that do not need a high speed\\nof data transmission. Radio frequency works in the Ultra High Frequency band (433 MHz)\\nand requires a receiver-transmitter pair. It is low power and cheap, with a small module\\nsize. Communication range is from 20 to 200 m. This range depends on the input voltage\\nof the module: at higher voltages, greater communication distance is reached. Working\\nvoltage for this technology ranges from 3.5 to 12 V. Radio broadcasting is performed\\nthrough amplitude modulation. Radio frequency requires both receivers and transmitters\\nto incorporate a microcontroller module. Typical power consumption is up to 10 mW.\\n\\nTable 3 shows a schematic comparison of some key properties of the main wireless transmission\\n\\ntechnologies used in respiration studies.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n20 of 84\\n\\nTable 3. Comparison of the main transmission technologies used in respiratory monitoring\\nsystems [237].\\n\\nOperating\\nBandwidth\\n\\nTransmission\\nSpeed\\n\\nPower\\nConsumption\\n\\nRange (m)\\n\\nHardware\\nComplexity\\n\\nBluetooth\\n\\n2.4 GHz\\n\\n1 Mbps\\n\\nZigbee\\n\\nWi-Fi\\n\\n2.4 GHz\\n(valid worldwide)\\n\\n250 kbps at\\n2.4 GHz band\\n\\n2.4–5 GHz\\ngenerally\\n\\nUp to 1 Gbps\\n\\nGSM/GPRS\\n\\n850–1900 MHz\\n\\n120 kbps\\n\\nRadio frequency\\n\\n433 MHz\\n\\n4 kbps\\n\\n1–100\\n\\n10–100\\n\\n50–100\\n\\n100\\nm–several\\nkilometers\\n\\n20–200\\n\\nProcessing Station\\n\\nAnother item of analysis is the platform on which the recorded signals are processed to obtain\\n\\nrespiratory information. Several options exist in the state of the art (Figure 12):\\n\\n•\\n\\n•\\n\\n•\\n•\\n\\nPC (personal computer): The respiration sensing system is connected or linked to a local PC that\\nperforms the processing of the registered breathing signals.\\nSmartphone/Tablet: The sensing system communicates wirelessly with a smartphone application\\nthat runs the processing algorithm ubiquitously.\\nCloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.\\nEmbedded hardware: Processing is performed directly on embedded systems, which are located\\nin or near the sensing unit package.\\n\\nFigure 12. Representation of possible setups of respiratory sensing systems.\\n\\nEnergy Autonomy and Power Consumption\\n\\nRegarding the power supply, systems can be categorized according to whether (1) they harvest\\npart of the energy required for system operation, (2) they use rechargeable batteries, or (3) they are\\ndirectly connected to a power source through a cable. This section analyses the ﬁrst two categories\\nin more detail since systems connected to a power source are of less interest as they have unlimited\\npower availability.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device Sensors 2020, 20, x FOR PEER REVIEW 20 of 89  through amplitude modulation. Radio frequency requires both receivers and transmitters to incorporate a microcontroller module. Typical power consumption is up to 10 mW. Table 3 shows a schematic comparison of some key properties of the main wireless transmission technologies used in respiration studies. Table 3. Comparison of the main transmission technologies used in respiratory monitoring systems [237].  Operating Bandwidth Transmission Speed Power Consumption Range (m) Hardware Complexity Bluetooth 2.4 GHz 1 Mbps  1–100  Zigbee 2.4 GHz (valid worldwide) 250 kbps at 2.4 GHz band  10–100  Wi-Fi 2.4–5 GHz generally Up to 1 Gbps  50–100  GSM/GPRS 850–1900 MHz 120 kbps  100 m–several kilometers  Radio frequency 433 MHz 4 kbps  20–200  Processing Station Another item of analysis is the platform on which the recorded signals are processed to obtain respiratory information. Several options exist in the state of the art (Figure 12): • PC (personal computer): The respiration sensing system is connected or linked to a local PC that performs the processing of the registered breathing signals. • Smartphone/Tablet: The sensing system communicates wirelessly with a smartphone application that runs the processing algorithm ubiquitously. • Cloud: Breathing signals are sent wirelessly to a remote server, which performs cloud computing.  • Embedded hardware: Processing is performed directly on embedded systems, which are located in or near the sensing unit package.   Figure 12. Representation of possible setups of respiratory sensing systems. Cloud PC Send Save Visualiz. Send Save Visualiz. Smartphone/Tablet Embedded hardware Sensing device \\x0cSensors 2020, 20, 5446\\n\\n21 of 84\\n\\n(1) Energy Harvesters\\n\\nFew were the studies found in the systematic searches conducted in this review that harvested\\nenergy [77,84,104]. However, some energy harvesting techniques have been reported experimentally in\\nother wearable systems [240–249]. This section presents a description of these techniques and how they\\nwere implemented in the respiratory sensing systems. They were based on magnetic induction, piezo\\nelectric eﬀect, triboelectric power generation, pyroelectric eﬀect, thermoelectric eﬀect, electrostatic\\npower generation, and solar cells.\\n\\n• Magnetic induction generator: A small electric generator can be used to transform mechanical\\nenergy into electrical energy according to Faraday’s law. An electric current is induced in the\\ngenerator coils by a changing magnetic ﬁeld produced by the movement of the rotor due to\\nthe mechanical energy applied to it during breathing. The amount of generated voltage can be\\ncalculated according to Equation (1) [135].\\n\\nV = − N × K1\\nK2\\n\\n× d∆CChest\\ndt\\n\\n,\\n\\n(1)\\n\\nwhere N is the number of turns of the coil, ∆CChest is the circumference change of the chest, K2 is the\\nproportionality constant between ∆CChest and the angular displacement, and K1 is the proportionality\\nconstant between the magnetic ﬂux and the rate of change of the angular displacement. The prototype\\npresented by Padasdao et al. [135] attached the motor to a plastic housing with an armature ﬁxed to\\nthe rotor gears (or shaft) (Figure 13A). A non-elastic wire was wrapped around the chest. One side of\\nthe wire was ﬁxed to the plastic housing and the other end was attached to the armature. A piece of\\nhard felt was ﬁxed to the housing to help stabilize the device against the body. A spring was attached\\nbetween the armature and the plastic housing to provide a restoring force to the armature. During\\ninspiration, the non-elastic wire pulled the armature, leading to rotor rotation. During expiration,\\nthe spring pulled the armature back, leading to rotor rotation in the opposite direction. In this way,\\nenergy was harvested. In the work of Padasdao et al. [135], the electrical signal generated was used\\nto obtain the RR instead of supplying power to the system. However, this is an example of how\\nrespiratory movements can be converted into electrical energy.\\n\\nOther respiration-based energy harvesting systems can be found in the literature. The works of\\nDelnavaz et al. [240] and Goreke et al. [241] used air ﬂow to produce power with magnetic induction\\ngenerators. On the one hand, the prototype of Delnavaz et al. [240] was made up of two ﬁxed magnets\\nlocated at the ends of a tube (opposite poles facing each other) with a free magnet inside the tube\\n(Figure 13B). The free magnet was suspended due to the repulsive forces with the ﬁxed magnets. A coil\\nwas wrapped around the outside of the tube. When a subject breathed into the tube, the free magnet\\nmoved around its static position. In this way, a voltage was induced in the coil since it was crossed by\\na variable magnetic ﬁeld, which caused the magnetic induction. Experimental results showed that\\nmore than 3 µW were generated. The induced voltage in a closed circuit (U) was proportional to the\\nmagnetic ﬂux gradient (dφ/dx) and the velocity of the magnet (dx/dt), according to Equation (2).\\n\\nU = −N\\n\\nd∅\\ndt\\n\\ndx\\ndt\\n\\n.\\n\\n(2)\\n\\nOn the other hand, a microelectromechanical-scale turbine was presented by Goreke et al. [241].\\nThe turbine had 12 blades on its outer contour and ball bearings around the center embedded in\\ngrooves (Figure 13C). A permanent magnet was integrated in the area between the ball bearings and the\\nturbine blades. The entire prototype was encapsulated in a package with rectangular openings for the\\nairﬂow. The prototype presented was under development and not fully implemented. The operating\\nprinciple of the system could be as follows: by ﬂowing air for the rectangular openings, the blades\\nrotate and move the turbine in such a way that its coils see a variable magnetic ﬁeld generated by the\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n22 of 84\\n\\nﬁxed magnet. This generates power through magnetic induction. The maximum power generated\\nwas 370 mW.\\n\\n•\\n\\nFigure 13. Schemes of energy harvesting using magnetic induction generation: (A) DC generator\\nactivated by chest movements (ﬁgure inspired by Reference [135]), (B) tube with ﬁxed and free magnets\\nmoved by airﬂow (ﬁgure inspired by Reference [240]), and (C) turbine moved by airﬂow (ﬁgure inspired\\nby Reference [241]).\\n\\nPiezoelectric energy harvesting: These harvesters generate a voltage when compressed or\\nstretched [242]. In the work of Shahhaidar et al. [242], they were embedded in a belt alongside the\\nchest. Due to low capacitance of the piezoresistive materials, the overall harvested energy was low.\\nTherefore, this piezoresistive conﬁguration was unable to provide the necessary energy to power\\nthe entire system. The main drawback to adopting this energy harvesting technique for respiration\\nsensors is that the required vibration frequency is much higher than the respiration frequency.\\nIn this sense, the paper of Li et al. [243] presented a prototype based on the interaction between a\\npiezoelectric cantilever and a magnet placed on a substrate (Figure 14B). The vertical vibration\\nof the cantilever due to the magnet presence allowed generating a constant amount of energy.\\nThe substrate with the magnet was attached to subject body (a limb joint). The movements of the\\nsubject led to substrate stretching and contraction, which caused the vibration of the piezoelectric\\ncantilever. The energy generated was stable for diﬀerent types of movements, since it was tested\\non diﬀerent parts of the body. The energy harvester worked correctly for subject movements in the\\nfrequency range of 0.5–5.0 Hz. It has potential to be used with breathing movements. Meanwhile,\\nWang et al. [244] presented a piezoelectric rubber band that could be mounted on an elastic\\nwaistband to generate electricity from the circumferential stretch caused by breathing. The paper\\nshowed a structure made up of top and bottom electrodes with two solid layers and one void layer\\nin between (Figure 14A). They were made of composite polymeric and metallic microstructures\\nwith embedded bipolar charges. Finally, the work of Sun et al. [245] presented an energy harvester\\nfrom respiration air ﬂow based on the piezoelectric eﬀect. They used piezoelectric polyvinylidene\\nﬂuoride (PVDF) microbelts that oscillated under low-speed airﬂow to generate electrical power in\\nthe order of magnitude of µW (Figure 14C).\\n\\nSensors 2020, 20, x FOR PEER REVIEW 22 of 89  for the airflow. The prototype presented was under development and not fully implemented. The operating principle of the system could be as follows: by flowing air for the rectangular openings, the blades rotate and move the turbine in such a way that its coils see a variable magnetic field generated by the fixed magnet. This generates power through magnetic induction. The maximum power generated was 370 mW.  Figure 13. Schemes of energy harvesting using magnetic induction generation: (A) DC generator activated by chest movements (figure inspired by Reference [135]), (B) tube with fixed and free magnets moved by airflow (figure inspired by Reference [240]), and (C) turbine moved by airflow (figure inspired by Reference [241]). • Piezoelectric energy harvesting: These harvesters generate a voltage when compressed or stretched [242]. In the work of Shahhaidar et al. [242], they were embedded in a belt alongside the chest. Due to low capacitance of the piezoresistive materials, the overall harvested energy was low. Therefore, this piezoresistive configuration was unable to provide the necessary energy to power the entire system. The main drawback to adopting this energy harvesting technique for respiration sensors is that the required vibration frequency is much higher than the respiration frequency. In this sense, the paper of Li et al. [243] presented a prototype based on the interaction between a piezoelectric cantilever and a magnet placed on a substrate (Figure 14B). The vertical vibration of the cantilever due to the magnet presence allowed generating a constant amount of energy. The substrate with the magnet was attached to subject body (a limb joint). The movements of the subject led to substrate stretching and contraction, which caused the vibration of the piezoelectric cantilever. The energy generated was stable for different types of movements, since it was tested on different parts of the body. The energy harvester worked correctly for subject movements in the frequency range of 0.5–5.0\\u2009Hz. It has potential to be used with breathing movements. Meanwhile, Wang et al. [244] presented a piezoelectric rubber band that could be mounted on an elastic waistband to generate electricity from the circumferential stretch caused by breathing. The paper showed a structure made up of top and bottom electrodes with two solid layers and one void layer in between (Figure 14A). They were made of composite polymeric and metallic microstructures with embedded bipolar charges. Finally, the work of Sun et al. [245] presented an energy harvester from respiration air flow based on the piezoelectric effect. They used piezoelectric polyvinylidene fluoride (PVDF) microbelts that oscillated under low-speed airflow to generate electrical power in the order of magnitude of µW (Figure 14C). \\x0cSensors 2020, 20, 5446\\n\\n23 of 84\\n\\nFigure 14. Piezoelectric energy harvesters. Three possible conﬁgurations are shown: (A) power\\ngeneration based on compression or stretching movements associated with breathing (ﬁgure inspired\\nby Reference [244]), (B) energy harvesting based on vibration ampliﬁed by a magnet (ﬁgure inspired by\\nReference [243]), and (C) technique using low speed airﬂow (ﬁgure inspired by Reference [245]).\\n\\n•\\n\\nTriboelectric energy harvesting: They generate charges by rubbing two diﬀerent materials (one is an\\nelectron donor and the other is an electron acceptor), resulting in the creation of a potential in the\\ncontact region [250]. One possible setup is to attach the tribo-pair to a belt to detect variations\\nin abdominal circumference. Triboelectric generators were used in breathing studies as a means\\nof measuring RR, but not as energy harvesters, since the power generated is low for the power\\nrequirements of the entire respiration monitoring system that includes also a data transmission\\nmodule. In the work of Zhang et al. [246] two belts (one extensible and one inextensible) were\\nattached to each side of two materials (Figure 15A). A mechanical experiment was performed to\\nobtain the peak voltage for diﬀerent sliding amplitudes in the range of 2.5 to 30 mm that represents\\nthe typical displacement of a breathing depth. The result of this experiment was Equation (3).\\n\\nVpeak = 0.01383XMax + 0.0092,\\n\\n(3)\\n\\nwhere Vpeak is the peak value of the voltage, and the Xmax is the maximum sliding displacement of\\nthe tribo-pair. A similar approach was proposed by Zhang et al. [77]. They presented a tribo-pair\\nwith both sides of one material ﬁxed to two “Z-shaped” connectors that were attached to a belt\\nwith an inextensible part and an extensible part (Figure 15B). The abdominal contraction and\\nexpansion associated with respiration caused deformation of the two “Z-shaped” connectors.\\nThis deformation led to a process of contact and separation of the tribo-pair, generating an\\nelectrical signal.\\n\\nA self-powered respiratory sensor and energy harvester was also shown in the work of\\nVasandani et al. [247]. The working principle was very similar to the work of Zhang et al. [77]\\nbut, in this case, a prototype was built with movable and ﬁxed supports (Figure 15C). The two materials\\nwere ﬁxed to these two supports. The movements associated with respiration caused an angular\\ndisplacement of the movable support by means of a belt and a lever mechanism, harvesting energy.\\n◦\\nThe voltage obtained between the electrodes was zero in case of full contact and rose to 9.34 V for a 60\\nseparation. The maximum area power density was 7.584 mW/m2.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 23 of 89   Figure 14. Piezoelectric energy harvesters. Three possible configurations are shown: (A) power generation based on compression or stretching movements associated with breathing (figure inspired by Reference [244]), (B) energy harvesting based on vibration amplified by a magnet (figure inspired by Reference [243]), and (C) technique using low speed airflow (figure inspired by Reference [245]). • Triboelectric energy harvesting: They generate charges by rubbing two different materials (one is an electron donor and the other is an electron acceptor), resulting in the creation of a potential in the contact region [250]. One possible setup is to attach the tribo-pair to a belt to detect variations in abdominal circumference. Triboelectric generators were used in breathing studies as a means of measuring RR, but not as energy harvesters, since the power generated is low for the power requirements of the entire respiration monitoring system that includes also a data transmission module. In the work of Zhang et al. [246] two belts (one extensible and one inextensible) were attached to each side of two materials (Figure 15A). A mechanical experiment was performed to obtain the peak voltage for different sliding amplitudes in the range of 2.5 to 30 mm that represents the typical displacement of a breathing depth. The result of this experiment was Equation (3).  (cid:1848)(cid:3043)(cid:3032)(cid:3028)(cid:3038)=0.01383(cid:1850)(cid:3014)(cid:3028)(cid:3051)+0.0092, (3)where (cid:1848)(cid:3043)(cid:3032)(cid:3028)(cid:3038) is the peak value of the voltage, and the (cid:1850)(cid:3040)(cid:3028)(cid:3051) is the maximum sliding displacement of the tribo-pair. A similar approach was proposed by Zhang et al. [77]. They presented a tribo-pair with both sides of one material fixed to two “Z-shaped” connectors that were attached to a belt with an inextensible part and an extensible part (Figure 15B). The abdominal contraction and expansion associated with respiration caused deformation of the two “Z-shaped” connectors. This deformation led to a process of contact and separation of the tribo-pair, generating an electrical signal.  A self-powered respiratory sensor and energy harvester was also shown in the work of Vasandani et al. [247]. The working principle was very similar to the work of Zhang et al. [77] but, in this case, a prototype was built with movable and fixed supports (Figure 15C). The two materials were fixed to these two supports. The movements associated with respiration caused an angular displacement of the movable support by means of a belt and a lever mechanism, harvesting energy. The voltage obtained between the electrodes was zero in case of full contact and rose to 9.34 V for a 60° separation. The maximum area power density was 7.584 mW/m2. \\x0cSensors 2020, 20, 5446\\n\\n24 of 84\\n\\nFigure 15. Setups for triboelectric energy harvesting. Three possible conﬁgurations are shown: (A) ﬂat\\nbelt-attached setup (ﬁgure inspired by Reference [246]), (B) Z-shaped connector (ﬁgure inspired by\\nReference [77]), and (C) movable and ﬁxed supports (ﬁgure inspired by Reference [247]).\\n\\n•\\n\\n•\\n\\nElectrostatic energy harvesting: It is based on the change of parameters of a capacitive device,\\nwhich is called electrostatic energy harvester. Breathing may cause separation of the capacitor\\nplates or modiﬁcation of the plate area, among others [251]. This energy harvesting technique is\\nnot common in respiratory systems. The prototype of Seo et al. [248] showed a capacitor made\\nof two metal electrodes and an insulating layer in between. The capacitance of the prototype\\nvaried with respiration. This was because the area of the top electrode was variable depending\\non the presence of a wet surface associated with respiration (Figure 16). Humid exhaled breath\\nair was cooled by the ambient air on the top surface of the insulated material. Thus, the water\\nmolecules were condensed, acting as part of the upper electrode and changing the capacitance\\nof the prototype. This condensation provided a thick layer that became part of the electrode.\\nThen, the water naturally evaporated due to its vapor pressure and the device returned to its\\noriginal status. The variable capacitance allowed the charges to circulate, harvesting electrostatic\\nenergy. The prototype presented in Reference [248] reported a generated power of 2 µW/cm2.\\nPyroelectric energy harvesting: These harvesters are based on the reorientation of dipoles owing to\\ntemperature ﬂuctuations [252]. Therefore, they need a temperature variation in time. Xue et al. [249]\\npresented a prototype made of a pyroelectric component (metal coated PVDF ﬁlm) covered with\\nelectrodes and mounted on the respirator of a mask at the location where air ﬂows during breathing\\n(Figure 17). The size of the prototype was 3.5 × 3.5 cm. The estimated current generated can be\\nderived from the pyroelectric eﬀect equation:\\n\\nI = Ap\\n\\ndT\\ndt\\n\\n(4)\\n\\nwhere I is the generated current, A in the sensing area, p is the pyroelectric coeﬃcient (approximately\\n27 µC/m2 K), and dT/dt is the variation in temperature. Temperature variation is due to the diﬀerence\\nbetween human body temperature and ambient temperature. It is also inﬂuenced by the transformation\\nof water vapor into exhaled gas. The pyroelectric generator is heated by expiration and cooled by\\n\\nSensors 2020, 20, x FOR PEER REVIEW 24 of 89   Figure 15. Setups for triboelectric energy harvesting. Three possible configurations are shown: (A) flat belt-attached setup (figure inspired by Reference [246]), (B) Z-shaped connector (figure inspired by Reference [77]), and (C) movable and fixed supports (figure inspired by Reference [247]). • Electrostatic energy harvesting: It is based on the change of parameters of a capacitive device, which is called electrostatic energy harvester. Breathing may cause separation of the capacitor plates or modification of the plate area, among others [251]. This energy harvesting technique is not common in respiratory systems. The prototype of Seo et al. [248] showed a capacitor made of two metal electrodes and an insulating layer in between. The capacitance of the prototype varied with respiration. This was because the area of the top electrode was variable depending on the presence of a wet surface associated with respiration (Figure 16). Humid exhaled breath air was cooled by the ambient air on the top surface of the insulated material. Thus, the water molecules were condensed, acting as part of the upper electrode and changing the capacitance of the prototype. This condensation provided a thick layer that became part of the electrode. Then, the water naturally evaporated due to its vapor pressure and the device returned to its original status. The variable capacitance allowed the charges to circulate, harvesting electrostatic energy. The prototype presented in Reference [248] reported a generated power of 2 µW/cm2. • Pyroelectric energy harvesting: These harvesters are based on the reorientation of dipoles owing to temperature fluctuations [252]. Therefore, they need a temperature variation in time. Xue et al. [249] presented a prototype made of a pyroelectric component (metal coated PVDF film) covered with electrodes and mounted on the respirator of a mask at the location where air flows during breathing (Figure 17). The size of the prototype was 3.5 × 3.5 cm. The estimated current generated can be derived from the pyroelectric effect equation: (cid:1835)=(cid:1827)(cid:1868)(cid:3031)(cid:3021)(cid:3031)(cid:3047), (4)where I is the generated current, A in the sensing area, p is the pyroelectric coefficient (approximately 27 µC/m2 K), and dT/dt is the variation in temperature. Temperature variation is due to the difference between human body temperature and ambient temperature. It is also influenced by the transformation of water vapor into exhaled gas. The pyroelectric generator is heated by expiration and cooled by inspiration. Therefore, electricity is harvested from a change in temperature over time. Peak power reached up to 8.31 µW with an external load of 50 MΩ. \\x0cSensors 2020, 20, 5446\\n\\n25 of 84\\n\\ninspiration. Therefore, electricity is harvested from a change in temperature over time. Peak power\\nreached up to 8.31 µW with an external load of 50 MΩ.\\n\\n•\\n\\nThermoelectric energy harvesting: These harvesters are based on the Seebeck eﬀect. They convert\\na temperature gradient into electric power. Therefore, they need a temperature variation in\\nspace [253]. A thermoelectric module is an array of p-type and n-type semiconductors. According\\nto Nozariasbmarz et al. [252], the conversion eﬃciency of a thermoelectric generator can be\\ncalculated as:\\n\\nη =\\n\\nTH − TC\\nTH\\n\\n(cid:112)\\n\\n(cid:112)\\n\\n(1 + ZT) − 1\\n(1 + ZT) + TC/TH\\n\\n,\\n\\n(5)\\n\\nwhere TC and TH are the temperature of the cold and hot sides, respectively. ZT is the dimensionless\\nﬁgure of merit for the thermoelectric module. For the thermoelectric material, ZT can be calculated\\naccording to:\\n\\nZT =\\n\\nT,\\n\\n(6)\\n\\ns2σ\\nk\\n\\nwhere s is the Seebeck coeﬃcient, σ is the electrical conductivity, k is the thermal conductivity, and T is\\nthe absolute temperature.\\n\\nThermoelectric energy harvesters are not usually considered to power respiratory sensors. In the\\nreview of Nozariabsbmarz et al. [252], it was reported that several generators used the heat from the\\nwrist for thermoelectric power generation.\\n\\n•\\n\\nSolar cells: This technology has been also used to power respiratory sensing systems. The energy\\nproduced by the solar cells is stored in a battery through a charge regulator that also controls the\\ndischarge of the battery to power the sensing system. The charge regulator controls that both the\\nbattery and the sensing system are supplied with adequate voltage and current levels. Figure 18\\nshows an example of sensing system powered by solar cells. Solar-powered systems have not\\nbeen extensively explored in existing studies. As an exception, the work of Gorgutsa et al. [84]\\npresented a Received Signal Strength Indicator through standard Bluetooth protocol using a\\nhybrid-spiral antenna made of multi-material ﬁbers. The system was integrated into a cotton shirt.\\nThey used a low-power Bluetooth module that was powered by a rechargeable battery and a solar\\ncell on a custom printed circuit board.\\n\\nFigure 16. Electrostatic energy harvesting based on the variation of the area of the upper electrode\\nowing to humidity of the exhaled air (ﬁgure inspired by Reference [248]).\\n\\nSensors 2020, 20, x FOR PEER REVIEW 25 of 89  • Thermoelectric energy harvesting: These harvesters are based on the Seebeck effect. They convert a temperature gradient into electric power. Therefore, they need a temperature variation in space [253]. A thermoelectric module is an array of p-type and n-type semiconductors. According to Nozariasbmarz et al. [252], the conversion efficiency of a thermoelectric generator can be calculated as: (cid:2015)=(cid:3021)(cid:3257)(cid:2879)(cid:3021)(cid:3252)(cid:3021)(cid:3257)(cid:3493)((cid:2869)(cid:2878)(cid:3027)(cid:3021))(cid:2879)(cid:2869)(cid:3493)((cid:2869)(cid:2878)(cid:3027)(cid:3021))(cid:2878)(cid:3021)(cid:3252)(cid:3021)(cid:3257)⁄, (5)where TC and TH are the temperature of the cold and hot sides, respectively. ZT is the dimensionless figure of merit for the thermoelectric module. For the thermoelectric material, ZT can be calculated according to: (cid:1852)(cid:1846)=(cid:3046)(cid:3118)(cid:3097)(cid:3038)(cid:1846), (6)where s is the Seebeck coefficient, σ is the electrical conductivity, k is the thermal conductivity, and T is the absolute temperature. Thermoelectric energy harvesters are not usually considered to power respiratory sensors. In the review of Nozariabsbmarz et al. [252], it was reported that several generators used the heat from the wrist for thermoelectric power generation. • Solar cells: This technology has been also used to power respiratory sensing systems. The energy produced by the solar cells is stored in a battery through a charge regulator that also controls the discharge of the battery to power the sensing system. The charge regulator controls that both the battery and the sensing system are supplied with adequate voltage and current levels. Figure 18 shows an example of sensing system powered by solar cells. Solar-powered systems have not been extensively explored in existing studies. As an exception, the work of Gorgutsa et al. [84] presented a Received Signal Strength Indicator through standard Bluetooth protocol using a hybrid-spiral antenna made of multi-material fibers. The system was integrated into a cotton shirt. They used a low-power Bluetooth module that was powered by a rechargeable battery and a solar cell on a custom printed circuit board.  Figure 16. Electrostatic energy harvesting based on the variation of the area of the upper electrode owing to humidity of the exhaled air (figure inspired by Reference [248]).  \\x0cSensors 2020, 20, 5446\\n\\n26 of 84\\n\\nFigure 17. Schematic of a pyroelectric energy harvester using a mask-mounted breathing prototype\\n(ﬁgure inspired by Reference [253]).\\n\\nFigure 18. Example of a solar-powered system composed of a solar module, a charge regulator and\\na microcontroller. The voltage regulator receives an input voltage from the solar cell in the range of\\n0.3 V to 6 V. The charge regulator manages the charge of the battery (at constant voltage and current).\\nThe battery is connected in parallel to the internal voltage regulator of the microcontroller of the system.\\n\\n(2) Battery-Powered Systems\\n\\nBattery-powered systems require, at least, a battery and a charger. These two elements should be\\nconsidered in the sizing of the system. Batteries are usually one of the most limiting components in\\nterms of space (Figure 19).\\n\\nFigure 19. Charge regulator and battery (low capacity, 150 mAh) integrated into the sensing prototype\\ndeveloped by Vanegas et al. [254], slightly modiﬁed. The sensor used in that prototype (a force-sensitive\\nresistor) is included separately for size comparison. Units: cm.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 25 of 89  • Thermoelectric energy harvesting: These harvesters are based on the Seebeck effect. They convert a temperature gradient into electric power. Therefore, they need a temperature variation in space [253]. A thermoelectric module is an array of p-type and n-type semiconductors. According to Nozariasbmarz et al. [252], the conversion efficiency of a thermoelectric generator can be calculated as: (cid:2015)=(cid:3021)(cid:3257)(cid:2879)(cid:3021)(cid:3252)(cid:3021)(cid:3257)(cid:3493)((cid:2869)(cid:2878)(cid:3027)(cid:3021))(cid:2879)(cid:2869)(cid:3493)((cid:2869)(cid:2878)(cid:3027)(cid:3021))(cid:2878)(cid:3021)(cid:3252)(cid:3021)(cid:3257)⁄, (5)where TC and TH are the temperature of the cold and hot sides, respectively. ZT is the dimensionless figure of merit for the thermoelectric module. For the thermoelectric material, ZT can be calculated according to: (cid:1852)(cid:1846)=(cid:3046)(cid:3118)(cid:3097)(cid:3038)(cid:1846), (6)where s is the Seebeck coefficient, σ is the electrical conductivity, k is the thermal conductivity, and T is the absolute temperature. Thermoelectric energy harvesters are not usually considered to power respiratory sensors. In the review of Nozariabsbmarz et al. [252], it was reported that several generators used the heat from the wrist for thermoelectric power generation. • Solar cells: This technology has been also used to power respiratory sensing systems. The energy produced by the solar cells is stored in a battery through a charge regulator that also controls the discharge of the battery to power the sensing system. The charge regulator controls that both the battery and the sensing system are supplied with adequate voltage and current levels. Figure 18 shows an example of sensing system powered by solar cells. Solar-powered systems have not been extensively explored in existing studies. As an exception, the work of Gorgutsa et al. [84] presented a Received Signal Strength Indicator through standard Bluetooth protocol using a hybrid-spiral antenna made of multi-material fibers. The system was integrated into a cotton shirt. They used a low-power Bluetooth module that was powered by a rechargeable battery and a solar cell on a custom printed circuit board.  Figure 16. Electrostatic energy harvesting based on the variation of the area of the upper electrode owing to humidity of the exhaled air (figure inspired by Reference [248]).  Sensors 2020, 20, x FOR PEER REVIEW 26 of 89  Figure 17. Schematic of a pyroelectric energy harvester using a mask-mounted breathing prototype (figure inspired by Reference [253]).  Figure 18. Example of a solar-powered system composed of a solar module, a charge regulator and a microcontroller. The voltage regulator receives an input voltage from the solar cell in the range of 0.3 V to 6 V. The charge regulator manages the charge of the battery (at constant voltage and current). The battery is connected in parallel to the internal voltage regulator of the microcontroller of the system. (2) Battery-Powered Systems Battery-powered systems require, at least, a battery and a charger. These two elements should be considered in the sizing of the system. Batteries are usually one of the most limiting components in terms of space (Figure 19).  Figure 19. Charge regulator and battery (low capacity, 150 mAh) integrated into the sensing prototype developed by Vanegas et al. [254], slightly modified. The sensor used in that prototype (a force-sensitive resistor) is included separately for size comparison. Units: cm. Power autonomy determines the viability of a system. The autonomy of a battery-powered respiration sensing system is obtained by calculating or measuring its battery life, which is defined as the time that a system can operate with a fully charged battery. Two different factors must be determined when performing tests to measure battery life: system operating mode and the way of measuring battery life.    Solar cell Charge  Battery Microcontroller regulator  Sensors 2020, 20, x FOR PEER REVIEW 26 of 89  Figure 17. Schematic of a pyroelectric energy harvester using a mask-mounted breathing prototype (figure inspired by Reference [253]).  Figure 18. Example of a solar-powered system composed of a solar module, a charge regulator and a microcontroller. The voltage regulator receives an input voltage from the solar cell in the range of 0.3 V to 6 V. The charge regulator manages the charge of the battery (at constant voltage and current). The battery is connected in parallel to the internal voltage regulator of the microcontroller of the system. (2) Battery-Powered Systems Battery-powered systems require, at least, a battery and a charger. These two elements should be considered in the sizing of the system. Batteries are usually one of the most limiting components in terms of space (Figure 19).  Figure 19. Charge regulator and battery (low capacity, 150 mAh) integrated into the sensing prototype developed by Vanegas et al. [254], slightly modified. The sensor used in that prototype (a force-sensitive resistor) is included separately for size comparison. Units: cm. Power autonomy determines the viability of a system. The autonomy of a battery-powered respiration sensing system is obtained by calculating or measuring its battery life, which is defined as the time that a system can operate with a fully charged battery. Two different factors must be determined when performing tests to measure battery life: system operating mode and the way of measuring battery life.    Solar cell Charge  Battery Microcontroller regulator  \\x0cSensors 2020, 20, 5446\\n\\n27 of 84\\n\\nPower autonomy determines the viability of a system. The autonomy of a battery-powered\\nrespiration sensing system is obtained by calculating or measuring its battery life, which is deﬁned\\nas the time that a system can operate with a fully charged battery. Two diﬀerent factors must be\\ndetermined when performing tests to measure battery life: system operating mode and the way of\\nmeasuring battery life.\\n\\nRegarding system operating mode, there are essentially two diﬀerent approaches:\\n\\n•\\n•\\n\\nContinuous operation: Battery life is measured with the breathing device operating continuously.\\nContinuous operation + inactivity periods: A typical daily use of the system is considered, which may\\ninclude certain inactivity periods in which the device is in “idle” mode or even oﬀ (not used).\\n\\nRegarding the way of measuring battery life, it should be noticed that it depends on the type of\\nbattery used and its parameters. The main parameter of a battery is its capacity, which determines\\nthe nominal amount of charge that can be stored. It is usually expressed in mAh. As a general rule,\\nthe higher the capacity, the longer the battery life. However, capacity depends on several external\\nfactors, such as discharge rate, operating temperature, aging, and state of charge (SOC). When a battery\\nis discharged at low rate (low current), the energy is delivered more eﬃciently. Higher discharge\\nrates (higher currents demanded by the breathing system) lead to a reduction in eﬀective battery\\ncapacity [255]. Temperature also aﬀects battery capacity in such a way that low temperatures decrease\\ncapacity. Aging may also decrease the capacity [256]. If a battery is not full, the state of charge (SOC)\\nmust also be considered. It represents the percentage of capacity that is currently available with respect\\nto the rated capacity.\\n\\nThe most common and sensible approach is that tests are conducted with a new fully-charged\\nbattery that operates in the nominal temperature range and discharges within the nominal current\\nrange. Under these conditions, the nominal capacity of the battery can be considered its true capacity.\\nOtherwise, diﬀerent reduction factors (<1) should be applied to rated capacity. Therefore, diﬀerent\\nways to measure battery life experimentally can be found in existing studies:\\n\\n• Measure of battery life directly: A battery can be considered discharged when the voltage drops\\nbelow a certain value (3.6 V [257] for common small batteries). Therefore, by taking a full battery\\nand monitoring the output voltage, it is possible to obtain battery life with expression (7).\\n\\nBatteryLi f e (h) = InitialTime − DischargeTime.\\n\\n(7)\\n\\n• Measure of current consumption: Current consumption of the respiratory sensing system can be\\nmeasured experimentally or estimated from the datasheets of the system components. The formula\\nfor calculating battery life is diﬀerent for each operation mode:\\n\\nContinuous operation: The system is assumed to operate continuously consuming an average\\ncurrent value.\\n\\n(cid:35)\\n\\nBatery Li f e (h) =\\n\\nCapacity(mAh)·SOC f actor\\n\\n·C f actor\\n\\n·Ta f actor\\n\\n·Age f actor\\n\\nOC (mA)\\n\\n,\\n\\n(8)\\n\\n∈ R[0, 1] are reduction factors of the capacity to\\nwhere SOC f actor, C f actor, Ta f actor, Age f actor\\nbe applied in case tests are not performed under the optimal conditions mentioned above,\\nand OC is the average value of the operating current.\\nContinuous operation + inactivity periods (rough estimate): Current consumption in the\\noperation and inactivity periods is assumed to be “constant”.\\n\\n(cid:35)\\n\\nBatery Li f e (h) =\\n\\nCapacity(mAh)·SOC f actor\\n\\nOC (mAh)· nminOC\\nnmintotal\\n\\n·Ta f actor\\n\\n·C f actor\\n+ IC (mAh) nminIC\\nnmintotal\\n\\n·Age f actor\\n\\n,\\n\\n(9)\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n28 of 84\\n\\n(cid:35)\\n\\nwhere IC(mAh) is the average value of current consumed by the system in idle or non-active\\nmodes, nminoc is the number of minutes that the breathing system is in operation mode\\nduring a certain period of time (for instance, one day), nminIc is the number of minutes\\nthat the breathing system is in idle or non-active modes for the same time period,\\nand nmintotal = nminOC + nminIC.\\nContinuous operation + inactivity periods (ﬁne estimate): The calculation of battery life\\nis performed using a more accurate model. Diﬀerent values of current consumption\\nare considered in operation and inactivity modes.\\nIn this calculation, the system\\ncan adopt not only two states, but n states. Let c = [c1, c2, . . . , cn] be the average\\ncurrent values of each of the n diﬀerent states of the respiratory system considered,\\nand nmin = [nmin1, nmin2, . . . , nminn] the number of minutes in a given period of time\\n(for instance, one day) that the breathing system remains in each state of the n possible\\nstates. The calculation can be done with Equation (10).\\n\\nBatery Li f e (h) =\\n\\nCapacity(mAh)·SOC f actor\\n·\\n\\n(cid:80)n\\n\\ni=1 ci\\n\\n(cid:80)n\\n\\n·C f actor\\nnmini\\nj=1 nmin j\\n\\n·Ta f actor\\n\\n·Age f actor\\n\\n.\\n\\n(10)\\n\\n3.2.2. Results of the Analysis\\n\\nThe previously described items were analyzed for the studies found as a result of the systematic\\nreview. These items were the use of wired or wireless data transmission, the performance of centralized\\nor remote processing, the speciﬁc station used to carry out processing and the energy autonomy of the\\nprototypes. They were studied for the wearable category as these elements are limiting in non-contact\\nsensing systems. However, they are less crucial in environmental systems, since most of them use\\nwired communications and are connected to a power source.\\n\\nTable 4 shows a comparison of the approaches found in the state of the art for the wearable\\ngroup. The ﬁrst two columns of Table 4 show the speciﬁc studies that used wired and wireless data\\ntransmission, and Figure 20 presents the percentage distribution of the type of transmission. The use\\nof wired and wireless technologies was similar.\\n\\nTable 4. Analysis of transmission technology, processing station, and energy autonomy for studies in\\nthe wearable category.\\n\\nStudy 1\\n\\nWireless\\nTransmission\\n\\nWired\\nTransmission\\n\\nProcessing\\nStation\\n\\nBattery\\nCapacity\\n\\nBattery Life\\n(Type Battery)\\n\\nAitkulov 2019 [57,58]\\n\\n-\\n\\nData storage\\n\\n-\\n\\nBalasubramaniyam\\n2019 [59]\\n\\nInternet\\nconnection\\n\\nBricout 2019 [60]\\n\\n-\\n\\nChu 2019 [61]\\n\\nBluetooth\\n\\nElfaramawy 2019 [62]\\n\\nRadio-frequency\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nFajkus 2019 [63]\\n\\nHurtado 2019 [64]\\n\\nJayarathna 2019 [65]\\n\\n-\\n\\n-\\n\\nBluetooth\\n(low energy),\\nSD card\\n\\nKano 2019 [66]\\n\\nBluetooth\\n\\nInterrogator\\nDAQ (data\\nacquisition)\\n\\n-\\n\\n-\\n\\n-\\n\\nCloud storage,\\nPC,\\nSmartphone\\n\\n-\\n\\nPC\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n3.7 V, 100 mAh\\n\\n6 h\\n(Li-ion battery)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nPC,\\nsmartphone,\\ncloud Storage\\n\\n600 mAh\\n\\n5 days\\n(Li-ion battery)\\n\\nSmartphone\\n\\n3 V\\n\\n(Cell battery)\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n29 of 84\\n\\nStudy 1\\n\\nWireless\\nTransmission\\n\\nWired\\nTransmission\\n\\nTable 4. Cont.\\n\\nKaracocuk 2019 [67]\\n\\nBluetooth\\n\\nMassaroni 2019 [68]\\n\\nBluetooth\\n\\nMassaroni 2019 [69]\\n\\nBluetooth\\n\\nNguyen 2019 [70]\\n\\nPresti 2019 [71]\\n\\nPresti 2019 [72]\\n\\n-\\n\\n-\\n\\n-\\n\\nPuranik 2019 [73]\\n\\nWi-Fi\\n\\nSoomro 2019 [74]\\n\\nXiao 2019 [75]\\n\\nYuasa 2019 [76]\\n\\nZhang 2019 [77]\\n\\nDan 2018 [78]\\n\\nKoyama 2018 [79]\\n\\nMalik 2018 [80]\\n\\nMartin 2018 [81]\\n\\nPang 2018 [82]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nInterrogator\\n\\nInterrogator\\n\\n-\\n\\nUSB\\n\\n-\\n\\nUSB\\n\\n-\\n\\n-\\n\\nInterrogator\\nDAQ\\n\\nDAQ\\n\\n-\\n\\n-\\n\\nProcessing\\nStation\\n\\nPC,\\nsmartphone\\n\\nBattery\\nCapacity\\n\\nBattery Life\\n(Type Battery)\\n\\n-\\n\\n-\\n\\nPC\\n\\n-\\n\\n-\\n\\nPC\\n\\nPC\\n\\n-\\n\\nPC,\\nsmartphone\\n\\nPC\\n\\nSmartphone\\n\\nSmartphone,\\nPC\\n\\n-\\n\\nPC\\n\\n-\\n\\nPC\\n\\n-\\n\\n3.6 V, 650 mAh\\n\\n8 h (Li-polymer\\nbattery)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n3.7 V, 1020 mAh\\n\\n(Li-ion battery)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n1 Note: The analysis for studies published before 2018 [2,3,17,21,49,83–162] is included in Appendix A (Table A3).\\n\\nFigure 20. Number of studies adopting wired or wireless data transmission in respiration\\nsensing systems.\\n\\nFigure 21 shows the distribution of wireless technologies used for data transmission. Bluetooth\\nwas the preferred technology, as it is suitable for applications that send point-to-point information\\nover relatively short distances and require high-speed data transmission. Its main drawback is power\\nconsumption, which could be a limitation for continuous monitoring, as existing studies state that\\nthe battery life is not more than a few hours. However, in view of Table 4, this method seems\\nsuitable for many applications. Wi-Fi, radio frequency, or Zigbee were used in a limited number of\\nstudies [73,96,144,156,159]. Regarding wired transmission, third column of Table 4 shows that USB\\ncommunication was the preferred option [74,76,86–88,109,114,118,133,141,158].\\n\\nSensors 2020, 20, x FOR PEER REVIEW 29 of 89  Presti 2019 [71] - Interrogator PC - - Presti 2019 [72] - Interrogator PC - - Puranik 2019 [73] Wi-Fi - - 3.7 V, 1020 mAh (Li-ion battery) Soomro 2019 [74] - USB PC, smartphone - - Xiao 2019 [75] - - PC - - Yuasa 2019 [76] - USB Smartphone - - Zhang 2019 [77] - - Smartphone, PC - - Dan 2018 [78] - - - - - Koyama 2018 [79] - Interrogator DAQ PC - - Malik 2018 [80] - DAQ - - - Martin 2018 [81] - - PC - - Pang 2018 [82] - - - - - 1 Note: The analysis for studies published before 2018 [2,3,17,21,49,83–162]  is included in Appendix A (Table A3).  Figure 20. Number of studies adopting wired or wireless data transmission in respiration sensing systems. Figure 21 shows the distribution of wireless technologies used for data transmission. Bluetooth was the preferred technology, as it is suitable for applications that send point-to-point information over relatively short distances and require high-speed data transmission. Its main drawback is power consumption, which could be a limitation for continuous monitoring, as existing studies state that the battery life is not more than a few hours. However, in view of Table 4, this method seems suitable for many applications. Wi-Fi, radio frequency, or Zigbee were used in a limited number of studies [73,96,144,156,159]. Regarding wired transmission, third column of Table 4 shows that USB communication was the preferred option [74,76,86–88,109,114,118,133,141,158]. Wireless, 40Wired, 43Not Specified, 23\\x0cSensors 2020, 20, 5446\\n\\n30 of 84\\n\\nFigure 21. Number of respiratory monitoring studies that considered diﬀerent\\ncommunication technologies.\\n\\ntypes of\\n\\nOnce measurements are transmitted, a main station processes them. Figure 22 shows the\\npercentage distribution of the processing stations used in the studies selected in the systematic\\nsearches. PCs were the preferred processing stations, showing that most authors performed centralized\\nprocessing, while the use of smartphones, tablets or cloud computing was not so common [2,59,65–67,\\n74,76,77,84,91,98,99,101,102,107,109,116,119,122,130,132,134,143,144,156], although they were found in\\n30% of studies.\\n\\nFigure 22. Number of studies adopting the diﬀerent processing units.\\n\\nRegarding energy autonomy of systems, the use of energy harvesters was residual [84,104],\\nwhich can be due to the fact that studies presented complete systems that included data transmission\\nand processing modules. These modules are energy demanding, and therefore the use of energy\\nharvesters can only be used as a complement, but not as the primary power source.\\nIn this\\nregard, many studies [2,3,17,62,65,73,84,86,87,89,91,98,99,101,114–116,119,131,144,145,147,162] used\\nrechargeable batteries to power the systems. The most common declared battery lives were in the\\norder of hours (Figure 23) [2,17,62,69,101,115,119], although some studies did not even provide data\\non this point.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 30 of 89   Figure 21. Number of respiratory monitoring studies that considered different types of communication technologies. Once measurements are transmitted, a main station processes them. Figure 22 shows the percentage distribution of the processing stations used in the studies selected in the systematic searches. PCs were the preferred processing stations, showing that most authors performed centralized processing, while the use of smartphones, tablets or cloud computing was not so common [2,59,65–67,74,76,77,84,91,98,99,101,102,107,109,116,119,122,130,132,134,143,144,156], although they were found in 30% of studies.  Figure 22. Number of studies adopting the different processing units. Regarding energy autonomy of systems, the use of energy harvesters was residual [84,104], which can be due to the fact that studies presented complete systems that included data transmission and processing modules. These modules are energy demanding, and therefore the use of energy harvesters can only be used as a complement, but not as the primary power source. In this regard, many studies [2,3,17,62,65,73,84,86,87,89,91,98,99,101,114–116,119,131,144,145,147,162] used rechargeable batteries to power the systems. The most common declared battery lives were in the order of hours (Figure 23) [2,17,62,69,101,115,119], although some studies did not even provide data on this point. 0510152025Number of studies0102030405060Number of studiesSensors 2020, 20, x FOR PEER REVIEW 30 of 89   Figure 21. Number of respiratory monitoring studies that considered different types of communication technologies. Once measurements are transmitted, a main station processes them. Figure 22 shows the percentage distribution of the processing stations used in the studies selected in the systematic searches. PCs were the preferred processing stations, showing that most authors performed centralized processing, while the use of smartphones, tablets or cloud computing was not so common [2,59,65–67,74,76,77,84,91,98,99,101,102,107,109,116,119,122,130,132,134,143,144,156], although they were found in 30% of studies.  Figure 22. Number of studies adopting the different processing units. Regarding energy autonomy of systems, the use of energy harvesters was residual [84,104], which can be due to the fact that studies presented complete systems that included data transmission and processing modules. These modules are energy demanding, and therefore the use of energy harvesters can only be used as a complement, but not as the primary power source. In this regard, many studies [2,3,17,62,65,73,84,86,87,89,91,98,99,101,114–116,119,131,144,145,147,162] used rechargeable batteries to power the systems. The most common declared battery lives were in the order of hours (Figure 23) [2,17,62,69,101,115,119], although some studies did not even provide data on this point. 0510152025Number of studies0102030405060Number of studies\\x0cSensors 2020, 20, 5446\\n\\n31 of 84\\n\\nFigure 23. Distribution of battery lives reported in the respiratory monitoring studies.\\n\\nThere were a set of studies focused on minimizing power consumption. They included low power\\ndata transmission technologies. In this regard, Milici et al. used wireless transponders [91] to obtain\\nautonomy of more than one year, while Mahbub et al. [98] adopted Impulse Radio Ultra-Wideband\\n(IR UWB), which led to an autonomy of about 40 days. In general, battery live is highly dependent on\\ntransmission technology. The works of Bhattacharya et al. [156], Puranik et al. [73], White et al. [96],\\nCiobotariu et al. [144], and Mitchell et al. [159] used wearable devices with Wi-Fi [73,96,144,156],\\nZigbee [159], or GSM/GPRS [144], with high variability in power consumption.\\n\\n3.3. Validation Experiments\\n\\n3.3.1. Items of Analysis\\n\\nDiﬀerent items were considered to analyze the validation experiments carried out in the studies:\\n\\n•\\n\\nSubjects: Almost all studies used volunteers to assess the respiration sensing systems. In this\\ncase, it is required to provide data, such as the number of subjects who participated in the tests\\nand their main characteristics (age, weight, height, sex, and health status). As breathing studies\\ngenerally involve humans, it is mandatory to have the approval of the competent ethical committee\\n(following the Declaration of Helsinki [258]) to recruit the subjects to participate in the study,\\nto inform them about the study, and to obtain their consent.\\n\\n• Activities/positions: This item refers to the speciﬁc activities or positions that volunteers who\\nparticipate in the tests are asked to perform as part of the validation experiments. The most\\ncommon positions adopted in existing studies are represented in Figure 24 with an example sensor.\\n\\n• Whether or not motion artifacts are included in the diﬀerent activities.\\n• Number and values of RRs or volume rates to be tested in the experiments.\\n• Number of repetitions of the diﬀerent test scenarios.\\n•\\n\\nDuration: The designed tests (activities and positions, number of RRs or volume rates, and number\\nof repetitions) determine the duration of the experiments.\\nExperiment design: This item refers to the strategies adopted to validate the breathing sensors.\\nThree main methods have been found in the state of the art (Figure 25):\\n\\n•\\n\\nSensors 2020, 20, x FOR PEER REVIEW 31 of 89   Figure 23. Distribution of battery lives reported in the respiratory monitoring studies. There were a set of studies focused on minimizing power consumption. They included low power data transmission technologies. In this regard, Milici et al. used wireless transponders [91] to obtain autonomy of more than one year, while Mahbub et al. [98] adopted Impulse Radio Ultra-Wideband (IR UWB), which led to an autonomy of about 40 days. In general, battery live is highly dependent on transmission technology. The works of Bhattacharya et al. [156], Puranik et al. [73], White et al. [96], Ciobotariu et al. [144], and Mitchell et al. [159] used wearable devices with Wi-Fi [73,96,144,156], Zigbee [159], or GSM/GPRS [144], with high variability in power consumption. 3.3. Validation Experiments 3.3.1. Items of Analysis Different items were considered to analyze the validation experiments carried out in the studies: • Subjects: Almost all studies used volunteers to assess the respiration sensing systems. In this case, it is required to provide data, such as the number of subjects who participated in the tests and their main characteristics (age, weight, height, sex, and health status). As breathing studies generally involve humans, it is mandatory to have the approval of the competent ethical committee (following the Declaration of Helsinki [258]) to recruit the subjects to participate in the study, to inform them about the study, and to obtain their consent.  • Activities/positions: This item refers to the specific activities or positions that volunteers who participate in the tests are asked to perform as part of the validation experiments. The most common positions adopted in existing studies are represented in Figure 24 with an example sensor. • Whether or not motion artifacts are included in the different activities. • Number and values of RRs or volume rates to be tested in the experiments.  • Number of repetitions of the different test scenarios. • Duration: The designed tests (activities and positions, number of RRs or volume rates, and number of repetitions) determine the duration of the experiments. • Experiment design: This item refers to the strategies adopted to validate the breathing sensors. Three main methods have been found in the state of the art (Figure 25): < 12 h12 to 24 h1 to 7 days7 days to 1 month> 1 month <1 year>1 year\\x0cSensors 2020, 20, 5446\\n\\n32 of 84\\n\\nFigure 24. Common positions/activities to validate the breathing sensors (sitting, standing, lying down,\\nwalking, running, and sleeping). Chest sensor used as an example.\\n\\nArtiﬁcial validation prototypes: Some studies used artiﬁcial prototypes that emulated human\\nconditions rather than real volunteers. On the one hand, if the sensor were worn on the chest, diaphragm,\\nor thorax, a mechanical structure that emulated human respiration could serve for validation. That was\\nthe approach adopted by Padasdao et al. [135]: a motor moved a mechanical chest to the rhythm and\\ndepth of human breathing (Figure 25A). Similarly, the work of Witt et al. [141] also used a mechanical\\nchest driven by a stepper motor, setting the amplitude and frequency of the movements to simulate\\nbreathing activity. Another set of works [77,94,110,114,146] used machines or custom prototypes\\nthat applied traction and compression movements to simulate human respiration on strain sensors.\\nOn the other hand, if the system is to be worn in the nose or mouth, an artiﬁcial prototype can be\\nbuilt that emulates the airﬂow associated with respiration. For that, Agcayazi et al. [123] used a\\nmannequin equipped with an inﬂatable cuﬀ bladder that emulated breathing cycles, which is similar\\nto the prototype of Koch et al. [90]. For humidity sensors, authors designed controlled humidity\\nchambers using humidiﬁers and dry air compressors [74] or switches for controlling nitrogen ﬂow\\nand a motor to control the dispersion of water vapor [97]. Finally, other studies presented artiﬁcial\\n\\nSensors 2020, 20, x FOR PEER REVIEW 32 of 89   Figure 24. Common positions/activities to validate the breathing sensors (sitting, standing, lying down, walking, running, and sleeping). Chest sensor used as an example. Artificial validation prototypes: Some studies used artificial prototypes that emulated human conditions rather than real volunteers. On the one hand, if the sensor were worn on the chest, diaphragm, or thorax, a mechanical structure that emulated human respiration could serve for validation. That was the approach adopted by Padasdao et al. [135]: a motor moved a mechanical chest to the rhythm and depth of human breathing (Figure 25A). Similarly, the work of Witt et al. [141] also used a mechanical chest driven by a stepper motor, setting the amplitude and frequency of the movements to simulate breathing activity. Another set of works [77,94,110,114,146] used machines or custom prototypes that applied traction and compression movements to simulate human respiration on strain sensors. On the other hand, if the system is to be worn in the nose or mouth, an artificial prototype can be built that emulates the airflow associated with respiration. For that, Agcayazi et al. [123] used a mannequin equipped with an inflatable cuff bladder that emulated breathing cycles, which is similar to the prototype of Koch et al. [90]. For humidity sensors, authors designed controlled humidity chambers using humidifiers and dry air compressors [74] or switches for controlling nitrogen flow and a motor to control the dispersion of water vapor [97]. Finally, other studies presented artificial validation prototypes adapted to the specific sensors used for respiration \\x0cSensors 2020, 20, 5446\\n\\n33 of 84\\n\\nvalidation prototypes adapted to the speciﬁc sensors used for respiration monitoring. Zito et al. [226]\\nvalidated a radar sensor with a moving target that emulated the movements associated with breathing.\\n\\nFigure 25. Representation of diﬀerent validation approaches: (A) use of artiﬁcial validation prototypes,\\n(B) validation using a metronome, and (C) validation using a reference device.\\n\\nValidation using artiﬁcial prototypes has the advantage that diﬀerent respiration or volume rates\\ncan be programmed precisely. These theoretical values can be compared with the measurements\\nobtained with the sensor. Thus, no error can be attributed to the validation method. A typical validation\\nworkﬂow using this method is outlined in Figure 26. In this method, sensor measurements may be\\n(cid:15)Rk×m, where k is the number of repetitions per parameter, and m is\\ncontained in matrix A =\\nthe number of diﬀerent parameter values to evaluate. This measurement matrix A can be compared\\n(cid:15)Rk×m. Matrix B contains the reference values used to program the\\nwith the reference matrix B =\\nartiﬁcial validation prototype. Therefore, all the elements in a given row have the same value as the jth\\nreference parameter (column) remains the same for all repetitions (∀i(cid:15)[1..k], row).\\n\\nbij\\n\\naij\\n\\n(cid:16)\\n\\n(cid:17)\\n\\n(cid:17)\\n\\n(cid:16)\\n\\nSensors 2020, 20, x FOR PEER REVIEW 33 of 89  monitoring. Zito et al. [226] validated a radar sensor with a moving target that emulated the movements associated with breathing.  Figure 25. Representation of different validation approaches: (A) use of artificial validation prototypes, (B) validation using a metronome, and (C) validation using a reference device. Validation using artificial prototypes has the advantage that different respiration or volume rates can be programmed precisely. These theoretical values can be compared with the measurements obtained with the sensor. Thus, no error can be attributed to the validation method. A typical validation workflow using this method is outlined in Figure 26. In this method, sensor measurements may be contained in matrix (cid:1775)=(cid:3435)(cid:1853)(cid:3036)(cid:3037)(cid:3439)(cid:2035)ℝ(cid:3038)×(cid:3040), where k is the number of repetitions per parameter, and m is the number of different parameter values to evaluate. This measurement matrix A can be compared with the reference matrix (cid:1776)=(cid:3435)(cid:1854)(cid:3036)(cid:3037)(cid:3439)(cid:2035)ℝ(cid:3038)×(cid:3040). Matrix B contains the reference values used to program the artificial validation prototype. Therefore, all the elements in a given row have the same value as the jth reference parameter (column) remains the same for all repetitions (∀(cid:1861)(cid:2035)[1..(cid:1863)], row). \\x0cSensors 2020, 20, 5446\\n\\n34 of 84\\n\\nFigure 26. Flow diagram of a typical validation procedure using artiﬁcial prototypes.\\n\\nMetronome as reference: When humans are involved in the validation experiments, one option is\\nto use a metronome to set the rate of respiration that subjects must follow during the tests (Figure 25B).\\nThe advantage of this method over artiﬁcial prototypes is that the sensing system is tested with the target\\nsubjects and not with an emulation of a human chest or throat. However, its weak point is that subjects\\nmay not accurately follow the rate of the metronome. Therefore, part of the measurement error can be\\nattributed to the test design itself rather than to the sensing system. A typical validation workﬂow using\\na metronome as a reference is summarized in Figure 27. The measurements recorded by the sensor\\n(cid:15)Rn×k×p×l×m, which is a ﬁve-dimensional\\nunder validation may be contained in matrix A =\\nmatrix with the measured values for each subject d, repetition e, activity f, position g and parameter\\n(cid:15)Rn×k×p×l×m, which contains the reference\\nvalue h. The reference to compare A is matrix B =\\nbreathing parameters set in the metronome for each subject d, repetition e, activity f, position g and\\nparameter value h. Therefore, B exclusively contains the values of vector z = [z1, z2, . . . zm], which are\\nthe possible settings for the metronome (Figure 27).\\n\\nbde f gh\\n\\nade f gh\\n\\n(cid:16)\\n\\n(cid:17)\\n\\n(cid:17)\\n\\n(cid:16)\\n\\nSensors 2020, 20, x FOR PEER REVIEW 34 of 89   Figure 26. Flow diagram of a typical validation procedure using artificial prototypes. Metronome as reference: When humans are involved in the validation experiments, one option is to use a metronome to set the rate of respiration that subjects must follow during the tests (Figure 25B). The advantage of this method over artificial prototypes is that the sensing system is tested with the target subjects and not with an emulation of a human chest or throat. However, its weak point is that subjects may not accurately follow the rate of the metronome. Therefore, part of the measurement error can be attributed to the test design itself rather than to the sensing system. A typical validation workflow using a metronome as a reference is summarized in Figure 27. The measurements recorded by the sensor under validation may be contained in matrix (cid:1775)=(cid:3435)(cid:1853)(cid:3031)(cid:3032)(cid:3033)(cid:3034)(cid:3035)(cid:3439)(cid:2035)ℝ(cid:3041)×(cid:3038)×(cid:3043)×(cid:3039)×(cid:3040), which is a five-dimensional matrix with the measured values for each subject d, repetition e, activity f, position g and parameter value h. The reference to compare A is matrix (cid:1776)=(cid:3435)(cid:1854)(cid:3031)(cid:3032)(cid:3033)(cid:3034)(cid:3035)(cid:3439)(cid:2035)ℝ(cid:3041)×(cid:3038)×(cid:3043)×(cid:3039)×(cid:3040), which contains the reference breathing parameters set in the metronome for each subject d, repetition e, activity f, position g and parameter value h. Therefore, B exclusively contains the values of vector (cid:1878)=[(cid:1878)(cid:2869),(cid:1878)(cid:2870),…(cid:1878)(cid:3040) ], which are the possible settings for the metronome (Figure 27). \\x0cSensors 2020, 20, 5446\\n\\n35 of 84\\n\\nFigure 27. Flow chart for the validation of a respiration sensor using the methods “metronome as\\nreference” and “validation against a reference device”.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 35 of 89   Figure 27. Flow chart for the validation of a respiration sensor using the methods “metronome as reference” and “validation against a reference device”. \\x0cSensors 2020, 20, 5446\\n\\n36 of 84\\n\\nValidation against a reference device: The most complete way to validate a new sensor is to\\ncompare its performance with the performance of a reference sensor considered as a gold standard\\n(Figure 25C). The reference sensor and the sensor under validation must be worn at the same time\\nto obtain synchronized measurements. Having synchronized measurements allows the sensing\\ncapabilities of both sensors to be compared fairly. The sensor under test should provide measurements\\nas close as possible to those of the reference sensor. It is important to note that the reference sensor\\nalso has a measurement error. Therefore, this error should be considered in the comparison, as it may\\ninﬂuence the results. Respiratory values provided by the reference device may diﬀer slightly from\\nreal values. This validation method faces several challenges. First, it is essential to synchronize both\\nmeasuring instrument and this synchronization can be diﬃcult. Second, most commercial products do\\nnot provide information on how the ﬁnal breathing parameter (RR or volume parameter) is obtained, so\\nthe comparison of measurements may not be obvious. In addition, most products do not allow selecting\\nthe refresh time window or do not even provide information about the length of this window, so it is\\nnot possible to know the set of measurements used to calculate the output respiration values. Figure 27\\nshows a typical block diagram of the validation method when using a reference device. The results of\\n(cid:15)Rn×k×p×l×m, which contain the\\n(cid:15)Rn×k×p×l×m and C =\\nthis validation are matrices A =\\nmeasured values for each subject d, repetition e, activity f, position g, and parameter h for the sensor\\nunder evaluation and for the reference sensor, respectively.\\n\\nade f gh\\n\\nade f gh\\n\\n(cid:16)\\n\\n(cid:17)\\n\\n(cid:16)\\n\\n(cid:17)\\n\\n3.3.2. Results of the Analysis\\n\\nTable 5 presents the results of the analysis of diﬀerent items of the validation experiments for both\\nwearable and environmental systems. Large diﬀerences among studies were observed in all aspects of\\nthe experiments: protocol, number of subjects, positions, types of breathing, duration, and inclusion of\\nmotion artifacts.\\n\\nIn relation to the number of subjects involved in the tests, 71% of the studies that provided this\\ndata included 10 subjects or less. Only 13% of the studies included more than 20 subjects [7,10,19,64,81,\\n132,135,147,173,175,211,232]. There were also a considerable number of studies (53) that did not even\\nprovide this information. A part of them did not use subjects for sensor validation.\\n\\nRegarding the duration of the experiments, most of the studies carried out short experiments of a\\nfew minutes. In fact, 58% of the studies performed tests of less than 5 minutes [69,70,81,86–88,96,100,\\n102,104,111,125,136,161,163,165,171–174,193,195,196,200,212,215,221,228,229,232]. Most of the works that\\nconducted longer tests included sleep studies [7,17,53,60,115,146,148,164,165,169,173,192,198,205,211,220,223].\\nTwenty-six studies reported that motion artifacts were considered during testing. They showed that\\nthe inclusion of motion artifacts in experiments greatly influenced sensor performance [2,9,17,53,61,62,\\n66–68,81,108,109,117,119,131,132,135,147,157,178,187,190,196,205,210,221,225]. In relation to the activities\\nor positions considered in the experiments, lying down and sitting were the most tested positions.\\nOther positions or activities, like standing, walking, moving, or running, were used in a minority of\\nstudies [2,17,21,61,62,66–68,77,79,81,91,94,101–103,108,110,111,115,118,119,124,129,131,132,135,146–149,177,\\n178,188,205,214,233,235]. Most of the studies that provided information on activities considered more\\nthan one position [2,6,9,17,21,52,53,61,62,66–68,77,79,85–88,94,102,108,110,115,118,119,124,129,131–133,135,\\n146–148,157,164,165,169,171,177,178,187,196,198,205,210,211,213,214,220,221,223,225,233,235].\\nIt was also\\ncommon to test different values of the respiration parameter (for example, RRs from 10 to 22.5 bpm in the\\nstudy of Vanegas et al. [254]).\\n\\nIn relation to the validation protocol, Figure 28 shows the distribution of the analyzed studies in\\nthe three categories introduced in Section 3.3.2: validation with an artiﬁcial prototype, metronome\\nas reference and validation against a reference device. A new category was created to cover studies\\nthat performed informal validation. It was called “human observation”, since an expert provided\\na value of the breathing parameter from direct observation of the signals recorded by the sensors.\\nFigure 28 shows that validation using a reference device was the predominant approach (adopted by\\n67% of the studies that performed validation), followed by the use of an artiﬁcial validation prototype\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n37 of 84\\n\\n(10%) [69,74,77,90,93,97,110,114,116,119,123,135,141,146,150,226]. It is also worth noting that 53 studies\\npresented the sensing systems without providing evidence of their validation.\\n\\nFigure 28. Number of studies that adopted the diﬀerent validation approaches.\\n\\nTable 5. Analysis of validation experiments for the studies in the wearable and environmental categories.\\n\\nValidation\\nParameters\\n\\nNumber of Subjects\\n\\nDuration\\n\\nActivities Considered\\n\\n1\\n\\n5\\no\\nt\\n\\n2\\n\\n0\\n1\\no\\nt\\n\\n6\\n\\n0\\n2\\no\\nt\\n\\n1\\n1\\n\\n0\\n2\\n>\\n\\nd\\ne\\nﬁ\\ni\\nc\\ne\\np\\ns\\n\\nt\\no\\nN\\n\\nn\\ni\\nm\\n5\\n<\\n\\nn\\ni\\nm\\n5\\n>\\n\\ng\\nn\\ni\\nt\\nt\\ni\\nS\\n\\ng\\nn\\ni\\nd\\nn\\na\\nt\\nS\\n\\nn\\nw\\no\\nd\\ng\\nn\\ni\\ny\\nL\\n\\ng\\nn\\ni\\np\\ne\\ne\\nl\\nS\\n\\nNumber of\\nstudies\\n\\n34\\n\\n40\\n\\n30\\n\\n22\\n\\n19\\n\\n63\\n\\n47\\n\\n34\\n\\n59\\n\\n25\\n\\n66\\n\\n16\\n\\ng\\nn\\ni\\nv\\no\\nm\\n\\n,\\n\\ng\\nn\\ni\\nn\\nn\\nu\\nr\\n\\n,\\n\\ng\\nn\\ni\\nk\\nl\\na\\nW\\n\\n28\\n\\ns\\nt\\nc\\na\\nf\\ni\\nt\\nr\\na\\nn\\no\\ni\\nt\\no\\nM\\n\\n27\\n\\n3.4. Sensor Measurement Processing\\n\\n3.4.1. Items of Analysis\\n\\nThis category includes the following items: performance evaluation, software used for the analysis,\\n\\nand processing algorithm. This section describes them in detail.\\n\\nPerformance Evaluation\\n\\nThe evaluation of sensor performance can be done using several ﬁgures of merit, such as absolute\\nerror, relative/percentage error, root mean square error, correlation factor, Bland-Altman plot, calculation\\nof accuracies, or linear regression.\\n\\nAbsolute error (∆): Diﬀerence between the value measured by the sensor under test (x) and the\\n\\nreference value (y). It is calculated according to Equation (11).\\n\\n∆ = x − y.\\n\\n(11)\\n\\nIt is more common to provide the mean absolute error (MAE) as the mean of the absolute value of\\n\\nall absolute errors:\\n\\nMAE =\\n\\n(cid:80)n\\n\\ni=1\\n\\n(cid:12)(cid:12)(cid:12)xi\\n\\n− yi\\n\\n(cid:12)(cid:12)(cid:12),\\n\\n1\\nn\\n\\n(12)\\n\\nSensors 2020, 20, x FOR PEER REVIEW 37 of 89  the studies that performed validation), followed by the use of an artificial validation prototype (10%) [69,74,77,90,93,97,110,114,116,119,123,135,141,146,150,226]. It is also worth noting that 53 studies presented the sensing systems without providing evidence of their validation.  Figure 28. Number of studies that adopted the different validation approaches. Table 5. Analysis of validation experiments for the studies in the wearable and environmental categories. Validation Parameters Number of Subjects Duration Activities Considered  1 2 to 5 6 to 10 11 to 20 >20 Not specified <5 min >5 min Sitting Standing Lying down Sleeping Walking, running, moving Motion artifacts Number of studies 34 40 30 22 19 63 47 34 59 25 66 16 28 27 3.4. Sensor Measurement Processing 3.4.1. Items of Analysis This category includes the following items: performance evaluation, software used for the analysis, and processing algorithm. This section describes them in detail. Performance Evaluation The evaluation of sensor performance can be done using several figures of merit, such as absolute error, relative/percentage error, root mean square error, correlation factor, Bland-Altman plot, calculation of accuracies, or linear regression.  Absolute error (Δ): Difference between the value measured by the sensor under test (x) and the reference value (y). It is calculated according to Equation (11).  Δ=(cid:1876)−(cid:1877). (11)It is more common to provide the mean absolute error (MAE) as the mean of the absolute value of all absolute errors:  020406080100120ArtificialvalidationprototypeMetronomeas referenceValidationagainstreferencedeviceHumanobservationOtherNo validationNumber of studies\\x0cSensors 2020, 20, 5446\\n\\n38 of 84\\n\\nwhere n is the number of measurements obtained from the sensor under test, xi the values of those\\nmeasurements, and yi the reference values associated with those measurements for the “artiﬁcial\\nvalidation prototype” method and the “metronome as reference” method or the measurements of the\\nreference device for the “validation against a reference device” method.\\n\\nRelative error (RE): Absolute error of the breathing sensor under test (∆) divided by its reference\\n(true) value (y). Thus, it provides an error value relative to the size of the breathing parameter being\\nmeasured. It can be obtained according to Equation (13). The mean of the relative errors (MRE) can be\\nobtained using Equation (14).\\n\\nRE =\\n\\n∆\\n\\ny\\n\\nMRE =\\n\\n(cid:80)n\\n\\ni=1\\n\\n1\\nn\\n\\n,\\n(cid:12)(cid:12)(cid:12)xi\\n\\n(cid:12)(cid:12)(cid:12)\\n\\n,\\n\\n− yi\\nyi\\n\\n(13)\\n\\n(14)\\n\\nwhere n, xi, and yi are the same parameters as for the MAE.\\n\\nIf the relative error is expressed as a percentage, it is called the percentage error, although many\\n\\nauthors also provide the relative error in percentage.\\n\\nRoot mean square error (RMSE): In respiration sensing studies, it is also used to compare the\\ndiﬀerence between the values measured by the sensor under analysis and the reference results. It is the\\nroot mean of these diﬀerences and can be obtained according to Equation (15).\\n\\nRMSE =\\n\\n(cid:115)\\n\\n(cid:80)n\\n\\ni=1(xi\\nn\\n\\n− yi)2\\n\\n,\\n\\n(15)\\n\\nwhere n, xi, and yi are the same parameters as for the MAE.\\n\\nCorrelation factor: It provides a measure of the relationships between the measurements taken\\nby the respiration sensor under test and the reference data. There are diﬀerent ways to calculate this\\ncorrelation factor. Pearson correlation factor is one of most extended (Equation (16)).\\n\\nγxy =\\n\\n(cid:113)\\n\\n(cid:80)\\n\\nn\\n\\nx2\\ni\\n\\n(cid:80)\\n\\n− (cid:80)\\n(cid:113)\\n\\n(cid:80)\\n\\nn\\n− ((cid:80)\\n\\nxiyi\\nxi)2\\n\\nxi\\n(cid:80)\\n\\nn\\n\\nyi\\n− ((cid:80)\\n\\ny2\\ni\\n\\n,\\n\\nyi)2\\n\\n(16)\\n\\nwhere n, xi, and yi are the same parameters as for the MAE. A correlation factor of 1 means maximum\\nagreement between measured and reference data (optimal case), while a factor of 0 means that there is\\nno relationship between the datasets.\\n\\nBland-Altman analysis: It is a graphical method to compare the measurements from the breathing\\nsensor under test with the reference breathing values. A scatter diagram is drawn with the horizontal\\n\\n) and the vertical\\naxis representing the mean between measured values and reference values (\\naxis representing the diﬀerence between those values (xi\\n− yi). In addition, a horizontal line is included\\nin the plot with the mean value of all diﬀerences. Two more horizontal lines (one upper and one lower)\\nare plotted representing the limits of agreement (±1.96 times the standard deviation of the diﬀerences).\\nThe Bland-Altman plot is useful to show relationships between the magnitude of the breathing\\nparameter and the diﬀerences between measured values. It may also help to identify systematic\\nerrors in measurements or to detect outliers, among others. This method is especially suitable for the\\nvalidation method in which the sensor under evaluation is compared to a reference device.\\n\\n(xi + yi)\\n2\\n\\nAccuracy: It is the proportion of true results with respect to the total number of samples [259].\\nIt can be used in studies of respiration sensors that identify breathing patterns within a given set of k\\npossible patterns. It can also be applied to studies that determine the value of a breathing parameter\\nwithin a discrete set of k possible values. Let x = [x1, x2, . . . , xn] be the values of the n measurements\\ntaken by a respiration sensing system or the n labels of the breathing patterns recognized by the system.\\nSuppose that, from the n diﬀerent samples, m samples are correctly identiﬁed or measured, since they\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n39 of 84\\n\\nbelong to the correct class of the k possible classes. Therefore, (n-m) samples are not classiﬁed correctly.\\nThe accuracy of the breathing system can be obtained as:\\n\\nAccuracy (%) =\\n\\nm\\nn\\n\\n·100.\\n\\n(17)\\n\\nLinear regression: It models the relationship between the values measured by the respiration\\nsensing system under test (dependent variable) and the reference measurements (independent variable)\\nby ﬁtting a linear equation. The equation to ﬁt has the form of y = a + bx, where y is the dependent\\nvariable, x is the independent variable, b is the slope of the line, and a is the intercept (value of yi\\nwhen xi = 0). This linear ﬁtting is performed using x = [x1, x2, . . . , xn], which is the set of n reference\\nvalues of the breathing parameter, and y = [y1, y2, . . . , yn], which is the set of n values of the parameter\\nmeasured by the sensing system under evaluation. In these conditions, the values of each xi and yi\\nshould be as close as possible ∀i ∈ [1..n]. This means that, if the match between the reference values\\nand the measured values was perfect, the linear model should be a line with and intercept of 0 and a\\nslope of 1.\\n\\nIn addition, the coeﬃcient of determination r2 could also be calculated to obtain what percentage\\nof the variation in the values measured by the sensing system are predictable from the variation of the\\nreference values according to Equation (18).\\n\\nr2 = 1 − SEres\\nSEy\\n\\n,\\n\\n(18)\\n\\ni=1(yi\\n\\nwhere SEy = (cid:80)n\\n− y)2 is the sum of the squares of the diﬀerence of each measured value yi with\\nrespect to the mean value of all measurements y, and SEres = (cid:80)n\\n− (a + bxi)) is the sum of the\\nsquares of the diﬀerence of each measured value yi with respect to the value predicted by the model.\\nIf SEres is small, it means that the line is a good ﬁt, and r2 will be close to 1. Otherwise, if SEres is large,\\nit means that the diﬀerence between the measured values yi and the line is large, and r2 will be close to\\n0 (bad linear ﬁt). If the breathing system measured exactly the same values as the reference system,\\nSEres would be zero and r2 would be 1, which would be the ideal case.\\n\\ni=1(yi\\n\\nAnalysis Software\\n\\nThe most common tools used to analyze the measurements recorded by the sensors are:\\n\\n• MATLAB: Popular numerical computing environment and programming language that is suitable\\nfor the implementation of algorithms, matrix operations, or data plotting, among others.\\nLabview: System engineering software for applications that require testing, measurements, control,\\nfast hardware access, and data information.\\n\\n•\\n\\n• Others: An extensive set of tools has been used in existing studies, such as Python (high-level,\\nprogramming language specially focused on facilitating code readability), R (free software\\nenvironment and programming language for statistical computing [260]), C# (general-purpose\\nprogramming language developed by Microsoft [261]), C (general-purpose programming language\\nthat supports structured programming), OpenCV (open source software library for computer vision\\nand machine learning [262]), Blynk (Internet of Things platform), Kubios HRV (heart rate variability\\nanalysis software for professionals and scientists), Audacity (free open-source audio software),\\nKinect SDK (suitable for developing gesture or voice recognition applications, using Kinect\\nsensor technology [263]), LabChart (physiological data analysis and acquisition software [264]),\\nAcqknowledge (software to measure, transform, replay and analyze data [265]), mobile/Android\\n(mobile operating system), LabWindows/CVI (software development environment specially\\nfocused on measurement applications [266]), microcontroller/microprocessor (suitable if the\\nprocessing is not done in any external software, but directly in the same microprocessor or\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n40 of 84\\n\\nmicrocontroller that controls the sensor), or custom applications (PC applications in which the\\nnative source could not be accurately determined).\\n\\nProcessing Algorithm\\n\\nA broad set of algorithms has been used to process measurements from respiration sensors such\\nas peak detection, maximum-minimum detection, detection of zero-crossings, threshold detection,\\nfrequency analysis, wavelet transform, or Kalman ﬁlter, among others. They are brieﬂy described in\\nthis subsection.\\n\\nPeak detection: It is based on the detection of peaks in the signals registered by the sensing\\nsystem (Figure 29). If no restriction is imposed regarding peak prominence, a peak can be calculated\\non a signal x = [x1, x2, . . . , xn] according to Equation (19), where n is the number of samples in the\\nsignal. However, this method is extremely sensitive to noise and ﬂuctuations (Figure 29A). To improve\\ndetection, it is possible to set a minimum surrounding number of samples (p) in which the values must\\nbe below the peak value (Equation (20)) to accept the detected peak (Figure 29B). Another option is to\\nimpose a strictly increasing slope on the p samples preceding the peak and/or a strictly descending\\nslope on the p samples after the peak (Figure 29C), according to Equation (21).\\n\\nxi−1\\n\\n< xi\\n\\n>xi+1\\n\\n∀i ∈ Z : i ∈ [1, n],\\n\\nx j\\n\\nxj−1\\n\\n< xi\\n< x j\\n\\n> xh\\n\\n∀ j ∈ Z : j ∈ [i − p, i − 1] ; ∀h ∈ Z : h ∈ [i + 1, i + p],\\n\\n∀j ∈ Z : j ∈ [i − p, i] and xh+1\\n\\n< xh\\n\\n∀h ∈ Z : h ∈ [i, i + p].\\n\\n(19)\\n\\n(20)\\n\\n(21)\\n\\nThe peak detection method to process respiration signals has several important parameters that\\ndetermine the number of detected peaks. Peaks selected according to Equations (19), (20), or (21) can be\\nclassiﬁed according to the prominence of the peak, discarding those peaks that are below a threshold\\nvalue to avoid the eﬀect of noise and ﬂuctuations. Peak prominence can be deﬁned as the vertical\\ndistance between the closest local minima (in horizontal direction) and the peak, although there are\\nother possible deﬁnitions [267]. Let y = [y1, y2, . . . , yn] be a vector containing the magnitude of all\\nlocal minima of signal x, and b = [b1, b2, . . . , bn] the position (horizontal value) of the local minima y.\\nIf ai is the position of peak i, and bk is an element of b that satisﬁes that bk = min|b − ai| (the position\\nof the local minima closest to i), then, a peak i will only be accepted if its prominence is above a set\\nthreshold (PP),\\n\\n(cid:12)(cid:12)(cid:12) < PP (Figure 29D).\\n\\n− yk\\n\\n(cid:12)(cid:12)(cid:12)xi\\n\\nAnother parameter that may be used to determine the number of peaks is the distance among\\nthem. Breathing signals are low frequency (usually less than 25 bpm [254]); therefore, a threshold\\n(TD) is generally established to discard those peaks that do not diﬀer by, at least, TD from another\\npreviously detected peak (Figure 29E). Let c =\\nbe the position of the q peaks detected\\nin a signal. A new peak candidate i, with position on the horizontal axis di, will only be accepted if\\n(cid:12)(cid:12)(cid:12)di\\n\\n(cid:12)(cid:12)(cid:12) < TD , ∀j ∈ Z : j ∈ [1, q].\\nIt is also common to discard peaks that do not reach a certain level TL (xi\\n(cid:12)(cid:12)(cid:12) < TD , ∀ j ∈ Z : j ∈ [1, q] (Figure 29G).\\n\\n< TL) (Figure 29F) or,\\nalternatively, that a new peak i is discarded if its value does not diﬀer a given threshold TV from the q\\npeaks already detected; that is, if\\n\\n(cid:104)\\nc1, c2, . . . , cq\\n\\n− xj\\n\\n− c j\\n\\n(cid:12)(cid:12)(cid:12)xi\\n\\n(cid:105)\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n41 of 84\\n\\nFigure 29. Peak detection of a sample respiration signal obtained from the public breathing dataset\\npublished in Reference [254]. (A) Peak detection of a noisy signal without ﬁltering. (B) Peak detection\\nimposing a restriction of p surrounding number of samples (in green the peak accepted). (C) Example\\nof a peak accepted (left, green peak) and a peak discarded (right, red peak) when applying the slope\\nrestriction. (D) Example of a peak reaching (green) and not reaching (red) the minimum prominence\\nlevel PP to be considered a valid peak. (E) Example of two peaks (red) not fulﬁlling the minimum\\nhorizontal distance restriction TD. (F) Example of a peak (red) not fulﬁlling the vertical minimum level\\nrestriction and two peaks that surpass level TL (green peaks). (G) Example of two peaks discarded\\n(red) for not diﬀering the imposed tidal volume (TV) level from a detected peak (green).\\n\\nMaximum-minimum detection: A popular processing technique is to identify maximum and/or\\nminimum points in the breathing signals (x). Massaroni et al. [103] used the maximum and minimum\\nvalues to obtain the respiratory period (Tr), as well as inspiratory (Ti) and expiratory (Te) time.\\nThe process for detecting maximum and minimum points is similar to peak detection.\\n\\nZero-crossings: Technique based on the detection of the crossings of a breathing signal by a “zero”\\nlevel taken as a reference. Given a respiration signal composed of n values x = [x1, x2, . . . , xn], a new\\nzero crossing at the i value is detected when inequality (22) is satisﬁed.\\n\\nxi−1\\n\\n< xi\\n\\n< xi+1\\n\\ni ∈ [1..n].\\n\\n(22)\\n\\nOne of the challenges of this method is to ﬁnd the “zero” level taken as a reference to detect the\\ncrossing. One possible option is to detect the maximum and minimum values in a speciﬁc window\\nand obtain the “zero” level as the mean of those values (max(x) + min(x))/2. However, this method\\nis sensitive to outliers (Figure 30A). A possible solution is to take the median of x as the “zero” level\\n\\nSensors 2020, 20, x FOR PEER REVIEW 40 of 89  Processing Algorithm A broad set of algorithms has been used to process measurements from respiration sensors such as peak detection, maximum-minimum detection, detection of zero-crossings, threshold detection, frequency analysis, wavelet transform, or Kalman filter, among others. They are briefly described in this subsection. Peak detection: It is based on the detection of peaks in the signals registered by the sensing system (Figure 29). If no restriction is imposed regarding peak prominence, a peak can be calculated on a signal (cid:1876)=[(cid:1876)(cid:2869),(cid:1876)(cid:2870),…,(cid:1876)(cid:3041)] according to Equation (19), where n is the number of samples in the signal. However, this method is extremely sensitive to noise and fluctuations (Figure 29A). To improve detection, it is possible to set a minimum surrounding number of samples (p) in which the values must be below the peak value (Equation (20)) to accept the detected peak (Figure 29B). Another option is to impose a strictly increasing slope on the p samples preceding the peak and/or a strictly descending slope on the p samples after the peak (Figure 29C), according to Equation (21).   Figure 29. Peak detection of a sample respiration signal obtained from the public breathing dataset published in Reference [254]. (A) Peak detection of a noisy signal without filtering. (B) Peak detection imposing a restriction of p surrounding number of samples (in green the peak accepted). (C) Example of a peak accepted (left, green peak) and a peak discarded (right, red peak) when applying the slope restriction. (D) Example of a peak reaching (green) and not reaching (red) the minimum prominence level PP to be considered a valid peak. (E) Example of two peaks (red) not fulfilling the minimum horizontal distance restriction TD. (F) Example of a peak (red) not fulfilling the vertical minimum \\x0cSensors 2020, 20, 5446\\n\\n42 of 84\\n\\n(Figure 30A). Another option is to remove 10–20% of the largest and smallest values of x, obtaining\\na subset of values y ⊆ x. Then, the “zero” level can be calculated as the mean of the maximum and\\nminimum values of y.\\n\\nFigure 30. Zero-crossings method exempliﬁed in a real signal obtain from the public breathing dataset\\nof Vanegas et al. [254]. (A) Eﬀect of the presence of outliers in the signals in the calculation of the “zero\\nlevel”. (B) Example of a signal with trends and results of applying a de-trend processing. (C) Example\\nof using diﬀerent “zero levels” in a signal with trends. (D) Example of a noisy signal with several\\nzero-crossings detected when only one of them (green) should have been considered.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 42 of 89  This technique is also sensitive to noise since the number of zero-crossings may increase in noisy signals. Figure 30D shows how noise is confused with multiple crossings at the “zero” level in a breathing signal. This can be avoided by defining a minimum distance in the horizontal direction (TD). Let (cid:1878)=(cid:3427)(cid:1878)(cid:2869),(cid:1878)(cid:2870),…,(cid:1878)(cid:3044)(cid:3431) be the positions in the horizontal axis of q detected “zero-crossings”; then, a new “zero-crossing” i with position di will only be considered if (cid:3627)(cid:1856)(cid:3036)−(cid:1878)(cid:3037)(cid:3627)<(cid:1846)(cid:1830) ,∀(cid:1862)∈ℤ:(cid:1862)∈[1,(cid:1869)].  \\x0cSensors 2020, 20, 5446\\n\\n43 of 84\\n\\nThe “zero-crossings” technique is also aﬀected by trends or biases in the measurements. Trends\\nmay be due to movement of the sensing element or movement of the subject.\\nIt is a common\\nphenomenon, especially in belt-attached breathing sensors. Figure 30B shows a real breathing signal\\nwith trends (blue curve) from a public dataset [254]. If the “zero” level is calculated on a signal with\\ntrends, many crossings may go undetected since the same “zero” level is not a valid reference for the\\nentire signal. To solve this problem, it is possible to eliminate trends in the signal by subtracting the\\nbias (Figure 30B, orange signal). Another option could be to split the signal into shorter windows and\\ncalculate a diﬀerent “zero” level for each window (Figure 30C).\\n\\nThis technique is also sensitive to noise since the number of zero-crossings may increase in noisy\\nsignals. Figure 30D shows how noise is confused with multiple crossings at the “zero” level in a\\nbreathing signal. This can be avoided by deﬁning a minimum distance in the horizontal direction (TD).\\nLet z =\\nbe the positions in the horizontal axis of q detected “zero-crossings”; then, a new\\n(cid:12)(cid:12)(cid:12)di\\n“zero-crossing” i with position di will only be considered if\\n\\n(cid:12)(cid:12)(cid:12) < TD , ∀j ∈ Z : j ∈ [1, q].\\n\\n(cid:104)\\nz1, z2, . . . , zq\\n\\n− zj\\n\\n(cid:105)\\n\\nThreshold detection: This technique is similar to “peak detection”, “maximum-minimum\\ndetection” or “zero-crossing detection”. In this case, the level to detect is not a characteristic point of\\nthe curve but a certain threshold value. The same analysis performed for the previous categories could\\nbe applied to this method.\\n\\nFrequency analysis: This category includes diﬀerent techniques that make use of frequency\\ninformation to obtain respiration parameters. The most common approach is to use the well-known\\nFourier Transform (FT). Several studies detected peaks in the spectrum of respiration signals or in\\ntheir power spectral density (PSD) to obtain the breathing parameters. This method depends on the\\ntime window (Figure 31A). To provide meaningful data, long time windows are desirable. However,\\nthis limits refresh time of the system. A compromise between accuracy and refresh time is required.\\nFigure 31A shows a breathing signal and its spectra obtained with the FT for diﬀerent refresh time\\nwindows. The example respiration signal has a frequency of 0.33 Hz (20 bpm) and a sampling frequency\\nof 50 Hz. For a 4-s time window, the maximum available resolution is Fs/N, that is, 0.25 Hz. Figure 31A\\nshows that the detected frequency is in the range of 0.25–0.5 Hz. This resolution is 0.125 Hz for the 8-s\\ntime window (frequency detected in the 0.25–0.375 Hz range) and 0.0625 Hz for the 16-s time window\\n(frequency detected in the 0.3125–0.344 Hz range). It can be seen that the wider the time window,\\nthe more accurate results are obtained using this method. However, wide time windows make it\\ndiﬃcult to apply respiration monitoring systems to critical scenarios where instantaneous values must\\nbe provided.\\n\\nThis transform is also sensitive to noise ﬂuctuations. Noise ﬂuctuations are generally of a much\\nhigher frequency than breathing signals. Therefore, it is common to pre-ﬁlter the signals to remove\\nfrequencies that exceed those of breathing activities. Figure 31B shows the frequency spectrum of a\\nreal respiration signal without ﬁltering and with digital low-pass ﬁltering. It can be seen that the peak\\nof the respiration frequency (0.33 Hz) is more separated from the rest of the spectrum values in the\\nﬁltered signal (7 units for the ﬁltered signal and 5 for the unﬁltered signal). If noise levels increased,\\nit would even be diﬃcult to distinguish the peak associated with the respiration frequency.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n44 of 84\\n\\nFigure 31. Frequency analysis of sample real respiratory signals obtained from a public dataset [254].\\n(A) Eﬀect of the time window (4 s, 8 s, and 16 s) on the frequency calculation. The true frequency is\\n0.33 Hz (3 s period) and the sampling frequency is 50 Hz. Results for the 16-s time window (Table A3,\\n0.3125–0.344 Hz) are closer to the true value. (B) Eﬀect of noise on frequency detection (noisy signal\\nand its spectrum -B.1-, ﬁltered signal and its spectrum -B.2-). (C) Example of a breathing signal with\\nlow frequency ﬂuctuations. (D) Example of a breathing signal with ﬂuctuations due to movements of\\nthe subject and its spectrum.\\n\\nOn the other hand, low frequency signal ﬂuctuations may appear due to movements in the sensing\\ndevice or movements of subjects if breathing is measured during dynamic activities, such as walking.\\nThese ﬂuctuations must be treated to provide accurate results. They can be mathematically modeled\\naccording to Equation (23).\\n\\nv(t) = A\\n\\n1 + λ sin\\n\\nsin(wt − ϕ),\\n\\n(23)\\n\\n(cid:104)\\n\\n(cid:17)(cid:105)\\n\\n(cid:16)\\n\\nw f t\\n\\nwhere w is the angular frequency of the normal breathing signal, wf represents the angular frequency of\\nthe interference-causing activity, and λ is the magnitude of that activity. Figure 31C shows an example\\n\\nSensors 2020, 20, x FOR PEER REVIEW 44 of 89   Figure 31. Frequency analysis of sample real respiratory signals obtained from a public dataset [254]. (A) Effect of the time window (4 s, 8 s, and 16 s) on the frequency calculation. The true frequency is 0.33 Hz (3 s period) and the sampling frequency is 50 Hz. Results for the 16-s time window (Table A3, 0.3125–0.344 Hz) are closer to the true value. (B) Effect of noise on frequency detection (noisy signal and its spectrum -B.1-, filtered signal and its spectrum -B.2-). (C) Example of a breathing signal with low frequency fluctuations. (D) Example of a breathing signal with fluctuations due to movements of the subject and its spectrum. \\x0cSensors 2020, 20, 5446\\n\\n45 of 84\\n\\nof a real breathing signal with low frequency ﬂuctuations. Those frequency ﬂuctuations can lead to\\npeaks at very low frequency values of the spectrum. As low-pass ﬁlters are generally applied, those\\nfrequencies would not be removed and could therefore be confused with the respiration parameter,\\nwhich is also low frequency.\\n\\nSudden movements of subjects may also cause ﬂuctuations in signals, which can aﬀect the\\nmeasurements. Figure 31D shows an example of a real respiration signal with ﬂuctuations due to\\nmovements during acquisition tests. The bottom of Figure 31D shows its spectrum with a peak in the\\nrespiration frequency and other lower peaks (in red) at close frequencies due to signal ﬂuctuations.\\n\\nOther studies have also obtained breathing parameters from frequency using frequency modulation\\n\\n(FM) or amplitude modulation (AM).\\n\\nWavelet transform: It is used to decompose the breathing signal in such a way that a new\\nrepresentation can be obtained that allows a better detection of respiration peaks or crossings. It has\\nbeen used in the continuous or in the discrete form [268]. In the continuous wavelet transform (CWT)\\na comparison is made between the respiration signal and an analyzing wavelet ψ. The wavelet is\\nshifted by applying a dilation factor (b) and is compressed or stretched by applying a scale factor (a).\\nTherefore, the CWT can be calculated according to Equation (24).\\n\\nCWT(a, b) =\\n\\n(cid:90) ∞\\n\\n−∞\\n\\nx(t)ψ∗\\nab\\n\\n(t)dt,\\n\\n(24)\\n\\nwhere x(t) is the breathing signal under analysis, and ∗ denotes the complex conjugate [269]. The scale\\nfactor (a) has an inverse relationship with the frequency (the higher the value of a, the lower the\\nfrequency, and vice versa). The dilation factor (b) allows delaying (or advancing) the wavelet onset.\\nTherefore, it contains time information. In this way, the CWT can provide a kind of time-frequency\\nrepresentation where high frequency resolution is obtained for low frequencies and high time resolution\\nis obtained for high frequencies. This is shown in Figure 32A where a real respiration signal is processed\\nwith the CWT. The time-frequency representation of the processed signal is shown in Figure 32A (right).\\nIt can be seen that a low frequency value around 0.33 Hz is identiﬁed with high resolution in frequency\\nbut low resolution in time. In the example respiration signal, the frequency remains fairly constant\\naround the value of 0.33 Hz.\\n\\nA variant of the WT is the multiresolution analysis (MRA) [269]. The MRA represents the\\nvoltage signal at diﬀerent resolution levels by progressively analyzing the breathing signals into ﬁner\\noctave bands (Figure 32B). For that, the original signal is convolved with high and low pass ﬁlters\\nthat represent the prototype wavelet. The outputs of the low pass ﬁlter are called “approximation\\ncoeﬃcients”, while the outputs of the high pass ﬁlter are called “detail coeﬃcients”. Approximation\\ncoeﬃcients are down-sampled by a factor of 2 and are again subjected to high-pass and low-pass\\nﬁltering, obtaining a new set of “detail” and “approximation” coeﬃcients. This process is repeated\\niteratively, resulting in diﬀerent resolution levels. For a given decomposition level n, the detail\\ncoeﬃcients contain information on a particular set of frequencies (from fs/2n to fs/2n+1), with fs being\\nthe sampling frequency. Regarding the “approximation coeﬃcients” of the same decomposition level,\\nthey contain low-frequency information in the range fs/2n+1 − 0 Hz. The number of decomposition\\nlevels of the MRA depends on the speciﬁc breathing signal, so the band of the respiration frequencies\\ncan be correctly identiﬁed. It is aﬀected by the sampling frequency of the system. This decomposition\\nprocess is explained graphically in Figure 32B. The original respiration signal (x) can be reconstructed\\nfrom its detail and approximation coeﬃcients as follows:\\n\\nx =\\n\\nl(cid:88)\\n\\nj=1\\n\\nDj + Al,\\n\\n(25)\\n\\nwhere l is the number of decomposition levels. Figure 32B also shows an example of this technique\\napplied to a breathing signal with a sampling frequency of 50 Hz. Six decomposition levels were\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n46 of 84\\n\\nselected to obtain ﬁve sets of detail coeﬃcients in the ranges 25–12.5 Hz, 12.5–6.25 Hz, 6.25–3.125 Hz,\\n3.125–1.563 Hz, 1.563–0.781 Hz and one set of approximation coeﬃcients in the range 0.781–0 Hz.\\nThe ﬁrst and third levels of detail coeﬃcients and the sixth level of approximation coeﬃcients were\\nrepresented in Figure 32B as an example. In this case, the level of interest was the sixth (approximation\\ncoeﬃcients) since breathing signals are of low frequency. The Fourier Transform was performed on the\\ncoeﬃcients of the sixth level, obtaining a clear peak at the frequency of 0.33 Hz, which matches the\\nbreathing frequency of the sample respiration signal (20 bpm).\\n\\nFigure 32. Wavelet transform. (A) 2D representation of the continuous wavelet transform (CWT) (right)\\nof an example signal (left) taken from a dataset of real respiration signals [254] (RR of 20 bpm −0.33 Hz-,\\nand sampling frequency of 50 Hz). (B) Multiresolution analysis (MRA) decomposition process (top).\\nThe lower part shows an example of the MRA analysis applied to the signal above ((A), left). Six-level\\ndecomposition was applied using the ‘Haar’ wavelet. Two detail levels and the sixth approximation\\nlevel are represented. The spectrum of the approximation coeﬃcients (level 6) was obtained.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 47 of 89   Figure 32. Wavelet transform. (A) 2D representation of the continuous wavelet transform (CWT) (right) of an example signal (left) taken from a dataset of real respiration signals [254] (RR of 20 bpm −0.33 Hz-, and sampling frequency of 50 Hz). (B) Multiresolution analysis (MRA) decomposition process (top). The lower part shows an example of the MRA analysis applied to the signal above ((A), left). Six-level decomposition was applied using the ‘Haar’ wavelet. Two detail levels and the sixth approximation level are represented. The spectrum of the approximation coefficients (level 6) was obtained. In the work of Scalise et al. [232], the signal was decomposed into 12 levels and level 11 was considered to obtain the RR. Guo et al. [166] performed a 4-level decomposition, selecting level 3 to \\x0cSensors 2020, 20, 5446\\n\\n47 of 84\\n\\nIn the work of Scalise et al. [232], the signal was decomposed into 12 levels and level 11 was\\nconsidered to obtain the RR. Guo et al. [166] performed a 4-level decomposition, selecting level 3\\nto calculate the RR. Therefore, the wavelet transform is used to obtain the respiration signals in the\\ndesired frequency band.\\n\\nKalman ﬁlter: This technique has been used by several studies as a sensor fusion method. Thus,\\nit is not a method to extract breathing parameters but to fuse measurements from diﬀerent sensors.\\nWhen multiple respiration sensors are available, the measurements they provide are not exactly the\\nsame. Furthermore, measurements always contain noise. The Kalman ﬁlter is used to provide a ﬁnal\\nvalue based on the measurements of the diﬀerent sensors, the model of variation of the breathing\\nparameter, the noise model of the sensors, and the variation model [270]. Figure 33 shows an overview\\nof the Kalman ﬁlter algorithm adapted to the fusion of breathing sensors.\\n\\nFigure 33. Kalman ﬁlter algorithm for the fusion of diﬀerent respiration sensors.\\n\\nThe Kalman ﬁlter has two distinct phases: prediction and update. The prediction phase estimates\\nthe state (breathing parameter) in the current time step using the state estimate from the previous time\\nstep (previous breathing parameter). The breathing parameter predicted in this phase is called the\\n−\\n“a priori” state estimate ˆx\\nk and is obtained according to Equation (26).\\n\\n−\\nk = A ˆxk−1,\\nˆx\\n\\n(26)\\n\\nwhere ˆxk−1 is the state estimate in the previous state, in this case the previous breathing parameter\\nestimated, and A is the state transition model. Matrix A represents the expected evolution of ˆxk−1 for\\nthe next transition. As breathing does not vary much in the short term [102], a common approach is to\\n−\\ndeﬁne A as an identity matrix, so the “a priori” state estimate ˆx\\nk is equal to the previous state ˆxk−1.\\nIf respiration is not expected to be constant in the short term, A should contain the linear variation\\n−\\nmodel. The “a priori” estimate covariance P\\nk (Equation (27)), which is a measure of the accuracy of the\\n−\\n“a priori” state estimate ˆx\\nk , must also be predicted. It depends on the transition model A, the value of\\nthe covariance in the previous transition Pk−1, and Q. Q is the covariance of the process noise (the noise\\n−\\nof ˆx\\nk prediction model). In order to apply the Kalman ﬁlter, the process noise must follow a Gaussian\\ndistribution with zero mean and covariance Qk(∼ N(0, Q)). Although A and Q can vary at each time\\nstep k, it is common for them to take a constant value. Many methods exist to determine Q. In the\\n\\nSensors 2020, 20, x FOR PEER REVIEW 48 of 89  calculate the RR. Therefore, the wavelet transform is used to obtain the respiration signals in the desired frequency band. Kalman filter: This technique has been used by several studies as a sensor fusion method. Thus, it is not a method to extract breathing parameters but to fuse measurements from different sensors. When multiple respiration sensors are available, the measurements they provide are not exactly the same. Furthermore, measurements always contain noise. The Kalman filter is used to provide a final value based on the measurements of the different sensors, the model of variation of the breathing parameter, the noise model of the sensors, and the variation model [270]. Figure 33 shows an overview of the Kalman filter algorithm adapted to the fusion of breathing sensors.  Figure 33. Kalman filter algorithm for the fusion of different respiration sensors. The Kalman filter has two distinct phases: prediction and update. The prediction phase estimates the state (breathing parameter) in the current time step using the state estimate from the previous time step (previous breathing parameter). The breathing parameter predicted in this phase is called the “a priori” state estimate (cid:1876)(cid:3548)(cid:3038)(cid:2879) and is obtained according to Equation (26). (cid:1876)(cid:3548)(cid:3038)(cid:2879)=(cid:1827)(cid:1876)(cid:3548)(cid:3038)(cid:2879)(cid:2869), (26)where (cid:1876)(cid:3548)(cid:3038)(cid:2879)(cid:2869) is the state estimate in the previous state, in this case the previous breathing parameter estimated, and A is the state transition model. Matrix A represents the expected evolution of (cid:1876)(cid:3548)(cid:3038)(cid:2879)(cid:2869) for the next transition. As breathing does not vary much in the short term [102], a common approach is to define A as an identity matrix, so the “a priori” state estimate (cid:1876)(cid:3548)(cid:3038)(cid:2879) is equal to the previous state (cid:1876)(cid:3548)(cid:3038)(cid:2879)(cid:2869). If respiration is not expected to be constant in the short term, A should contain the linear variation model. The “a priori” estimate covariance (cid:1842)(cid:3038)(cid:2879) (Equation (27)), which is a measure of the accuracy of the “a priori” state estimate (cid:1876)(cid:3548)(cid:3038)(cid:2879), must also be predicted. It depends on the transition model A, the value of the covariance in the previous transition (cid:1842)(cid:3038)(cid:2879)(cid:2869), and Q. Q is the covariance of the process noise (the noise of (cid:1876)(cid:3548)(cid:3038)(cid:2879) prediction model). In order to apply the Kalman filter, the process noise must follow a Gaussian distribution with zero mean and covariance Qk(~(cid:1840)(0,(cid:1843))). Although A and Q can vary at each time step k, it is common for them to take a constant value. Many methods exist to determine Q. In the breathing system presented by Yoon et al. [131] Q was a diagonal matrix (which is a common approach) of the order of 10−4. (cid:1842)(cid:3038)(cid:2879)=(cid:1827)(cid:1842)(cid:3038)(cid:2879)(cid:2869)(cid:1827)(cid:3021)+(cid:1843). (27)\\x0cSensors 2020, 20, 5446\\n\\n48 of 84\\n\\nbreathing system presented by Yoon et al. [131] Q was a diagonal matrix (which is a common approach)\\nof the order of 10\\n\\n−4.\\n\\n−\\n\\nP\\n\\nk = APk−1AT + Q.\\n\\n(27)\\n\\n−\\nOnce the “a priori” state estimate ˆx\\nk has been predicted, the update phase comes into play. In the\\n−\\nupdate phase, the “a priori” state estimate ˆx\\nk is reﬁned using the measurements yk recorded by the\\nsensors. The result is the ﬁnal value of the breathing parameter ˆxk, which is called the “a posteriori”\\nstate estimate (Equation (28)).\\n\\n−\\nk + Kk\\nˆxk = ˆx\\n\\nyk\\n\\n−\\n− H ˆx\\nk\\n\\n(cid:16)\\n\\n(cid:17)\\n\\n.\\n\\n(28)\\n\\nThe estimation of ˆxk depends on the predicted “a priori” state estimate ˆx\\n\\n−\\nk , the measurements\\nregistered by the diﬀerent breathing sensors yk and the matrices Kk and H. Kk is known in the Kalman\\nﬁlter as the optimal Kalman gain. It minimizes the “a posterior” error covariance. A common way to\\ncalculate it is according to Equation (29).\\n\\nKk =\\n\\n−\\n\\nk HT\\nP\\nHP−\\nk HT + R\\n\\n.\\n\\n(29)\\n\\n−\\nk and two model parameters (H and R).\\nThis gain depends on the “a priori” estimate covariance P\\nH is the observation model that relates the measurements taken by the sensors yk to the state space\\nxk (breathing parameter), as follows yk = H ˆxk. It is common that previous techniques introduced\\nin this section (peak detection, maximum-minimum detection, zero-crossings, threshold detection,\\nfrequency analysis, or wavelet transform) are used to directly estimate the respiration parameter from\\nthe measurements. In that case, the measurement space and the state space are the same. Thus, H could\\nsimply be the identity matrix. If the respiration parameter (RR, for example) were not provided directly\\nas a result of the measurements, and other parameters were given instead (such as the number of\\npeaks, zero-crossings, etc.), matrix H would contain the equations to calculate the breathing parameter\\nfrom those values. Those equations were previously introduced in this section.\\n\\nR is the covariance of the observation noise (the noise associated with the measurements yk).\\nThe observation noise should also follow a Gaussian distribution with zero mean and covariance R\\n(~N(0,R)). Although H and R can vary at each time step k, it is common that they adopt a constant value.\\nIn the update phase, the covariance is also updated to obtain the “a posteriori” estimate covariance\\n\\nPk according to Equation (30).\\n\\n−\\nPk = P\\nk\\n\\n−\\n− KkHP\\nk .\\n\\n(30)\\n\\nAs a result of the update phase, the ﬁnal breathing parameter ˆxk is estimated, which is the output\\nof this algorithm. However, the Kalman ﬁlter is an iterative method that recalculates ˆxk at each time\\nstep. Therefore, the “a posteriori” state estimate ˆxk at the current time step will be the previous state\\nestimate ˆxk−1 at the next time step. The same happens with the covariance since the “a posteriori”\\nestimate covariance Pk at the current time step will be the previous estimate covariance Pk−1 at the next\\ntime step. In this way, the algorithm can start a new prediction process again (Figure 33). The whole\\nprocess is repeated indeﬁnitely. The output of the system at each transition is the “a posteriori” estimate\\nof the respiration parameters ˆxk.\\n\\n3.4.2. Results of the Analysis\\n\\nTable 6 presents the results of the analysis for the wearable studies and Table 7 shows the results\\nof the environmental studies. The second column of each table includes the speciﬁc data processing\\ntechniques used in each study. Figure 34 represents the number of works that use the diﬀerent\\nprocessing methods for wearable and environmental studies. The category “custom algorithm” was\\nadded to refer to processing algorithms that cannot be classiﬁed in any other group, as they are speciﬁc\\nto the sensor used for respiration monitoring. It can be seen that “peak detection” in respiration\\nsignals and “frequency analysis” using the Fourier Transform were some of the most widely used\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n49 of 84\\n\\nmethods by both wearable and environmental studies. The sum of the percentages of use of techniques\\nbased on the detection of levels in their diﬀerent forms (peaks, maximum and minimum values, zero\\ncrossings, or thresholds) was 42% for the wearable category and 33% for the environmental systems.\\nIn the environmental category, the variability in data processing methods was much greater than in\\nthe wearable category, as a large number of studies applied “custom algorithms”. The use of wavelet\\ndecomposition or the Kalman ﬁlter was residual [102,131,165,166,193,212,232].\\n\\nTable 6. Analysis of the processing algorithm, performance evaluation, and software for the studies of\\nthe wearable category.\\n\\nStudy 1\\n\\nAlgorithm\\n\\nPerformance\\nEvaluation\\n\\nPerformance Value\\n\\nAitkulov 2019 [57,58]\\n\\nFrequency analysis\\n\\nGraphical comparison\\n\\nAnalysis\\nSoftware\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\nBalasubramaniyam\\n2019 [59]\\n\\nBricout 2019 [60]\\n\\n-\\n\\n-\\n\\nAdaptive\\nreconstruction\\n\\nCorrelation factor\\n\\n0.64–0.74\\n\\n-\\n\\nChu 2019 [61]\\n\\nPeak detection\\n\\nBland-Altman analysis\\nCorrelation factor\\n\\n0.99 (correlation)\\n\\nMATLAB\\n\\nElfaramawy 2019 [62]\\n\\nPeak detection\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\nFajkus 2019 [63]\\n\\nPeak detection\\n\\nRelative error\\nBland-Altman analysis\\n\\n3.9% (RE)\\n\\nLabview\\n\\nHurtado 2019 [64]\\n\\nZero-crossing\\ndetection\\n\\nRelative error\\nBland-Altman analysis\\n\\n0.4 bpm (BA, mean of\\ndiﬀerence –MOD–)\\n\\nJayarathna 2019 [65]\\n\\nPeak detection\\n\\nKano 2019 [66]\\n\\nPeak detection\\n\\n-\\nCorrelation coeﬃcient\\nBland-Altman analysis\\n\\n-\\n\\n0.88 (correlation)\\n0.026 bpm (BA, MOD)\\n\\n-\\n\\n-\\n\\n-\\n\\nKaracocuk 2019 [67]\\n\\nFrequency analysis\\n\\nCorrelation\\n\\n-\\n\\nMassaroni 2019 [68]\\n\\nCustom algorithm\\n\\nRelative error\\nLinear regression\\nBland-Altman analysis\\n\\n4.03% (RE)\\n0.91–0.97 (r2)\\n−0.06 (BA, MOD)\\n\\nMassaroni 2019 [69]\\n\\nPeak detection\\n\\nBland-Altman analysis\\n\\n0.05 bpm (BA, MOD)\\n\\nNguyen 2019 [70]\\n\\nFrequency analysis\\n\\n-\\n\\n-\\n\\nPresti 2019 [71]\\n\\nPeak detection\\n\\nPercentage error\\n\\n<4.71% (PE)\\n\\nPresti 2019 [72]\\n\\nPeak detection\\n\\nPuranik 2019 [73]\\n\\nSoomro 2019 [74]\\n\\nXiao 2019 [75]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nGraphical comparison\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\nMicroprocessor\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\nMATLAB\\nLabview\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nYuasa 2019 [76]\\n\\nPeak detection\\n\\nAccuracy\\n\\n61.3–65.6%\\n\\nMATLAB\\n\\nZhang 2019 [77]\\n\\nFrequency analysis\\n\\n-\\n\\nDan 2018 [78]\\n\\nZero-crossing\\ndetection\\n\\nBland-Altman analysis\\n\\nKoyama 2018 [79]\\n\\nFrequency analysis\\n\\nAbsolute error\\n\\nMalik 2018 [80]\\n\\n-\\n\\nGraphical monitoring\\n\\n-\\n\\n0.01–0.02 bpm\\n(BA, MOD)\\n\\n4 bpm\\n\\n-\\n\\nMartin 2018 [81]\\n\\nCustom algorithm\\n\\nMean absolute error\\nMean relative error\\nBland-Altman analysis\\n\\n2.7 bpm (MAE)\\n30.9% (MRE)\\n2.4 bpm (BA, MOD)\\n\\n-\\n\\n-\\n\\nPython\\n\\nPython\\n\\nMATLAB\\n\\nPang 2018 [82]\\n\\n-\\n\\nGraphical monitoring\\n\\n-\\n\\n-\\n\\n1 Note: The analysis for studies published before 2018 [2,3,17,21,49,83–162] is included in Appendix A (Table A4).\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n50 of 84\\n\\nTable 7. Analysis of the processing algorithm, performance evaluation, and software for the studies of\\nthe environmental category.\\n\\n-\\n\\n-\\n\\n-\\n\\nStudy 1\\n\\nAlgorithm\\n\\nAl-Wahedi 2019 [163]\\n\\nFrequency analysis\\n\\nChen 2019 [164]\\n\\nGunaratne 2019 [165]\\n\\nZero-crossing\\ndetection\\n\\nWavelet transform\\nFuzzy logic\\n\\nPerformance\\nEvaluation\\n\\nManual veriﬁcation\\nRelative error\\n\\nPerformance Value\\n\\nAnalysis\\nSoftware\\n\\n4–14% (RE)\\n\\nLabview\\n\\nMean squared error\\n\\n1.23 bpm\\n\\nRelative error\\n\\n6.2%\\n\\nGuo 2019 [166]\\n\\nWavelet transform\\n\\nCross-correlation\\n\\n0.76–0.85\\n\\nIsono 2019 [167]\\n\\nCustom algorithm\\n\\nLinear regression\\nBland-Altman analysis\\n\\n0.969 (r2)\\n0.07–0.17 bpm\\n(BA, MOD)\\n\\nLabChart\\nMATLAB\\n\\nIvanovs 2019 [168]\\n\\nNeural networks\\n\\nOthers\\n\\n-\\n\\nJoshi 2019 [169]\\n\\n-\\n\\nCorrelation factor\\nRoot mean square error\\nBland-Altman analysis\\n\\n0.74 (correlation)\\n4.7 bpm (RMSE)\\n−0.36 (BA, MOD)\\n\\nKrej 2019 [170]\\n\\nMachine learning\\nmethods\\n\\nRoot mean square error\\nBland-Altman analysis\\n\\n1.48 bpm (RMSE)\\n0.16 bpm (BA, MOD)\\n\\n-\\n\\n-\\n\\nC#\\nR\\n\\nLorato 2019 [171]\\n\\nFrequency analysis\\n\\nRoot mean square error\\nBland-Altman analysis\\n\\n1.59 bpm (RMSE)\\n\\nMATLAB\\n\\nMassaroni 2019 [172]\\n\\nCustom algorithm\\n\\nAbsolute error\\nStandard error\\nPercentage error\\nBland-Altman analysis\\n\\n0.39 bpm (AE)\\n0.02 bpm (SE)\\n0.07% (PE)\\n−0.01 bpm (BA, MOD)\\n\\nMATLAB\\n\\nPark 2019 [173]\\n\\nFrequency analysis\\n\\nAccuracy\\nBland-Altman analysis\\n\\n99.4% (Acc)\\n\\nMATLAB\\n\\nWalterscheid 2019\\n[174]\\n\\nPeak detection\\n\\nGraphical comparison\\n\\n-\\n\\n-\\n\\nWang 2019 [175]\\n\\nCustom algorithm\\n\\nAbsolute error\\nRelative error\\n\\n0.3 bpm (AE)\\n2% (RE)\\n\\nMATLAB\\n\\nXu 2019 [176]\\n\\nCustom algorithm\\n\\nAbsolute error\\nCorrelation factor\\n\\n0.11 bpm (AE)\\n0.95 (correlation)\\n\\nYang 2019 [177]\\n\\nCustom algorithm\\n\\nAbsolute error\\n\\n0.3–0.6 bpm\\n\\nChen 2018 [178]\\n\\nCustom algorithm\\n\\nAccuracy\\n\\nChen 2018 [179]\\n\\nFrequency analysis\\n\\nGraphical comparison\\n\\n98.65%\\n\\n-\\n\\nMassaroni 2018 [180]\\n\\nThreshold detection\\nZero-crossing\\ndetection\\nCustom algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\nPercentage error\\nOthers\\n\\n0.97 (correlation)\\n0.01 bpm (BA, MOD)\\n5.5% (PE)\\n\\n-\\n\\n-\\n\\n-\\n\\nMobile app\\n\\nMATLAB\\n\\nMassaroni 2018 [181]\\n\\nPeak detection\\n\\nRelative error\\n\\n2%\\n\\nMATLAB\\n\\nSadek 2018 [182]\\n\\nPeak detection\\nCustom algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\nMean absolute error\\n\\n0.78 (correlation)\\n0.38 bpm (MAE)\\n\\n-\\n\\n1 Note: The analysis for studies published before 2018 [5–7,9,10,19,48,50–54,183–234] is included in Appendix A\\n(Table A5).\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n51 of 84\\n\\nFigure 34. Number of studies using diﬀerent processing algorithms for the wearable (left) and\\nenvironmental (right) categories.\\n\\nFigure 35 shows the ﬁgures of merit used to provide a value of sensor performance for the wearable\\nand environmental studies. The categories “graphical comparison” and “graphical monitoring”,\\nwhich could be considered as informal metrics, were added to the list of evaluation metrics of\\nSection 3.4.1. The category “graphical comparison” refers to studies that visually compared the\\nperformance of the sensing system under evaluation with a reference system, but did not use an\\nobjective metric. The category “graphical monitoring” indicates that measurements from sensors were\\nplotted, but no formal metric was calculated and no quantitative comparison was made. Figure 35 shows\\nthat “absolute error”, “relative/percentage error”, “Bland-Altman plot”, and “correlation coeﬃcient”\\nwere the preferred formal metrics for wearable and environmental systems. The use of “root mean\\nsquare error” [48,52,95,107,115,117,147,164,170,171,187,198], “linear regression” [68,161,167,183,209],\\nand “accuracy” [7,76,133,161,179,190,193,207,216] was limited. Furthermore, the percentage of studies\\nthat provided an “informal” ﬁgure of merit was much higher for the wearable category (45%) than\\nfor the environmental group (17%). Therefore, a stronger assessment can be seen in environmental\\nstudies. In general, validation results show low error values and a high correlation with reference\\ndevices. The details for the diﬀerent studies are included in the fourth column of Tables 5 and 6.\\nFifty-two% of the studies that used relative or percentage errors provided a value less than 5%,\\nwhile only 12% reported a value greater than 10%. Correlation coeﬃcients greater than 0.95 were\\nprovided by 46% of the studies [19,52,61,112,126,149,176,180,208,215,222,228,232]. Regarding absolute\\nerror, 78% of the studies that calculated the RR as the breathing parameter provided a value less\\nthan 2 bpm [5,19,64,115,124,132,135,172,175–177,182,189,195,201,207,218,224]. No study reported an\\nabsolute error value greater than 4 bpm. In relation to the Bland-Altman analysis, the mean of the\\ndiﬀerences was less than 0.2 bpm in 49% of the studies that provided data on this metric [48,66,68,69,\\n78,94,95,112,115,126,167,170,172,180,195,200,210,228].\\n\\nRegarding the tools for measurement processing, Figure 36 shows the distribution of use of the\\ndiﬀerent tools for the wearable and environmental respiration monitoring systems. MATLAB was\\nthe preferred software for both types of systems, since it was adopted by half of the studies, while NI\\nLabview was the second most used tool as it appeared in 20–30% of the works [2,3,19,63,71,85–88,127,\\n129,131,138,142,146,153,163,201,218–220,223,225]. The rest of the tools relied heavily on the speciﬁc\\nsensor used to capture the data. For instance, Audacity, as a sound processing tool, could only be\\nused in microphone-based respiration monitoring [162]; OpenCV, as a computer vision library, was\\nsuitable for respiration monitoring through images [187,216]. Therefore, the use of the rest of the tools\\nwas residual.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 52 of 89    Figure 34. Number of studies using different processing algorithms for the wearable (left) and environmental (right) categories. Figure 35 shows the figures of merit used to provide a value of sensor performance for the wearable and environmental studies. The categories “graphical comparison” and “graphical monitoring”, which could be considered as informal metrics, were added to the list of evaluation metrics of Section 3.4.1. The category “graphical comparison” refers to studies that visually compared the performance of the sensing system under evaluation with a reference system, but did not use an objective metric. The category “graphical monitoring” indicates that measurements from sensors were plotted, but no formal metric was calculated and no quantitative comparison was made. Figure 35 shows that “absolute error”, “relative/percentage error”, “Bland-Altman plot”, and “correlation coefficient” were the preferred formal metrics for wearable and environmental systems. The use of “root mean square error” [48,52,95,107,115,117,147,164,170,171,187,198], “linear regression” [68,161,167,183,209], and “accuracy” [7,76,133,161,179,190,193,207,216] was limited. Furthermore, the percentage of studies that provided an “informal” figure of merit was much higher for the wearable category (45%) than for the environmental group (17%). Therefore, a stronger assessment can be seen in environmental studies. In general, validation results show low error values and a high correlation with reference devices. The details for the different studies are included in the fourth column of Tables 5 and 6. Fifty-two% of the studies that used relative or percentage errors provided a value less than 5%, while only 12% reported a value greater than 10%. Correlation coefficients greater than 0.95 were provided by 46% of the studies [19,52,61,112,126,149,176,180,208,215,222,228,232]. Regarding absolute error, 78% of the studies that calculated the RR as the breathing parameter provided a value less than 2 bpm [5,19,64,115,124,132,135,172,175–177,182,189,195,201,207,218,224]. No study reported an absolute error value greater than 4 bpm. In relation to the Bland-Altman analysis, the mean of the differences was less than 0.2 bpm in 49% of the studies that provided data on this metric [48,66,68,69,78,94,95,112,115,126,167,170,172,180,195,200,210,228]. Regarding the tools for measurement processing, Figure 36 shows the distribution of use of the different tools for the wearable and environmental respiration monitoring systems. MATLAB was the preferred software for both types of systems, since it was adopted by half of the studies, while NI Labview was the second most used tool as it appeared in 20–30% of the works [2,3,19,63,71,85–88,127,129,131,138,142,146,153,163,201,218–220,223,225]. The rest of the tools relied heavily on the specific sensor used to capture the data. For instance, Audacity, as a sound processing tool, could only be used in microphone-based respiration monitoring [162]; OpenCV, as a computer vision library, was suitable for respiration monitoring through images [187,216]. Therefore, the use of the rest of the tools was residual. 051015202530Number of studies024681012141618Number of studies\\x0cSensors 2020, 20, 5446\\n\\n52 of 84\\n\\nFigure 35. Number of studies using the diﬀerent ﬁgures of merit to determine sensor performance for\\nthe wearable (top) and environmental (bottom) categories.\\n\\nFigure 36. Cont.\\n\\nSensors 2020, 20, x FOR PEER REVIEW 53 of 89     Figure 35. Number of studies using the different figures of merit to determine sensor performance for the wearable (top) and environmental (bottom) categories.  Absolute error, 8Relative/percentage error, 13Root mean square error, 5Correlation coefficient,10Bland-Altman plot, 14Accuracy, 2Linear regression, 1Graphical comparison, 13Graphical monitoring, 17Others, 2Absolute error, 11Relative/percentage error, 16Root mean square error, 5Correlation coefficient, 15Bland-Altman plot, 15Accuracy,4Linear regression, 2Graphical comparison, 13Graphical monitoring, 2Others, 6Matlab, 28Labview, 13Python, 2C#, 1Physput, 1Kuvios HRV, 1Blynk, 1Audacity, 1LabWindows/CVI, 1Microprocessor/ Microcontroller, 3Custom application, 1Objective-C, 1Sensors 2020, 20, x FOR PEER REVIEW 53 of 89     Figure 35. Number of studies using the different figures of merit to determine sensor performance for the wearable (top) and environmental (bottom) categories.  Absolute error, 8Relative/percentage error, 13Root mean square error, 5Correlation coefficient,10Bland-Altman plot, 14Accuracy, 2Linear regression, 1Graphical comparison, 13Graphical monitoring, 17Others, 2Absolute error, 11Relative/percentage error, 16Root mean square error, 5Correlation coefficient, 15Bland-Altman plot, 15Accuracy,4Linear regression, 2Graphical comparison, 13Graphical monitoring, 2Others, 6Matlab, 28Labview, 13Python, 2C#, 1Physput, 1Kuvios HRV, 1Blynk, 1Audacity, 1LabWindows/CVI, 1Microprocessor/ Microcontroller, 3Custom application, 1Objective-C, 1\\x0cSensors 2020, 20, 5446\\n\\n53 of 84\\n\\nFigure 36. Number of studies using the diﬀerent processing tools for the wearable (top) and\\nenvironmental (bottom) categories.\\n\\n4. Discussion\\n\\nRespiratory monitoring has been actively investigated in recent years, as can be deduced from\\nthe high number of studies included in this systematic review of the literature. While monitoring\\nbreathing in hospital or controlled environments poses fewer problems, the main research challenge is\\nto monitor breathing for a long period in the user’s daily environment.\\n\\nFollowing the approaches of previous works [24], two diﬀerent sets of systems for respiratory\\nmonitoring were identiﬁed. On the one hand, wearable systems have the advantages that they can\\nbe used in any environment, either indoors or outdoors, are generally easy to install and, in most\\ncases, inexpensive. However, the level of obtrusiveness can determine the acceptability of this type of\\nsystems. Some sensors, such as those designed to be worn on the face or neck, are more obtrusive.\\nA set of wearable sensing technologies are less invasive. This may be the case of those that are worn\\nin the chest, abdomen, arms, or wrist. This might be one of the reasons why the detection of chest\\nmovements is the predominant approach. Another reason could be that chest seems to be the part of\\nthe body that presents the greatest variations in its state as a result of the respiratory activity. However,\\nmost of these technologies require users to wear a belt on the chest or abdomen, electrodes that make\\ncontact with the skin, or tight clothing to detect the movement of the thorax [254]. These restrictions\\nmight cause discomfort in the long term or, in extreme cases, even skin problems. The proposal of\\nTeichmann et al. [56] is original since the sensor is carried in a pocket of a shirt that does not need\\nto be tight. This represents an advantage over other approaches, although some users may ﬁnd the\\nlack of integration into clothing uncomfortable. Future research can go in that direction. A common\\ndrawback of wearable systems is that they are heavily aﬀected by artifacts caused by non-breathing\\nmovements. This leads to larger measurement errors, which can even compromise the viability of\\nthe sensing systems in extreme cases. On the other hand, environmental sensors have the advantages\\nthat they are non-invasive, data transmission can be done with cable communication and battery life\\ndoes not limit their operation. However, their scope is restricted to a particular area. Any change\\nin the environment (for example, the relocation of furniture) can modify the detection capabilities.\\nAdditionally, some technologies, such as computer vision, present privacy concerns, which may aﬀect\\nuser acceptance [271]. Environmental sensors seem suitable for home or hospital applications, but not\\nfor continuous monitoring of moving subjects. In fact, usability is a big challenge in respiratory\\nmonitoring. Several authors have highlighted this fact [10,19,51,52,115,159,187,254]. However, despite\\nthis, we identiﬁed a clear gap in the literature since it was not possible to ﬁnd any usability analysis of\\nthe sensors implemented in the existing studies. Future research should also focus on usability. For that,\\nwell-known usability tests can be applied to evaluate the level of acceptance of technology by its\\npotential users. For example, the User Acceptance of Information Technology (UTAUT) model [272,273]\\n\\nSensors 2020, 20, x FOR PEER REVIEW 54 of 89   Figure 36. Number of studies using the different processing tools for the wearable (top) and environmental (bottom) categories. 4. Discussion Respiratory monitoring has been actively investigated in recent years, as can be deduced from the high number of studies included in this systematic review of the literature. While monitoring breathing in hospital or controlled environments poses fewer problems, the main research challenge is to monitor breathing for a long period in the user’s daily environment. Following the approaches of previous works [24], two different sets of systems for respiratory monitoring were identified. On the one hand, wearable systems have the advantages that they can be used in any environment, either indoors or outdoors, are generally easy to install and, in most cases, inexpensive. However, the level of obtrusiveness can determine the acceptability of this type of systems. Some sensors, such as those designed to be worn on the face or neck, are more obtrusive. A set of wearable sensing technologies are less invasive. This may be the case of those that are worn in the chest, abdomen, arms, or wrist. This might be one of the reasons why the detection of chest movements is the predominant approach. Another reason could be that chest seems to be the part of the body that presents the greatest variations in its state as a result of the respiratory activity. However, most of these technologies require users to wear a belt on the chest or abdomen, electrodes that make contact with the skin, or tight clothing to detect the movement of the thorax [254]. These restrictions might cause discomfort in the long term or, in extreme cases, even skin problems. The proposal of Teichmann et al. [56] is original since the sensor is carried in a pocket of a shirt that does not need to be tight. This represents an advantage over other approaches, although some users may find the lack of integration into clothing uncomfortable. Future research can go in that direction. A common drawback of wearable systems is that they are heavily affected by artifacts caused by non-breathing movements. This leads to larger measurement errors, which can even compromise the viability of the sensing systems in extreme cases. On the other hand, environmental sensors have the advantages that they are non-invasive, data transmission can be done with cable communication and battery life does not limit their operation. However, their scope is restricted to a particular area. Any change in the environment (for example, the relocation of furniture) can modify the detection capabilities. Additionally, some technologies, such as computer vision, present privacy concerns, which may affect user acceptance [271]. Environmental sensors seem suitable for home or hospital applications, but not for continuous monitoring of moving subjects. In fact, usability is a big challenge in respiratory monitoring. Several authors have highlighted this fact [10,19,51,52,115,159,187,254]. However, despite this, we identified a clear gap in the literature since it was not possible to find any usability analysis of the sensors implemented in the existing studies. Future research should also focus on usability. For that, well-known usability tests can be applied to evaluate the level of Matlab, 20Labview, 8Mobile/ Android App, 2C#, 2AcQknowledge software, 1Labchart, 1R computing environment, 1OpenCV, 2Kinect SDK, 1Custom application, 2\\x0cSensors 2020, 20, 5446\\n\\n54 of 84\\n\\nmay serve. This model was applied previously to evaluate smart wearable devices [274], including\\nhealth care [275,276], and m-health devices [277]. Other parameters, such as size or weight, can also\\naﬀect the adoption of the technology. These parameters have only been provided in a limited number\\nof studies [2,3,17,21,49,62,64,68,72,85,93,94,97–99,103,105,108,110,113,114,116,119,120,124,126,135,136,\\n138,141,143,144,146,148,161]. Future works should also consider size and weight as important factors\\nin the design of sensing systems, subjecting them to evaluation.\\n\\nRegarding the type of sensors used for respiratory monitoring, ﬁber optic sensors prevailed in the\\nwearable category. This may be due to their insensitivity to electromagnetic ﬁelds, their high resistance\\nto water and corrosion, and their compact size and low weight [125]. This technology also allows\\nmonitoring diﬀerent types of physiological parameters simultaneously [278]. In addition, resistive\\nsensors and accelerometers were the second and third most widely used technologies. This might be\\nexplained as they are suitable for detecting movement variations, and their design is simpler than other\\ntechnologies, such as capacitive, pyroelectric, or piezoelectric sensors, among others. In relation to the\\nenvironmental category, most researchers designed radar-based sensors. Cameras were also widely\\nused. The great development of computer vision technology in recent years [279] makes the detection\\nof chest movements through video image technically feasible. However, cameras present privacy\\nconcerns, which may be why radar sensors are the preferred non-contact technology. Radar systems\\nare also small in size, low cost, and simple in structure, which provides advantages in installation and\\noperation [280]. The researches that decided to integrate the sensors into everyday objects again opted\\nfor ﬁber optic technology and sensors based on the measurement of resistance changes. This could be\\ndue to the advantages of these technologies, which have been mentioned before. However, the use of\\nnon-object-embedded environmental systems was the predominant approach, as they do not require\\nusers to be in permanent contact with an object, increasing system applications.\\n\\nComparing the performance of sensors is a challenge. It is diﬃcult to compare the performance\\nof diﬀerent studies, since there is no standardized test to validate the sensors. Authors designed\\ncustomized experiments with great diﬀerences among them. Many aspects were deﬁned diﬀerently:\\nthe type and values of the respiratory parameters considered, the positions of the subjects during\\nthe tests, the number of human participants involved in the experiments, their characteristics, or the\\nduration of the experiments. Diﬀerences were also found in the inclusion of motion artifacts and\\nin the mechanical devices that simulated respiration, among others. A consequence of this is that\\nperformances provided by existing studies are not comparable, since they were obtained under diﬀerent\\ntest conditions. Therefore, a future research eﬀort is to design a common evaluation framework.\\nThis framework should include quiet and rapid breathing and diﬀerent postures, such as standing,\\nlying, or sitting. Experiments should include motion artifacts since they aﬀect sensor performance,\\nas shown by several studies [53,108,157,158]. Additionally, they should involve a number of users high\\nenough to obtain signiﬁcant results. In general, the number of subjects participating in existing studies\\nremains low.\\n\\nIn view of the results shown in Section 3.3.2, it is a fact that existing studies carry out short\\nexperiments to validate the sensors. However, little attention is paid to their long-term behavior.\\nThe eﬀect of temperature, sensor aging, or the characteristics of the carrier subjects (such as height or\\nweight) on the sensing systems have not been actively explored. A sensor that works well in a laboratory\\nenvironment might not work as well in a real setting when used for a long time. If there were errors\\nin the measurements, this would cause frequent recalibrations of the sensors. Therefore, a research\\nchallenge is to test the behavior of respiratory monitoring systems in more realistic environments.\\nThe declared performances in laboratory or controlled settings are high. The challenge is to prove\\nthat they are equally high in real-world usage. Sensor aging might be a problem in terms of system\\nperformance. However, it is less critical in terms of cost as replacement of sensing parts is generally\\naﬀordable due to its typically low price.\\n\\nRegarding the declared performances, the validation of the sensors should be done considering\\nreference devices. This is the approach adopted by most of the studies. Other validation methods,\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n55 of 84\\n\\nsuch as the use of metronomes or artiﬁcial prototypes, are less common since, unlike reference devices,\\nthey are not well-established systems that can be acquired by the scientiﬁc community to replicate\\nexperiments or compare results. There is less consensus with respect to the ﬁgure of merit used to\\ndetermine the accuracy of the sensing systems. The relative, absolute and RMS errors, the slope\\nof the linear regression line, and the correlation factor have been considered. It is also common to\\napply the Bland-Altman analysis [281]. It not only provides information on the diﬀerences between\\nthe measurements of both sensors but also shows the variation of the diﬀerences with respect to the\\nmagnitude of the measurements. In addition, the standard deviation of the diﬀerence is also used to\\nobtain the upper and lower limits of agreement. The high variability of the ﬁgures of merit makes it\\ndiﬃcult to compare the studies. One issue of respiratory monitoring is that the acceptable margin of\\nerror is not clearly deﬁned and, therefore, it is diﬃcult to determine whether a new sensing system is\\nin agreement with reference devices. This may be a consequence of the lack of a common experimental\\nframework, since the margin of error depends on the speciﬁc experiments carried out. For example,\\nthe acceptable error may be diﬀerent for slow or rapid breathing. Ideally, both the mean of diﬀerences\\nand the limits of agreement in the Bland-Altman analysis should be provided. As complementary\\ninformation, it would also be interesting to have the mean absolute or relative errors, or the correlation\\nfactor. This would facilitate comparison of system performance among studies. However, this is not\\nthe most common approach and only a limited number of studies have incorporated it [10,44,57,60,61,\\n65,78,92,100,109,112,114,122–124,132,163,165–169,176,178,191,196,205,206,211,224,228].\\n\\nAdditionally, the parameter to be sensed varies among studies. The most common breathing\\nparameter obtained by existing studies is the RR. However, several studies calculate volume parameters,\\nwhich are useful for many applications. There are studies that provide both [2,49,52,61,116,122,147],\\nalthough the calculation of the volume parameters is a challenge since it depends on the speciﬁc\\ntechnology. An approximation for a capacitive textile force sensor can be found in the work of\\nHoﬀmann et al. [17]. However, this is still and open research topic. Obtaining an accurate estimate of\\nvolume parameters using the sensing techniques presented in this review is not easy, especially for\\nwearable systems.\\n\\nRegarding processing algorithms, it can be concluded that detection of peaks, maximum and\\nminimum values, thresholds, or zero crossings were eﬀective in determining respiration parameters.\\nFrequency analysis also provided good results. This aspect seems to have been successfully resolved\\nin existing studies. The use of other processing techniques is residual, as they generally require\\nmore computing resources, are more complex, and are highly dependent on the speciﬁc design of the\\nsensing system.\\n\\nWired and wireless transmission are used equally, as the type of transmission is usually determined\\nby the type of sensor. Within wireless systems, Bluetooth was the preferred option. This may be\\nexplained because most sensing systems communicate with a smartphone/tablet or PC that is close to\\nthe sensing unit. In fact, PC processing is the main trend. This can be a consequence of the majority\\nof studies presenting laboratory prototypes that are far from usable portable systems. In general,\\nauthors do not give much thought to the amount of resources that the processing algorithms use as they\\nperform centralized oﬄine processing on a PC using numerical computing software, such as MATLAB.\\nThis could compromise the real time operation of the systems when they are running continuously.\\nFuture research eﬀorts should focus on designing suitable processing techniques to run ubiquitously\\nin real time on the same microprocessor of the sensing unit or on smartphones.\\n\\nPower consumption is crucial in wearable respiratory monitoring. Most studies did not provide\\ninformation on power consumption or battery life.\\nIn addition, there was no consensus on the\\nmeasurement procedure and the energy parameters that should be provided. In this context, it is very\\ndiﬃcult to compare the power consumption provided by the diﬀerent studies fairly. For example, battery\\nlife varies greatly depending on factors, such as data transmission procedure (continuous, intermittent,\\nor without transmission), sensor operating time (non-stop, several hours a day, etc.), monitoring\\nvisualization (real-time display, without visualization, etc.), or the inclusion of the processing of the\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n56 of 84\\n\\nmeasurements in the power study, among others. When a study provides the battery life of a respiratory\\nsensor, not only must the capacity of the particular battery used in the study be provided, but also\\nother characteristics that aﬀect its performance: depth of discharge, cycle lifetime, or c-rate [282].\\nIt would also be interesting that researchers indicate the power consumption of each component of\\nthe system and not just the total autonomy of the device [98]. This would allow the identiﬁcation\\nof the critical components and facilitate the comparison of diﬀerent systems. Given that autonomy\\nis a limiting factor, strategies to reduce power consumption are required [135]. However, only a\\nfew works have implemented them. Several respiratory monitoring studies focused on transmission\\ntechnology, since it is usually the most demanding module [91,98]. For example, technologies, such\\nas Wi-Fi or Bluetooth, consume more energy than Impulse Radio Ultra-wideband. Other strategies\\nadopted were the down-sampling of data to reduce computational load [119]. The limited number of\\nworks that adopted energy saving strategies may be a symptom that researchers are more focused\\non validating their sensors than in real-world applications. This can also be inferred from the short\\nbattery life indicated by most studies that include this data (less than 12 h typically). Furthermore,\\nthe use of energy harvesting techniques in respiratory monitoring is another open research question,\\nsince the number of studies that implemented them is still residual [77,84,104,135,240–248,250–253].\\nMost studies presented laboratory experiments instead of functional prototypes.\\n\\nAn ideal breathing sensor should be mobile, easy to use, imperceptible and immune to body\\nmotion [48,119,135]. Several authors agree that a system that covers all these aspect should be\\nsuccessfully integrated into clothing [21,59,65,69,84,85,94,103,108,113,119,123,142,143,151]. This is a\\nconsequence of the fact that long-term home monitoring entails direct connection between patient and\\nsystem. However, this poses several problems, such as the adaptation of the sensing system to diﬀerent\\nsizes of clothing, the integration of the energy supply, or the washing of sensors, among others. In fact,\\nthis is an open research question.\\n\\n5. Conclusions\\n\\nThis paper presents a systematic review on sensors for respiratory monitoring, ﬁlling a gap in the\\nstate of the art since no published reviews analyzing respiratory sensors from a comprehensive point\\nof view could be found to the best of our knowledge. As a result of several searches, an overwhelming\\nnumber of studies was found. They were sorted by relevance and, ﬁnally, 198 studies were obtained to\\nbe examined in detail. They were classiﬁed into two groups: wearable and environmental sensors.\\nSeveral aspects were analyzed: sensing techniques, sensors, breathing parameters, sensor location and\\nsize, general system setups, communication protocols, processing stations, energy autonomy, sensor\\nvalidation experiments, processing algorithms, performance evaluation, and software used for the\\nanalysis. As a result, detection of chest movements was identiﬁed as the most common technique\\nusing ﬁber optic sensors for the wearable systems and radar sensors for the environmental systems.\\nThe RR was the most common breathing parameter obtained in 68% of the studies. Most of the studies\\nperformed centralized measurement processing on a PC using MATLAB software. Bluetooth was by\\nfar the prevalent communication technology (60% of the wearable studies adopted it), and almost all\\nwireless respiration sensing systems were battery powered. The most common validation approach\\nwas to use a reference device to perform real tests on real subjects. Furthermore, a high percentage of\\nstudies obtained the breathing parameter after performing frequency analysis or peak detection on the\\nmeasurements. Meanwhile, the most common ﬁgures of merit selected to provide evidence on sensor\\nperformance were absolute and relative errors, Bland-Altman analysis, and correlation coeﬃcients.\\n\\nThis review also identiﬁed future research challenges. One of them is the need to deﬁne a common\\nframework to validate the sensors, since each author carried out his or her own experiments. This makes\\nit diﬃcult to compare sensor performances. Similarly, measurements of power consumption were\\nmade under diﬀerent conditions. A common measurement procedure is required to compare sensor\\nautonomies fairly. There are no long-term evaluations that study the eﬀect of aging, environmental\\nconditions, or characteristics of the subjects on sensor performance.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n57 of 84\\n\\nUsability tests are also lacking in existing studies. Similarly, the ﬁgure of merit to provide sensor\\nperformance varies from one study to another. The Bland-Altman analysis was identiﬁed as the most\\nappropriate method to validate the sensors against reference devices. Other research challenges are the\\nimplementation of energy-saving or energy-harvesting strategies, the application of respiratory sensors\\nto real-world scenarios, or the calculation of volume parameters in the diﬀerent sensing technologies.\\nAll these are remaining research eﬀorts.\\n\\nFinally, several authors highlighted the integration of respiratory monitoring sensors in clothing\\nas a promising technology. This is a future research eﬀort, which presents several challenges for a\\nfeasible, long-term, and unobtrusive solution.\\n\\nAuthor Contributions: Conceptualization, R.I. and I.P.; methodology, E.V. and R.I.; formal analysis, E.V. and R.I.;\\ninvestigation, E.V., R.I. and I.P.; resources, E.V.; data curation, E.V. and R.I.; writing—original draft preparation,\\nR.I.; writing—review and editing, R.I and E.V.; supervision, R.I.; project administration, I.P.; funding acquisition,\\nI.P. All authors have read and agreed to the published version of the manuscript.\\n\\nFunding: This research was funded by the European Union and the Gobierno de Aragón, grant number “Programa\\nOperativo FEDER Construyendo Europa desde Aragon T49_20R”, the Universidad de Zaragoza and the Centro\\nUniversitario de la Defensa de Zaragoza, grant number UZCUD2019-TEC-02, and the Consejo Nacional de Ciencia\\ny Tecnología CONACyT, grant number 709365.\\n\\nConﬂicts of Interest: The authors declare no conﬂict of interest.\\n\\nAppendix A\\n\\nTable A1. Analysis of techniques, sensors, breathing parameters, and sensor locations and sizes for\\nstudies of the wearable category published before 2018.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nMeasured\\nParameter\\n\\nLocation\\n\\nSize\\n\\nAgcayazi 2017 [123]\\n\\nAileni 2017 [134]\\n\\nBasra 2017 [145]\\n\\nBhattacharya 2017 [156]\\n\\nDas 2017 [162]\\n\\nFajkus 2017 [83]\\n\\nGorgutsa 2017 [84]\\n\\nGuay 2017 [85]\\n\\nKam 2017 [86–88]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nAir\\ntemperature\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nCapacitive\\n\\nResistive\\n\\nPyroelectric\\n\\nThermistor\\n\\nThermistor\\n\\nFiber optic\\n\\n-\\n\\nRR\\n\\nRR\\n\\nRR\\n\\n-\\n\\nRR\\n\\nFrequency shift\\n\\nFrequency shift\\n\\nFiber optic\\n\\nMonitoring of\\nbreathing\\n\\nMonitoring of\\nbreathing\\n\\nMonitoring of\\nbreathing\\n\\nKano 2017 [89]\\n\\nAir humidity\\n\\nNanocrystal and\\nnanoparticles\\n\\n-\\n\\nKoch 2017 [90]\\n\\nMilici 2017 [91]\\n\\nNakazumi 2017 [92]\\n\\nPark 2017 [93]\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nRespiratory air\\nﬂow\\n\\nAbdomen\\nmovements\\n\\nResistive\\n\\nThermistor\\n\\nPhotoelectric\\n\\nCapacitive\\n\\nMonitoring of\\nbreathing\\n\\nRR\\nMonitoring of\\nrespiratory\\ndiseases\\n\\nMonitoring of\\nbreathing\\n\\nMonitoring of\\nbreathing\\n\\nChest (shirt)\\n\\nChest\\n\\nNose (nostril)\\n\\nMouth mask\\n\\nNose (near)\\nMouth (near)\\n\\nChest\\n\\nChest (shirt)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nChest (shirt)\\n\\n20 × 10 cm\\n\\nChest\\n\\nNose (near)\\nMouth (near)\\n\\nAbdomen\\n\\nNose (near)\\nMouth (near)\\n\\nMouth mask (diving)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nWaist\\n\\n20 × 10 × 1 mm\\n(electrode)\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n58 of 84\\n\\nTable A1. Cont.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nPresti 2017 [94]\\n\\nValipour 2017 [95]\\n\\nWhite 2017 [96]\\n\\nChest wall\\nmovements\\n\\nRespiratory\\nsounds\\n\\nChest wall\\nmovements\\n\\nFiber optic\\n\\nMicrophone\\n\\nCapacitive\\n\\nMeasured\\nParameter\\n\\nRR\\nRespiratory\\nperiod\\n\\nRR\\n\\nRR\\n\\nLocation\\n\\nSize\\n\\nChest and\\nabdomen (shirt, front\\nand back)\\n\\nNose (near)\\nMouth (near)\\n\\nChest (below left\\npectoral muscle)\\n\\n1.5 cm\\n\\n-\\n\\n-\\n\\nYan 2017 [97]\\n\\nAir humidity\\n\\nNanocrystal and\\nnanoparticles\\n\\nMonitoring of\\nbreathing\\n\\nMouth (4 cm away)\\n\\n5 × 2 × 1 mm\\n\\nMahbub 2016–2017\\n[98,99]\\n\\nChethana 2016 [100]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nPiezoelectric\\n\\nFiber optic\\n\\nRR\\n\\nRR\\n\\nChest\\n\\n1.6 × 1.6 cm\\n\\nChest (interspace of\\npulmonic area)\\n\\nGüder 2016 [101]\\n\\nAir humidity\\n\\nNanocrystal and\\nnanoparticles\\n\\nMonitoring of\\nbreathing\\n\\nMouth mask\\n\\nRR\\n\\nChest\\n\\nRespiratory\\nperiod\\n\\nChest and\\nabdomen (textile)\\n\\n-\\n\\n-\\n\\n1 cm\\n\\nLepine 2016 [102]\\n\\nMassaroni 2016 [103]\\n\\nMassaroni 2016 [49]\\n\\nMoradian 2016 [104]\\n\\nNag 2016 [105]\\n\\nNam 2016 [106]\\n\\nRaji 2016 [107]\\n\\nRamos-García 2016 [108]\\n\\nRotariu 2016 [109]\\n\\nAtalay 2015 [110]\\n\\nCiocchetti 2015 [111]\\n\\nEstrada 2015 [112]\\n\\nGargiulo 2015 [113]\\n\\nGrlica 2015 [114]\\n\\nHernandez 2015 [115]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nRespiratory\\nsounds\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\nChest wall/\\nabdomen\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nJiang 2015 [116]\\n\\nKarlen 2015 [117]\\n\\nAir\\ntemperature\\n\\nModulation\\ncardiac activity\\n\\nAccelerometer\\nECG\\n\\nFiber optic\\n\\nFiber optic\\n\\nPyroelectric\\n\\nCapacitive\\n\\nRR\\nTV\\nCompartmental\\nvolume\\n\\nMonitoring of\\nbreathing\\n\\nMonitoring of\\nbreathing\\n\\nMicrophone\\n\\nRR\\n\\nThermistor\\n\\nRR\\nMonitoring of\\nrespiratory\\ndiseases\\n\\nChest and\\nabdomen (shirt)\\n\\n10 × 10 cm\\n\\nNose (below)\\n\\n-\\n\\nChest (diaphragm)\\n\\n50 mm2\\n\\nNose (near)\\nMouth (near)\\n\\nMouth mask\\n\\n-\\n\\n-\\n\\nResistive\\n\\nRR\\n\\nChest (shirt)\\n\\n23 × 4 cm\\n\\nPiezoelectric\\n\\nResistive\\n\\nFiber optic\\n\\nAccelerometer\\n\\nResistive\\n\\nCapacitive\\n\\nAccelerometer\\nGyroscope\\n\\nPyroelectric\\n\\nRR\\nMonitoring of\\nrespiratory\\ndiseases\\n\\nRR\\n\\nTV\\n\\nRR\\n\\nTV\\n\\n-\\n\\nRR\\n\\nChest\\n\\n-\\n\\nChest\\nAbdomen\\n\\nChest\\n\\nChest\\n\\n2.7 × 9.3 cm\\n\\n-\\n\\n-\\n\\nChest and\\nabdomen (shirt)\\n\\n5 × 7cm\\n(4 units)\\n\\nChest\\n\\nWrist\\n\\n4.5 × 1.7 cm\\n\\n-\\n\\nMV, peak\\ninspiratory\\nﬂow, RR, TV\\n\\nNose (below)\\n\\n5 × 25 × 100 mm\\n\\nPPG\\n\\nRR\\n\\nFinger (on sensor)\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n59 of 84\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nMeasured\\nParameter\\n\\nLocation\\n\\nSize\\n\\nTable A1. Cont.\\n\\nKazmi 2015 [118]\\n\\nMetshein 2015 [21]\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nPPG\\n\\nECG\\n\\nTeichmann 2015 [119]\\n\\nChest wall\\nmovements\\n\\nTransthoracic\\nimpedance\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nOther (micro\\nelectro-mechanical\\nsensor)\\n\\nRespiration\\ndetection\\n\\nFiber optic\\n\\nRR\\n\\nWei 2015 [120]\\n\\nYang 2015 [3]\\n\\nBifulco 2014 [121]\\n\\nFekr 2014 [122]\\n\\nHesse 2014 [124]\\n\\nKrehel 2014 [125]\\n\\nMin 2014 [126]\\n\\nPetrovic 2014 [127]\\n\\nSanchez 2014 [128]\\n\\nWo 2014 [129]\\n\\nYang 2014 [130]\\n\\nYoon 2014 [131]\\n\\nChan 2013 [132]\\n\\nHuang 2013 [133]\\n\\nKundu 2013 [161]\\n\\nPadasdao 2013 [135]\\n\\nCao 2012 [2]\\n\\nChiu 2012 [136]\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nAbdomen\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\nModulation\\ncardiac activity\\n\\nAir\\ntemperature\\nChest wall/\\nabdomen\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nPiezoelectric\\n\\nAccelerometer\\n\\nResistive\\n\\nFiber optic\\n\\nCapacitive\\n\\nFiber optic\\n\\nFiber optic\\n\\nFiber optic\\n\\nCapacitive\\n\\nAccelerometer\\nGyroscope\\n\\nAccelerometer\\nECG\\n\\nPyroelectric\\n\\nCapacitive\\n\\nDC generator\\n\\nPyroelectric\\n\\nFinger (on sensor)\\n\\n-\\n\\nChest (electrode\\nshirt)\\n\\nChest (pocket of\\nshirt)\\n\\n8 × 17cm\\n(electrode\\nsurface)\\n\\n10 × 8 cm\\n\\nNose (5 cm away)\\n\\n1.8 × 2.4 mm\\n\\nChest\\n\\nChest\\n\\nChest (middle\\nsternum region)\\n\\n70 cm (belt)\\n\\n-\\n\\n-\\n\\nChest\\n\\n3 × 1.96 × 2.8 cm\\n\\nMonitoring of\\nbreathing\\n\\nRR\\nTV\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nMV\\nTV\\n\\nChest (diﬀerent\\nregions)\\n\\nWaist\\n\\nChest (lower third of\\nthe thorax)\\n\\nMonitoring of\\nbreathing\\n\\nNose (near)\\nMouth (near)\\n\\nAbdomen\\n\\nChest\\nAbdomen\\n\\nChest\\n\\nChest\\n\\nNose (near)\\nMouth (near)\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\n-\\n\\n83 × 3.86 ×\\n0.135 cm\\n\\n-\\n\\n-\\n\\n-\\n\\n10 × 1 cm\\n\\n-\\n\\n-\\n\\n-\\n\\nChest and abdomen\\n(anterior and\\nposterior region)\\n\\n9 × 13 cm\\n16 × 16 cm\\n5 × 5 cm\\n\\nChest\\n\\nCoin size\\n\\nRR, MV, peak\\ninspiration\\nﬂow, TV\\n\\nNose (near)\\nMouth (near)\\n\\n7 × 4.5 × 1.8 cm\\n\\nPiezoelectric\\n\\nRR\\n\\nChest\\n\\n48 × 19 × 4 mm\\n\\nFavero 2012 [137]\\n\\nAir humidity\\n\\nMathew 2012 [138]\\n\\nAir humidity\\n\\nNanocrystal and\\nnanoparticles\\n\\nNanocrystal and\\nnanoparticles\\n\\nMonitoring of\\nbreathing\\n\\nMonitoring of\\nbreathing\\n\\nMouth mask (3 cm\\nfrom nose)\\n\\nNose (5 cm away)\\n\\n1 mm length\\n\\nScully 2012 [139]\\n\\nTrobec 2012 [140]\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nPPG\\n\\nECG\\n\\nRR\\n\\nRR\\n\\nFinger (on sensor)\\n\\nChest (diﬀerent\\nregions)\\n\\n-\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n60 of 84\\n\\nTable A1. Cont.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nWitt 2012 [141]\\n\\nZieba 2012 [142]\\n\\nCarlos 2011 [143]\\n\\nCiobotariu 2011 [144]\\n\\nGuo 2011 [146]\\n\\nHoﬀmann 2011 [17]\\n\\nLiu 2011 [147]\\n\\nLiu 2011 [148]\\n\\nMann 2011 [149]\\n\\nOno 2011 [150]\\n\\nSilva 2011 [151]\\n\\nYang 2011 [152]\\n\\nYoo 2010–2011 [153–155]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAbdomen\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\nAbdomen\\nmovements\\n\\nMeasured\\nParameter\\n\\nMonitoring of\\nbreathing\\n\\nLocation\\n\\nSize\\n\\nChest\\n\\n1 cm (elastic\\npart)\\n\\nFiber optic\\n\\nResistive\\n\\nRR\\n\\nChest (shirt)\\n\\n-\\n\\nResistive\\n\\nPiezoelectric\\n\\nRR\\nCoughing\\nevents\\n\\nRR\\nMonitoring of\\nrespiratory\\ndiseases\\n\\nChest and abdomen\\n(shirt)\\n\\n5.3 × 3.2 cm\\n\\nChest\\n\\n28 cm\\n\\nResistive\\n\\nRR\\n\\nChest\\n\\n10 × 0.25 cm\\n\\nCapacitive\\n\\nRespiration\\npattern\\nTV (among\\nothers)\\n\\nChest\\n\\n3 × 3 cm\\n\\nResistive\\n\\nRR, MV\\n\\nAbdomen\\n\\n-\\n\\nAccelerometer\\n\\nRR\\n\\nAbdomen\\n\\n23 mm\\ndiameter\\n\\nAccelerometer\\n\\nAccelerometer\\n\\nFiber optic\\n\\nCapacitive\\n\\nRR\\nRespiratory\\ndisease\\nmonitoring\\n\\nNeck (Midclavicular\\nline and lower costal\\nmargin intersection)\\n\\nRR\\n\\nRR\\n\\nRespiration\\npattern\\n\\nChest\\n\\nChest (shirt)\\n\\nChest\\nAbdomen\\n\\nFiber optic\\n\\nMonitoring of\\nbreathing\\n\\nNose (below)\\nAbdomen\\n\\nAnsari 2010 [157]\\n\\nModulation\\ncardiac activity\\n\\nECG\\n\\nRR\\n\\nDe Jonckheere 2010 [158]\\n\\nMitchell 2010 [159]\\n\\nZhang 2010 [160]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nFiber optic\\n\\nResistive\\n\\nFrequency shift\\n\\nMonitoring of\\nbreathing\\n\\nRespiration\\npattern\\n\\nRespiration\\nsignal\\n\\nArm\\nForearm\\n\\nChest\\nAbdomen\\n\\nChest\\nAbdomen\\n\\nChest\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nTable A2. Analysis of sensing techniques, sensors, breathing parameters, and sensor location and size\\nfor studies of the environmental category published before 2018.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nAzimi 2017 [183]\\n\\nChest wall\\nmovements\\n\\nPressure\\n(piezoelectric)\\n\\nCho 2017 [184]\\n\\nLeicht 2017 [185]\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nCamera\\n\\nMeasured\\nParameter\\n\\nRR\\n\\nRR\\nRespiratory\\npattern\\n\\nLocation\\n\\nSize\\n\\nMat\\n\\n-\\n\\n80 × 90 cm\\n\\n7.2 × 2.6 × 1.8 cm\\n\\nInductive\\n\\nRR\\n\\nOthers (vehicle\\nseatbelt)\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n61 of 84\\n\\nTable A2. Cont.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nLocation\\n\\nSize\\n\\nCamera\\n\\nRR\\n\\nLi 2017 [186]\\n\\nLi 2017 [187]\\n\\nPrathosh 2017 [10]\\n\\nProchazka 2017 [188]\\n\\nTataraidze 2017 [7]\\n\\nWang 2017 [189]\\n\\nHeldt 2016 [5]\\n\\nKukkapalli 2016 [190]\\n\\nProchazka 2016 [191]\\n\\nTveit 2016 [192]\\n\\nUshijima 2016 [6]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nFiber optic\\n\\nCamera\\n\\nCamera\\n\\nRadar\\n\\nRadar\\n\\nRadar\\n\\nRadar\\n\\nKinect\\n\\nCamera\\n\\nKinect\\n\\nErden 2015 [193]\\n\\nChest wall\\nmovements\\n\\nPyroelectric\\nVibration\\n\\nRR\\n\\nHuang 2015 [54]\\n\\nModulation\\ncardiac activity\\n\\nRadar\\n\\nLiu 2015 [194]\\n\\nPereira 2015 [195]\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nPiezoelectric\\n\\nCamera\\n\\nRavichandran 2015 [196]\\n\\nModulation\\ncardiac activity\\n\\nWi-Fi transmitter\\nand receiver\\n\\nSasaki 2015 [197]\\n\\nZakrzewski 2015 [198]\\n\\nArlotto 2014 [199]\\n\\nBernacchia 2014 [200]\\n\\nBernal 2014 [51]\\n\\nChen 2014 [201]\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nRadar\\n\\nRadar\\n\\nRadar\\n\\nKinect\\n\\nCamera\\n\\nMeasured\\nParameter\\n\\nRR\\n\\nRR\\n\\nRR\\nRespiratory\\npattern\\n\\nRR\\nMovement\\nactivity periods\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nRespiratory\\npatterns\\n\\nRR\\nRespiratory\\npattern\\n\\nRR\\n\\nRR\\nFalls\\n\\nRR\\n\\nRR\\n\\nMat\\n\\nDistance from\\nsubject (1.4 m above)\\n\\nDistance from\\nsubject (0.91 m away)\\n\\nDistance from subject\\n(in front of face)\\n\\nDistance from subject\\n\\nDistance from subject\\n(5–55 cm away)\\n\\nDistance from subject\\n(15–50 cm away)\\n\\nOthers (neck\\npendant)\\n\\nDistance from subject\\n(in front of face)\\n\\nDistance from\\nsubject (above)\\n\\nDistance from\\nsubject (20–100 cm\\nabove, pyroelectric)\\nMat (vibration)\\n\\nDistance from\\nsubject (1 m away)\\n\\nDistance from subject\\n(1.5–2 m away)\\n\\nDistance from subject\\n(0.9–4.3 m away)\\n\\nDistance from\\nsubject (1–2 m above,\\ndiagonally)\\n\\nDistance from\\nsubject (1.5 m above)\\n\\nRespiration\\ndetection\\n\\nDistance from subject\\n(0.8–4 m away)\\n\\nBreathing\\nmonitoring\\n\\nDistance from\\nsubject (30 cm away)\\n\\nRR\\n\\nDistance from subject\\n(120 cm above)\\n\\nRespiratory\\npattern, peak\\ninspiratory and\\nexpiratory ﬂow,\\nvital capacity\\n\\nDistance from\\nsubject (above)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nFiber optic\\n\\nRR\\n\\nMat\\n\\n25 × 20 cm\\n\\nLee 2014 [52]\\n\\nModulation\\ncardiac activity\\n\\nRadar\\n\\nRR\\nTV\\nRespiratory\\npattern\\n\\nDistance from\\nsubject (80 cm away)\\n\\n-\\n\\nMat\\n\\n250 × 125 cm\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n62 of 84\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nMeasured\\nParameter\\n\\nLocation\\n\\nSize\\n\\nTable A2. Cont.\\n\\nDiﬀerent electrode\\nsizes:\\n9 × 24 cm;\\n14 × 25 cm;\\n22 × 4 cm;\\n10 × 10 cm\\n\\n478 × 478 × 3.5 mm\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nLuis 2014 [202]\\n\\nChest wall\\nmovements\\n\\nCapacitive\\n\\nRespiration\\nsignal\\n\\nMat (chest region)\\n\\nMukai 2014 [203]\\n\\nNukaya 2014 [204]\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nCapacitive\\n\\nRR\\n\\nMat (chest region)\\n\\nPiezoelectric\\n\\nBreathing\\nmonitoring\\n\\nOthers (below a\\nneonatal bed)\\n\\nPatwari 2014 [205]\\n\\nModulation\\ncardiac activity\\n\\nWi-Fi transmitter\\nand receiver\\n\\nRR\\n\\nNodes\\n\\nPatwari 2014 [206]\\n\\nModulation\\ncardiac activity\\n\\nWi-Fi transmitter\\nand receiver\\n\\nRR\\nAmplitude and\\nphase\\n\\nRR\\nExhalation ﬂow\\nrate\\n\\nCamera\\n\\nRadar\\n\\nRR\\n\\nNodes\\n\\nDistance from\\nsubject (0.5 m away)\\n\\nDistance from\\nsubject (beside bed)\\n\\nCamera\\n\\nRespiratory\\npattern\\n\\n-\\n\\nCamera\\n\\nRR\\n\\nFiber optic\\n\\nOxygen\\nconcentration\\n\\nDistance from\\nsubject (beside bed)\\n\\nOthers (inside\\nmeasurement\\ninstrument)\\n\\nFiber optic\\n\\nPiezoelectric\\n\\nFiber optic\\n\\nRR\\n\\nRR\\n\\nRR Respiratory\\npattern\\n\\nRespiratory\\nmonitoring\\nRespiratory\\npattern\\n\\nMat (chest region)\\n\\nMat\\n\\nDistance from\\nsubject (1–3 m away)\\n\\nFiber optic\\n\\nRadar\\n\\nRadar\\n\\nKinect\\n\\nRR\\n\\nRR\\n\\nMat\\n\\nDistance from\\nsubject (1 m above)\\n\\nRespiration\\ndetection\\n\\nDistance from subject\\n(1–1.5 m away)\\n\\nExhalation ﬂow\\nrate\\n\\nDistance from\\nsubject (1.2 m away,\\n1.1 m height)\\n\\nInfrared\\n\\nRR\\n\\nDistance from subject\\n\\nNijsure 2013 [50]\\n\\nModulation\\ncardiac activity\\n\\nRadar\\n\\nShao 2014 [48]\\n\\nTaheri 2014 [207]\\n\\nWang 2014 [53]\\n\\nBartula 2013 [208]\\n\\nChen 2013 [209]\\n\\nDziuda 2013 [210]\\n\\nKlap 2013 [211]\\n\\nLau 2013 [19]\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nRespiratory\\nairﬂow\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nSprager 2013 [212]\\n\\nVinci 2013 [213]\\n\\nYavari 2013 [214]\\n\\nAoki 2012 [215]\\n\\nBoccanfuso 2012 [216]\\n\\nBruser 2012 [217]\\n\\nChen 2012 [218]\\n\\nDziuda 2012 [9,236]\\n\\nGu 2012 [219]\\n\\nLokavee 2012 [220]\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nAir\\ntemperature\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nOptical\\n\\nFiber optic\\n\\nRespiratory\\nactivity\\n\\nRR\\nRespiratory\\npattern\\n\\nMat\\n\\nMat\\n\\n200 × 90 cm\\n\\n-\\n\\nFiber optic\\n\\nRR\\n\\nMat (pneumatic\\ncushion)\\n\\n36 cm diameter,\\n7 cm height\\n\\nRadar\\n\\nBreathing\\nmonitoring\\n\\nDistance from\\nsubject (50 cm above)\\n\\n5 × 5 cm\\n\\nResistive\\n\\nRR\\n\\nMat, pillow\\n\\n-\\n\\nMat\\n\\n220 × 95 × 1.5 mm\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n63 of 84\\n\\nTable A2. Cont.\\n\\nStudy\\n\\nTechnique\\n\\nSensor\\n\\nShimomura 2012 [221]\\n\\nXia 2012 [222]\\n\\nLai 2011 [223]\\n\\nOtsu 2011 [224]\\n\\nPostolache 2011 [225]\\n\\nZito 2011 [226]\\n\\nHeise 2010 [227]\\n\\nMin 2010 [228]\\n\\nMostov 2010 [229]\\n\\nNishiyama 2010\\n[230,231]\\n\\nScalise 2010 [232]\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nChest wall\\nmovements\\n\\nModulation\\ncardiac activity\\n\\nSilvious 2010 [233]\\n\\nModulation\\ncardiac activity\\n\\nRadar\\n\\nKinect\\n\\nRadar\\n\\nRadar\\n\\nRadar\\n\\nRadar\\n\\nResistive\\n\\nUltrasonic\\n(proximity)\\n\\nRadar\\n\\nFiber optic\\n\\nRadar\\n\\nRadar\\n\\nTan 2010 [234]\\n\\nChest wall\\nmovements\\n\\nCamera\\n\\nMeasured\\nParameter\\n\\nRR\\n\\nRespiration\\nsignal\\n\\nRR\\nRespiration\\namplitude\\n\\nRR\\n\\nRR\\n\\nBreathing\\nmonitoring\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nLocation\\n\\nSize\\n\\nDistance from\\nsubject (2 m above)\\n\\nDistance from\\nsubject (above)\\n\\n-\\n\\n-\\n\\nDistance from\\nsubject (1 m away)\\n\\n3 × 4 cm (antenna)\\n\\nDistance from\\nsubject (0.8 m above)\\n\\nOthers (embedded in\\nwheelchair)\\n\\nDistance from\\nsubject (25–40 cm\\nfrom chest)\\n\\n-\\n\\nMat\\n\\n130 × 7.6 cm\\n\\nDistance from\\nsubject (1 m away)\\n\\nDistance from\\nsubject (2 m away)\\n\\n-\\n\\n10 × 10 × 5 cm\\n\\nRespiration\\nmonitoring\\n\\nMat (bed, chest\\nregion)\\n\\nRR\\n\\nRR\\n\\nRR\\n\\nDistance from\\nsubject (1.5 m away,\\nperpendicular)\\n\\nNodes (transmitter:\\n11.3 m from subject;\\nreceiver: 4.3 m from\\nsubject)\\n\\nDistance from subject\\n(0.5–1 m away)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nTable A3. Analysis of transmission technology, processing station, and energy autonomy for studies in\\nthe wearable category published before 2018.\\n\\nWired\\nTransmission\\n\\nProcessing\\nStation\\n\\nBattery\\nCapacity\\n\\nBattery Life\\n(Type Battery)\\n\\nStudy\\n\\nAgcayazi 2017 [123]\\n\\nWireless\\nTransmission\\n\\nBluetooth\\n(low energy)\\n\\nAileni 2017 [134]\\n\\nBluetooth\\n\\nBasra 2017 [145]\\n\\n-\\n\\n-\\n\\n-\\n\\nSerial\\ncommunication\\nLCD integrated\\n\\n-\\n\\nPC,\\nsmartphone,\\ntablet device\\n\\nMicrocontroller,\\nPC, mixed\\nsignal\\noscilloscope\\n\\nSmartphone,\\ncloud storage\\n\\nBhattacharya 2017 [156]\\n\\nWi-Fi\\n\\n-\\n\\nDas 2017 [162]\\n\\nFajkus 2017 [83]\\n\\nGorgutsa 2017 [84]\\n\\nGuay 2017 [85]\\n\\nKam 2017 [86–88]\\n\\n-\\n\\n-\\n\\nMono audio jack\\n\\nInterrogator\\n\\nPC\\n\\nPC\\n\\nBluetooth\\n(low energy)\\n\\n-\\n\\nPC, tablet\\ndevice\\n\\n-\\n\\n-\\n\\nGPIB interface\\n\\nUSB\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\n9 V, 500 mAh\\n\\n-\\n\\n9 V, 500 mAh\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n(Rechargeable\\nbattery and 630\\nmV solar cell)\\n\\n-\\n\\n(5 V DC power\\nbank)\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n64 of 84\\n\\nTable A3. Cont.\\n\\nStudy\\n\\nKano 2017 [89]\\n\\nKoch 2017 [90]\\n\\nWireless\\nTransmission\\n\\nBluetooth\\n\\n-\\n\\nMilici 2017 [91]\\n\\nBackscattered ﬁeld\\n\\nWired\\nTransmission\\n\\nProcessing\\nStation\\n\\nBattery\\nCapacity\\n\\nBattery Life\\n(Type Battery)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nCloud storage\\n\\n9 V, 500 mAh\\n\\n-\\n\\n330 h\\n\\n-\\n\\n-\\n>1 year\\n\\nNakazumi 2017 [92]\\n\\nPark 2017 [93]\\n\\nPresti 2017 [94]\\n\\nValipour 2017 [95]\\n\\nWhite 2017 [96]\\n\\nYan 2017 [97]\\n\\n-\\n\\n-\\n\\n-\\n\\nDAQ (Arduino)\\n\\nDAQ\\n\\nInterrogator\\n\\nRadio-frequency\\ntransceiver\\n\\nWi-Fi\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nCloud storage\\n\\n600 mAh\\n\\n40 days\\n\\nMahbub 2016–2017\\n[98,99]\\n\\nImpulse radio\\nultra-wide band\\n\\nChethana 2016 [100]\\n\\n-\\n\\nInterrogator\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nTablet device,\\nsmartphone,\\ncloud storage\\n\\nSmartphone\\n\\nGüder 2016 [101]\\n\\nBluetooth\\n\\nLepine 2016 [102]\\n\\nMassaroni 2016 [103]\\n\\nMassaroni 2016 [49]\\n\\nMoradian 2016 [104]\\n\\nBluetooth\\n(low energy)\\n\\nPassive\\nultra-high-frequency\\nRFID\\n\\nNag 2016 [105]\\n\\nNam 2016 [106]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nInterrogator\\n\\nInterrogator\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\nData storage\\n\\nOscilloscope\\n\\n-\\n\\nPC\\n\\nRaji 2016 [107]\\n\\nRadio-frequency\\n\\n-\\n\\nCloud storage\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nSerial\\ncommunication\\n\\nPC\\n\\nUSB\\n\\n-\\n\\nInterrogator\\n\\nData storage\\n\\n-\\n\\nUSB\\n\\nData storage\\n\\nTablet device\\n\\n-\\n\\nPC\\n\\nPC\\n\\n-\\n\\nPC\\n\\nPC\\n\\nBluetooth\\n(low energy)\\n\\n-\\n\\nPC,\\nsmartphone\\n\\nRamos-García 2016 [108]\\n\\nRotariu 2016 [109]\\n\\nAtalay 2015 [110]\\n\\nCiocchetti 2015 [111]\\n\\nEstrada 2015 [112]\\n\\nGargiulo 2015 [113]\\n\\nGrlica 2015 [114]\\n\\nHernandez 2015 [115]\\n\\nJiang 2015 [116]\\n\\nKarlen 2015 [117]\\n\\nKazmi 2015 [118]\\n\\nMetshein 2015 [21]\\n\\n-\\n\\n-\\n\\n-\\n\\nTeichmann 2015 [119]\\n\\nBluetooth\\n\\nWei 2015 [120]\\n\\nYang 2015 [3]\\n\\n-\\n\\nBluetooth\\n\\nBifulco 2014 [121]\\n\\n-\\n\\nFekr 2014 [122]\\n\\nBluetooth\\n(low energy)\\n\\nData storage\\n\\nUSB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\nPC\\n\\n-\\n\\nPC,\\nsmartphone,\\ntablet device,\\ncloud storage\\n\\nHesse 2014 [124]\\n\\nKrehel 2014 [125]\\n\\n-\\n\\n-\\n\\nData storage\\n\\nInterrogator\\n\\nPC\\n\\nPC\\n\\n-\\n\\n9 h\\n\\n-\\n\\n-\\n\\n-\\n\\n(Self-powered\\npassive sensor)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n>25 days\\n\\n6–9 h\\n\\n(Rechargeable\\nbattery, wireless\\ncharger)\\n\\n-\\n\\n-\\n\\n-\\n\\n2600 mAh\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n2000 mAh\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nSmartphone\\n\\n2.95 Wh\\n\\n2.23 h\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n65 of 84\\n\\nTable A3. Cont.\\n\\nWireless\\nTransmission\\n\\nWired\\nTransmission\\n\\nProcessing\\nStation\\n\\nBattery\\nCapacity\\n\\nBattery Life\\n(Type Battery)\\n\\nStudy\\n\\nMin 2014 [126]\\n\\nPetrovic 2014 [127]\\n\\nSanchez 2014 [128]\\n\\nWo 2014 [129]\\n\\nYang 2014 [130]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nBluetooth\\n(low energy)\\n\\nYoon 2014 [131]\\n\\nBluetooth\\n\\nChan 2013 [132]\\n\\nHuang 2013 [133]\\n\\nKundu 2013 [161]\\n\\nPadasdao 2013 [135]\\n\\nBluetooth\\n(low energy)\\n\\n-\\n\\n-\\n\\n-\\n\\nCao 2012 [2]\\n\\nBluetooth\\n\\nChiu 2012 [136]\\n\\nFavero 2012 [137]\\n\\nMathew 2012 [138]\\n\\nScully 2012 [139]\\n\\nTrobec 2012 [140]\\n\\nWitt 2012 [141]\\n\\nZieba 2012 [142]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nCarlos 2011 [143]\\n\\nBluetooth\\n\\nCiobotariu 2011 [144]\\n\\nWi-Fi, GSM\\n\\nGuo 2011 [146]\\nHoﬀmann 2011 [17]\\n\\nBluetooth\\n\\nBluetooth\\n\\nLiu 2011 [147]\\n\\n-\\n\\nLiu 2011 [148]\\n\\nMann 2011 [149]\\n\\nOno 2011 [150]\\n\\nSilva 2011 [151]\\n\\nRadio-frequency\\n(transceiver)\\n\\n-\\n\\n-\\n\\n-\\n\\nYang 2011 [152]\\n\\nBluetooth\\n\\nYoo 2010–2011 [153–155]\\n\\nAnsari 2010 [157]\\n\\nDe Jonckheere 2010 [158]\\n\\n-\\n\\n-\\n\\n-\\n\\nMitchell 2010 [159]\\n\\nZhang 2010 [160]\\n\\nZigbee\\n\\nBluetooth\\n\\n-\\n\\nInterrogator\\n\\nSpectrometer\\n\\nDAQ\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nSmartphone\\n\\nPC\\n\\nSmartphone\\n\\nPC\\n\\n-\\n\\n-\\n\\nSmartphone\\n\\n1000 mAh\\n\\nPC\\n\\n-\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nPC, cloud\\nstorage\\n\\nTablet device\\n\\nPC\\n\\nPC\\n\\nPC\\n\\nBase station\\n\\nPC\\n\\nPC\\n\\n-\\n\\nPC\\n\\nPC\\n\\n-\\n\\nPC\\n\\nPC\\n\\nPC\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n590 mAh\\n\\n370 mAh\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nUSB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nInterrogator\\n\\nInterrogator\\n\\nData storage\\n\\n-\\n\\nUSB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nData Storage (SD\\ncard)\\n\\n-\\n\\n-\\n\\nData storage\\n\\nInterrogator\\n\\n-\\n\\nDAQ\\n\\n-\\n\\nUSB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n24 h\\n\\n(Li-polymer\\nbattery)\\n\\n(Coin battery)\\n\\n-\\n\\n-\\n\\n-\\n>10 h\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n5 weeks\\n\\n-\\n\\n12 h\\n\\n54 h\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nTable A4. Analysis of the processing algorithm, performance evaluation, and software for the studies\\nof the wearable category published before 2018.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nPerformance\\nValue\\n\\nAnalysis Software\\n\\nAgcayazi 2017 [123]\\n\\nAileni 2017 [134]\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\n-\\n\\nBasra 2017 [145]\\n\\nFrequency analysis\\n\\nGraphical monitoring\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n66 of 84\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nPerformance\\nValue\\n\\nAnalysis Software\\n\\nTable A4. Cont.\\n\\nBhattacharya 2017 [156]\\n\\nThreshold\\ndetection\\n\\nGraphical comparison\\n\\nDas 2017 [162]\\n\\n-\\n\\nGraphical monitoring\\n\\n-\\n\\n-\\n\\nFajkus 2017 [83]\\n\\nFrequency analysis\\n\\nRelative error\\n\\n3.9%\\n\\nGorgutsa 2017 [84]\\n\\nGuay 2017 [85]\\n\\nKam 2017 [86–88]\\n\\nKano 2017 [89]\\n\\nReceived signal\\nstrength indicator\\n\\n-\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\nGraphical monitoring\\n\\n-\\n\\n-\\n\\nRelative error\\n\\n<4.08%\\n\\nGraphical monitoring\\n\\nBlynk\\n\\nAudacity\\n\\nMATLAB\\n\\nCustom application\\n\\nLabview\\n\\nLabview\\nMATLAB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\nMATLAB\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\nLabWindows/CVI\\n\\n-\\n\\nMATLAB\\n\\nMATLAB\\n\\nMATLAB\\n\\nC#\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n0.006–0.008 bpm\\n(BA MOD)\\n\\n1.26 bpm (RMSE)\\n0.1 bpm\\n(BA, MOD)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n2.11–5.98 bpm\\n<0.14 s (BA, MOD)\\n1.14% (PE)\\n−1.59% (RE for RR)\\n14% (RE for TV)\\n\\n-\\n\\n-\\n<1%\\n\\n0.41\\n\\n-\\n\\n0.87 (correlation)\\n8.3% (PE)\\n<0.002 s (BA, mean\\ndiﬀerence, time\\nbetween peaks)\\n\\n0.8–0.97\\n(correlation)\\n−0.01 bpm\\n(BA, MOD)\\n<10%\\n\\nKoch 2017 [90]\\n\\nCustom algorithm\\n\\nGraphical monitoring\\n\\nMilici 2017 [91]\\n\\nPeak detection\\n\\nGraphical comparison\\n\\nNakazumi 2017 [92]\\n\\nPark 2017 [93]\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\nGraphical monitoring\\n\\nPresti 2017 [94]\\n\\nMax-min detection\\n\\nBland-Altman analysis\\n\\nValipour 2017 [95]\\n\\n-\\n\\nRoot mean square error\\nBland-Altman analysis\\n\\nWhite 2017 [96]\\n\\nFrequency analysis\\n\\n-\\n\\nYan 2017 [97]\\n\\nMahbub 2016–2017 [98,99]\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\nGraphical monitoring\\n\\nChethana 2016 [100]\\n\\nFrequency analysis\\n\\n-\\n\\nGüder 2016 [101]\\n\\n-\\n\\nGraphical monitoring\\n\\nLepine 2016 [102]\\n\\nKalman ﬁlter\\n\\nAbsolute error\\n\\nMassaroni 2016 [103]\\n\\nMax-min detection\\n\\nBland-Altman analysis\\nPercentage error\\n\\nMassaroni 2016 [49]\\n\\nMoradian 2016 [104]\\n\\nNag 2016 [105]\\n\\nMax-min detection\\nCustom algorithm\\n\\nRelative error\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\nGraphical monitoring\\n\\nNam 2016 [106]\\n\\nFrequency analysis\\n\\nMean relative error\\n\\nRaji 2016 [107]\\n\\nRamos-García 2016 [108]\\n\\nThreshold\\ndetection\\n\\nPeak detection\\nFrequency analysis\\n\\nRoot mean square error\\n\\n1.7–2 bpm\\n\\nCorrelation factor\\n\\nRotariu 2016 [109]\\n\\nPeak detection\\n\\nAtalay 2015 [110]\\n\\nFrequency analysis\\n\\n-\\n\\n-\\n\\nCiocchetti 2015 [111]\\n\\nPeak detection\\nCustom algorithm\\nManual veriﬁcation\\n\\nCorrelation factor\\nPercentage error\\nBland-Altman analysis\\n\\nEstrada 2015 [112]\\n\\nPeak detection\\nCustom Algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\nGargiulo 2015 [113]\\n\\nGrlica 2015 [114]\\n\\n-\\n\\n-\\n\\nRelative error\\n\\nGraphical monitoring\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n67 of 84\\n\\nTable A4. Cont.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nHernandez 2015 [115]\\n\\nMax-min detection\\nFrequency analysis\\n\\nBland-Altman analysis\\nMean absolute error\\nRoot mean square error\\n\\nPerformance\\nValue\\n\\n0.15 bpm\\n(BA, MOD)\\n0.38 bpm (MAE)\\n1.25 bpm (RMSE)\\n\\nJiang 2015 [116]\\n\\nCustom algorithm\\n\\nRespiration simulation\\n\\n-\\n\\nAnalysis Software\\n\\n-\\n\\n-\\n\\nKarlen 2015 [117]\\n\\nCustom algorithm\\n\\nBland-Altman analysis\\nRoot mean square error\\n\\n6.01 bpm (RMSE)\\n\\nMATLAB\\n\\nKazmi 2015 [118]\\n\\nMetshein 2015 [21]\\n\\nTeichmann 2015 [119]\\n\\n-\\n\\n-\\n\\nFrequency analysis\\n(Frequency\\nmodulation)\\nCustom algorithm\\n\\nGraphical comparison\\n\\nGraphical comparison\\n\\nGraphical comparison\\n\\nWei 2015 [120]\\n\\n-\\n\\n-\\n\\nYang 2015 [3]\\n\\nManual veriﬁcation\\n\\nGraphical comparison\\n\\nBifulco 2014 [121]\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nFekr 2014 [122]\\n\\nNumeric\\nintegration\\nalgorithm\\n\\nCorrelation factor\\nRelative error\\n\\n0.85 (correlation)\\n0.2% (RE)\\n\\nEasy pulse\\nanalyzer\\nCool term software\\nKuvios HRV\\n\\n-\\n\\nMicrocontroller\\n\\n-\\n\\nLabview\\n\\n-\\n\\n-\\n\\nHesse 2014 [124]\\n\\nPeak detection\\n\\nMean absolute error\\n\\n0.32 bpm\\n\\nMicrocontroller\\n\\nKrehel 2014 [125]\\n\\n-\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\n±3 bpm (BA)\\n\\nMATLAB\\n\\nMin 2014 [126]\\n\\nPeak detection\\nCustom Algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\nPetrovic 2014 [127]\\n\\nSanchez 2014 [128]\\n\\n-\\n\\n-\\n\\nWo 2014 [129]\\n\\nFrequency analysis\\n\\nMean relative error\\nBland-Altman analysis\\n\\n-\\n\\n-\\n\\nYang 2014 [130]\\n\\n-\\n\\nGraphical monitoring\\n\\nYoon 2014 [131]\\n\\nKalman ﬁlter\\n\\nRelative error\\n\\nChan 2013 [132]\\n\\nHuang 2013 [133]\\n\\nKundu 2013 [161]\\n\\n-\\n\\n-\\n\\n-\\n\\nAbsolute error\\n\\nAccuracy\\n\\nAccuracy\\nCoeﬃcient of\\ndetermination\\n\\nPadasdao 2013 [135]\\n\\nFrequency analysis\\n(Fast Fourier\\nTransform)\\n\\nBland-Altman analysis\\nMean absolute error\\n\\n0.98 (correlation)\\n0.0015 bpm\\n(BA, MOD)\\n\\n8.7% (RE-MV-)\\n10.5% (RE-TV-)\\n−1 (BA, MOD)\\n\\n-\\n\\n-\\n\\n-\\n\\n7.3%\\n\\n<2 bpm\\n\\n98.8%\\n\\n100% (acc)\\n0.906 (r2)\\n\\n0.23–0.48 bpm\\n(BA, MOD)\\n0.00027 bpm\\n(MAE)\\n\\nMATLAB\\n\\nMATLAB\\nLabview\\n\\n-\\n\\nLabview\\n\\n-\\n\\nMATLAB\\nLabview\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nCao 2012 [2]\\n\\nPeak detection\\n\\nGraphical comparison\\n\\n-\\n\\nLabview\\n\\nChiu 2012 [136]\\n\\nFrequency analysis\\n\\nPaired t-test\\n\\nFavero 2012 [137]\\n\\n-\\n\\n-\\n\\nMathew 2012 [138]\\n\\nZero-crossing\\ndetection\\n\\nGraphical monitoring\\n\\nNo statistical\\ndiﬀerence with\\nreference\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\nLabview\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n68 of 84\\n\\nTable A4. Cont.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nPerformance\\nValue\\n\\nAnalysis Software\\n\\nScully 2012 [139]\\n\\nTrobec 2012 [140]\\n\\nFrequency analysis\\n(Frequency\\nmodulation)\\n\\nECG-derived\\nalgorithm\\n\\nGraphical comparison\\n\\n-\\n\\nWitt 2012 [141]\\n\\n-\\n\\nGraphical comparison\\n\\nZieba 2012 [142]\\n\\nManual veriﬁcation\\n\\n-\\n\\nCarlos 2011 [143]\\n\\n-\\n\\nGraphical monitoring\\n\\nCiobotariu 2011 [144]\\n\\nMax-min detection\\nCustom algorithm\\n\\nGuo 2011 [146]\\n\\nPeak detection\\n\\nHoﬀmann 2011 [17]\\n\\nCustom algorithm\\n\\nGraphical comparison\\n\\nSimulation\\nGraphical comparison\\n\\nCorrelation factor\\nRelative error\\n\\nLiu 2011 [147]\\n\\nEmpirical Mode\\nDecomposition\\n\\nMean percentage error\\nRoot mean square error\\n\\nLiu 2011 [148]\\n\\nMann 2011 [149]\\n\\nPrincipal\\nComponent\\nAnalysis\\nFrequency analysis\\n\\nThreshold\\ndetection\\n\\nRelative error\\n\\nCorrelation factor\\n\\nOno 2011 [150]\\n\\nCustom algorithm Displacement comparison\\n\\nSilva 2011 [151]\\n\\nFrequency analysis\\n\\nGraphical comparison\\n\\nYang 2011 [152]\\n\\nYoo 2010–2011 [153–155]\\n\\n-\\n\\n-\\n\\n-\\n\\nGraphical monitoring\\n\\nAnsari 2010 [157]\\n\\nFrequency analysis\\n\\n-\\n\\nDe Jonckheere 2010 [158]\\n\\n-\\n\\nGraphical comparison\\nBland-Altman analysis\\n\\nMitchell 2010 [159]\\n\\nManual veriﬁcation\\n\\nGraphical comparison\\n\\nZhang 2010 [160]\\n\\n-\\n\\nBiofeedback (audiovisual\\nfeedback signal)\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\nMATLAB\\n\\n-\\n\\nLabview\\n\\nCustom application\\n\\nC#\\n\\nLabview\\n\\n0.92 (correlation)\\n\\n6.1%, 14.6% (MPE)\\n4.1 bpm, 9.8 bpm\\n(RMSE)\\n\\n10%\\n\\n0.97\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nObjective-C\\n\\n-\\n\\n-\\n\\nLabview\\n\\n-\\n\\n-\\n\\nPhysput\\n\\nMATLAB\\n\\nTable A5. Analysis of the processing algorithm, performance evaluation, and software for the studies\\nof the environmental category published before 2018.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nAzimi 2017 [183]\\n\\nPeak detection\\nCustom algorithm\\n\\nLinear regression\\n\\nCho 2017 [184]\\n\\nCustom algorithm\\n\\n-\\n\\nLeicht 2017 [185]\\n\\n-\\n\\nGraphical comparison\\n\\nLi 2017 [186]\\n\\nFrequency analysis\\n\\nGraphical monitoring\\n\\nPerformance\\nValue\\n\\n0.968 and 1.0223\\n(slope)\\n\\n-\\n\\n-\\n\\n-\\n\\nLi 2017 [187]\\n\\nCustom algorithm\\n\\nRoot mean square error\\n\\n1.12 bpm\\n\\nPrathosh 2017 [10]\\n\\nCustom algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\n0.94 (correlation)\\n0.88 bpm\\n(BA, MOD)\\n\\nProchazka 2017 [188]\\n\\nNeural Network\\n\\n-\\n\\nTataraidze 2017 [7]\\n\\nPeak detection\\nCustom algorithm\\n\\nAccuracy\\n\\n-\\n\\n97%\\n\\nAnalysis Software\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\nMATLAB\\n\\nOpenCV\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n69 of 84\\n\\nTable A5. Cont.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nPerformance\\nValue\\n\\nAnalysis Software\\n\\nWang 2017 [189]\\n\\nHeldt 2016 [5]\\n\\nFrequency analysis\\n(Short-Time Fourier\\nTransform)\\n\\nThreshold\\ndetection\\n\\nAbsolute error\\n\\n0.11–0.33 bpm\\n\\n-\\n\\nMean absolute error\\n\\n1.2 bpm\\n\\nAcknowledge\\n\\nKukkapalli 2016 [190]\\n\\nPeak detection\\n\\nAccuracy\\n\\n>95%\\n\\nProchazka 2016 [191]\\n\\nCustom algorithm\\n\\nRelative error\\n\\n0.06–0.26%\\n\\nTveit 2016 [192]\\n\\nPhase-based\\nrespiration\\ndetection\\nPixel-intensity\\ndetection\\n\\nManual veriﬁcation\\nRelative error\\n\\n7.21–11.57%\\n\\nUshijima 2016 [6]\\n\\n-\\n\\nGraphical comparison\\n\\nErden 2015 [193]\\n\\nHuang 2015 [54]\\n\\nLiu 2015 [194]\\n\\nWavelet transform\\nEmpirical mode\\ndecomposition\\n\\nPeak detection\\nThreshold\\ndetection\\n\\nPeak detection\\nThreshold\\ndetection\\n\\nPereira 2015 [195]\\n\\nCustom algorithm\\n\\nRavichandran 2015 [196]\\n\\nSasaki 2015 [197]\\n\\nZakrzewski 2015 [198]\\n\\nZero-crossing\\ndetection\\nFrequency analysis\\nLinear predictive\\ncoding\\nLeast-squares\\nharmonic analysis\\n\\n-\\nLinear/ non-Linear\\ndemodulation\\n\\nAccuracy\\n\\n-\\n\\nRelative error\\n\\n1.8–5.7%\\n\\nCorrelation factor\\nMean Absolute Error\\nBland-Altman analysis\\n\\n0.92 (correlation)\\n0.53 bpm (MAE)\\n0.025 bpm\\n(BA, MOD)\\n\\nAbsolute error\\n\\n2.16 bpm\\n\\nRelative error\\n\\nMean squared error\\n\\n-\\n\\n93%\\n\\n-\\n\\n3%\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\nMATLAB\\n\\nArlotto 2014 [199]\\n\\n-\\n\\nGraphical comparison\\n\\nBernacchia 2014 [200]\\n\\nCustom algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\n0.96 (correlation)\\n0 bpm (BA, MOD)\\n\\nBernal 2014 [51]\\n\\nPeak detection\\nZero-crossing\\ndetection\\nCustom algorithm\\n\\nGraphical comparison\\n\\n-\\n\\n-\\n\\nChen 2014 [201]\\n\\nPeak detection\\n\\nAbsolute error\\nRelative error\\n\\nLee 2014 [52]\\n\\nFrequency analysis\\n\\nCorrelation factor\\nRoot mean square error\\n\\nLuis 2014 [202]\\n\\nCustom algorithm\\n\\nMukai 2014 [203]\\n\\nFrequency analysis\\n\\n-\\n\\n-\\n\\nNukaya 2014 [204]\\n\\n-\\n\\nScatterplot\\n\\n1.65 bpm (AE)\\n9.9% (RE)\\n\\n0.90–0.976\\n(correlation)\\n0.0038–0.076 bpm\\n(RMSE)\\n\\n-\\n\\n-\\n\\n-\\n\\nPatwari 2014 [205]\\n\\nFrequency analysis\\n\\nRelative error\\n\\n1 bpm\\n\\nPatwari 2014 [206]\\n\\nCustom algorithm\\n\\nRelative error\\n\\n0.1 to 0.4 bpm\\n\\nLabview\\n\\nMATLAB\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n70 of 84\\n\\nTable A5. Cont.\\n\\nStudy\\n\\nAlgorithm\\n\\nPerformance Evaluation\\n\\nShao 2014 [48]\\n\\nCustom algorithm\\n\\nTaheri 2014 [207]\\n\\nCustom algorithm\\n\\nCorrelation factor\\nBland-Altman analysis\\nRoot mean square error\\n\\nMean absolute error\\nAccuracy\\n\\nWang 2014 [53]\\n\\nThreshold\\ndetection\\n\\nOthers (confusion matrix)\\n\\nBartula 2013 [208]\\n\\nCustom algorithm\\n\\nCorrelation factor\\n\\nChen 2013 [209]\\n\\nFrequency analysis\\n\\nDziuda 2013 [210]\\n\\nMax detection\\n\\nKlap 2013 [211]\\n\\nProprietary\\nalgorithms\\n\\nLau 2013 [19]\\n\\nPeak detection\\n\\nLinear regression\\nBland-Altman analysis\\n\\nRelative error\\nBland-Altman analysis\\n\\nPerformance\\nValue\\n\\n0.93 (correlation)\\n0.02 bpm\\n(BA, MOD)\\n1.2 bpm (RMSE)\\n\\n0.93–1.77 bpm\\n(MAE)\\n79–89% (Acc)\\n\\n94%\\n\\n0.98\\n\\n0.999 (r2)\\n\\nAnalysis Software\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\n<8% (RE)\\n0 bpm (BA, MOD)\\n\\nCustom application\\n\\nRelative error\\n\\n4–8% (RE)\\n\\n-\\n\\nCorrelation factor\\nMean absolute error\\n\\n0.971 (correlation)\\n2 bpm (MAE)\\n\\n0.98 (correlation)\\n\\nKinect SDK\\n\\nNijsure 2013 [50]\\n\\nCustom algorithm\\n\\nCorrelation factor\\n\\nSprager 2013 [212]\\n\\nWavelet transform\\n\\nRelative error\\n\\nVinci 2013 [213]\\n\\nFrequency analysis\\n\\nGraphical comparison\\n\\nYavari 2013 [214]\\n\\n-\\n\\nGraphical comparison\\n\\n0.814\\n7.37 ± 7.20%\\n\\n-\\n\\n-\\n\\nAoki 2012 [215]\\n\\nCustom algorithm\\n\\nBoccanfuso 2012 [216]\\n\\nSinusoidal\\ncurve-ﬁtting\\nfunction\\n\\nCorrelation factor\\nBland-Altman plot\\n\\nAccuracy\\n\\nBruser 2012 [217]\\n\\n-\\n\\n-\\n\\nChen 2012 [218]\\n\\nFrequency analysis\\n\\nMean absolute error\\n\\nDziuda 2012 [9,236]\\n\\nMax-min detection\\n\\nRelative error\\n\\nGu 2012 [219]\\n\\nLokavee 2012 [220]\\n\\n-\\n\\n-\\n\\nGraphical comparison\\n\\nGraphical comparison\\n\\n-\\n\\n-\\n\\n2 bpm\\n\\n12%\\n\\n-\\n\\n-\\n\\nShimomura 2012 [221]\\n\\nFrequency analysis\\n\\nRelative error\\n\\n1.61%\\n\\nXia 2012 [222]\\n\\n-\\n\\nCorrelation factor\\n\\n0.958–0.978\\n\\nLai 2011 [223]\\n\\nMultipeak\\ndetection\\n\\nCorrelation factor\\n\\n0.5–0.83\\n\\nOtsu 2011 [224]\\n\\nCustom algorithm\\n\\nAbsolute error\\n\\n0.19 bpm\\n\\nPostolache 2011 [225]\\n\\nPeak detection\\n\\n-\\n\\nZito 2011 [226]\\n\\n-\\n\\nGraphical comparison\\n\\nHeise 2010 [227]\\n\\nMin 2010 [228]\\n\\nZero-crossing\\ndetection\\n\\nEnvelop detection\\nZero-crossing\\ndetection\\n\\n-\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\nMostov 2010 [229]\\n\\nCustom algorithm\\n\\n-\\n\\nNishiyama 2010 [230,231]\\n\\n-\\n\\nGraphical monitoring\\n\\n-\\n\\n-\\n\\n-\\n\\n0.93–0.98\\n(correlation)\\n−0.002–0.006 bpm\\n(BA, MOD)\\n\\n-\\n\\n-\\n\\nScalise 2010 [232]\\n\\nWavelet transform\\n\\nCorrelation factor\\nBland-Altman analysis\\n\\n0.98 (correlation)\\n13 ms (BAP, MOD)\\n\\nSilvious 2010 [233]\\n\\n-\\n\\nGraphical comparison\\n\\nTan 2010 [234]\\n\\nCustom algorithm\\n\\nGraphical comparison\\n\\n-\\n\\n-\\n\\nLabview\\n\\n-\\n\\nMATLAB\\n\\nMATLAB\\n\\n-\\n\\nOpenCV\\n\\n-\\n\\nLabview\\n\\nC#\\n\\nLabview\\n\\nLabview\\n\\n-\\n\\n-\\n\\nMATLAB\\nLabview\\n\\n-\\n\\nLabview\\nAndroid app\\n\\n-\\n\\n-\\n\\nMATLAB\\n\\n-\\n\\n-\\n\\n-\\n\\n-\\n\\nCustom application\\n\\n\\x0cSensors 2020, 20, 5446\\n\\nReferences\\n\\n71 of 84\\n\\n1. Milenkovi´c, A.; Otto, C.; Jovanov, E. Wireless sensor networks for personal health monitoring: Issues and an\\n\\n3.\\n\\n5.\\n\\n2.\\n\\n4.\\n\\n6.\\n\\nimplementation. Comput. Commun. 2006, 29, 2521–2533. [CrossRef]\\nCao, Z.; Zhu, R.; Que, R.-Y. A wireless portable system with microsensors for monitoring respiratory diseases.\\nIEEE Trans. Biomed. Eng. 2012, 59, 3110–3116.\\nYang, X.; Chen, Z.; Elvin, C.S.M.; Janice, L.H.Y.; Ng, S.H.; Teo, J.T.; Wu, R. Textile Fiber Optic Microbend\\nSensor Used for Heartbeat and Respiration Monitoring. IEEE Sens. J. 2015, 15, 757–761. [CrossRef]\\nSubbe, C.P.; Kinsella, S. Continuous monitoring of respiratory rate in emergency admissions: Evaluation of\\nthe RespiraSenseTM sensor in acute care compared to the industry standard and gold standard. Sensors 2018,\\n18, 2700. [CrossRef]\\nHeldt, G.P.; Ward, R.J., III. Evaluation of Ultrasound-Based Sensor to Monitor Respiratory and Nonrespiratory\\nMovement and Timing in Infants. IEEE Trans. Biomed. Eng. 2016, 63, 619–629. [CrossRef] [PubMed]\\nUshijima, T.; Satake, J. Development of a Breathing Detection Robot for a Monitoring System. In Proceedings\\nof the Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th\\nInternational Symposium on Advanced Intelligent Systems (ISIS), Sapporo, Japan, 25–28 August 2016;\\npp. 790–795.\\nTataraidze, A.; Anishchenko, L.; Korostovtseva, L.; Bochkarev, M.; Sviryaev, Y.; Alborova, I. Detection of\\nmovement activity and breathing cycles on bioradiolocation signals. In Proceedings of the IEEE nternational\\nConference on Microwaves, Antennas, Communications and Electronic Systems (COMCAS), Tel Aviv, Israel,\\n13–15 November 2017; pp. 1–4.\\nGatti, U.C.; Schneider, S.; Migliaccio, G.C. Physiological condition monitoring of construction workers.\\nAutom. Constr. 2014, 44, 227–233. [CrossRef]\\nDziuda, L.; Skibniewski, F.W.; Krej, M.; Lewandowski, J. Monitoring Respiration and Cardiac Activity Using\\nFiber Bragg Grating-Based Sensor. IEEE Trans. Biomed. Eng. 2012, 59, 1934–1942. [CrossRef] [PubMed]\\n10. Prathosh, A.P.; Praveena, P.; Mestha, L.K.; Bharadwaj, S. Estimation of Respiratory Pattern From Video Using\\n\\n9.\\n\\n7.\\n\\n8.\\n\\nSelective Ensemble Aggregation. IEEE Trans. Signal Process. 2017, 65, 2902–2916. [CrossRef]\\n\\n11. Liu, X.; Wang, Q.; Liu, D.; Wang, Y.; Zhang, Y.; Bai, O.; Sun, J. Human emotion classiﬁcation based on\\nmultiple physiological signals by wearable system. Technol. Health Care 2018, 26, 459–469. [CrossRef]\\n\\n12. Homma, I.; Masaoka, Y. Breathing rhythms and emotions. Exp. Physiol. 2008, 93, 1011–1021. [CrossRef]\\n13.\\n\\n´Cosi´c, D. Neuromarketing in market research. Interdiscip. Descr. Complex Syst. INDECS 2016, 14, 139–147.\\n[CrossRef]\\n\\n14. Kowalczuk, Z.; Czubenko Michałand Merta, T. Emotion monitoring system for drivers. IFAC-PapersOnLine\\n\\n2019, 52, 200–205. [CrossRef]\\n\\n15. Granato, M. Emotions Recognition in Video Game Players Using Physiological Information. Ph.D. Thesis,\\n\\nUniversità degli studi di Milano, Milano, Italy, 2019.\\n\\n16. Kołakowska, A.; Landowska, A.; Szwoch, M.; Szwoch, W.; Wrobel, M.R. Emotion recognition and\\nIn Human-Computer Systems Interaction: Backgrounds and Applications 3; Springer:\\n\\nits applications.\\nBerlin/Heidelberg, Germany, 2014; pp. 51–62.\\n\\n17. Hoﬀmann, T.; Eilebrecht, B.; Leonhardt, S. Respiratory Monitoring System on the Basis of Capacitive Textile\\n\\n18.\\n\\nForce Sensors. IEEE Sens. J. 2011, 11, 1112–1119. [CrossRef]\\nSperlich, B.; Aminian, K.; Düking, P.; Holmberg, H.-C. Wearable Sensor Technology for Monitoring Training\\nLoad and Health in the Athletic Population. Front. Physiol. 2019, 10. [CrossRef]\\n\\n19. Lau, D.; Chen, Z.; Teo, J.T.; Ng, S.H.; Rumpel, H.; Lian, Y.; Yang, H.; Kei, P.L. Intensity-Modulated Microbend\\nFiber Optic Sensor for Respiratory Monitoring and Gating During MRI. IEEE Trans. Biomed. Eng. 2013, 60,\\n2655–2662. [CrossRef]\\n\\n20. Krebber, K.; Lenke, P.; Liehr, S.; Schukar, M.; Wendt, M.; Witt, J.; Wosniok, A. Technology and applications of\\n\\nsmart technical textiles based on ﬁber optic sensors. Adv. Photonics Renew. Energy 2008. [CrossRef]\\n\\n21. Metshein, M. A device for measuring the electrical bioimpedance with variety of electrode placements for\\nmonitoring the breathing and heart rate. In Proceedings of the 26th Irish Signals and Systems Conference\\n(ISSC), Carlow, UK, 24–25 June 2015; pp. 1–4.\\nFriedl, K.E. Military applications of soldier physiological monitoring. J. Sci. Med. Sport 2018, 21, 1147–1153.\\n[CrossRef]\\n\\n22.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n72 of 84\\n\\n23.\\n\\nScalise, L.; Mariani Primiani, V.; Russo, P.; De Leo, A.; Shahu, D.; Cerri, G. Wireless sensing for the respiratory\\nactivity of human beings: Measurements and wide-band numerical analysis. Int. J. Antennas Propag. 2013,\\n2013, 396459. [CrossRef]\\n\\n24. Massaroni, C.; Nicolò, A.; Lo Presti, D.; Sacchetti, M.; Silvestri, S.; Schena, E. Contact-based methods for\\n\\nmeasuring respiratory rate. Sensors 2019, 19, 908. [CrossRef]\\n\\n25. Mukhopadhyay, S.C. Wearable Sensors for Human Activity Monitoring: A Review. IEEE Sens. J. 2015, 15,\\n\\n1321–1330. [CrossRef]\\n\\n26. Nag, A.; Mukhopadhyay, S.C.; Kosel, J. Wearable Flexible Sensors: A Review.\\n\\nIEEE Sens.\\n\\nJ. 2017, 17,\\n\\n3949–3960. [CrossRef]\\n\\n27. Chung, M.; Fortunato, G.; Radacsi, N. Wearable ﬂexible sweat sensors for healthcare monitoring: A review.\\n\\nJ. R. Soc. Interface 2019, 16, 20190217. [CrossRef]\\n\\n28. Bandodkar, A.J.; Jeang, W.J.; Ghaﬀari, R.; Rogers, J.A. Wearable sensors for biochemical sweat analysis.\\n\\nAnnu. Rev. Anal. Chem. 2019, 12, 1–22. [CrossRef] [PubMed]\\n\\n29. López-Nava, I.H.; Muñoz-Meléndez, A. Wearable Inertial Sensors for Human Motion Analysis: A Review.\\n\\n30.\\n\\nIEEE Sens. J. 2016, 16, 7821–7834. [CrossRef]\\nSeshadri, D.R.; Li, R.T.; Voos, J.E.; Rowbottom, J.R.; Alfes, C.M.; Zorman, C.A.; Drummond, C.K. Wearable\\nsensors for monitoring the internal and external workload of the athlete. NPJ Digit. Med. 2019, 2, 71.\\n[CrossRef] [PubMed]\\n\\n31. Aroganam, G.; Manivannan, N.; Harrison, D. Review on Wearable Technology Sensors Used in Consumer\\n\\nSport Applications. Sensors 2019, 19, 1983. [CrossRef] [PubMed]\\n\\n32. Al-Eidan, R.M.; Al-Khalifa, H.; Al-Salman, A.M. A Review of Wrist-Worn Wearable: Sensors, Models,\\n\\nand Challenges. J. Sens. 2018, 2018, 5853917. [CrossRef]\\n\\n33. Baig, M.M.; Aﬁﬁ, S.; GholamHosseini, H.; Mirza, F. A Systematic Review of Wearable Sensors and IoT-Based\\nMonitoring Applications for Older Adults—A Focus on Ageing Population and Independent Living.\\nJ. Med. Syst. 2019, 43, 233. [CrossRef] [PubMed]\\n\\n34. Heikenfeld, J.; Jajack, A.; Rogers, J.; Gutruf, P.; Tian, L.; Pan, T.; Li, R.; Khine, M.; Kim, J.; Wang, J.; et al.\\nWearable sensors: Modalities, challenges, and prospects. Lab Chip 2018, 18, 217–248. [CrossRef] [PubMed]\\n35. Witte, A.-K.; Zarnekow, R. Transforming Personal Healthcare through Technology—A Systematic Literature\\nReview of Wearable Sensors for Medical Application. In Proceedings of the 52nd Hawaii International\\nConference on System Sciences, Grand Wailea, Maui, 8–11 January 2019; pp. 3848–3857.\\n\\n36. Pantelopoulos, A.; Bourbakis, N.G. A Survey on Wearable Sensor-Based Systems for Health Monitoring and\\n\\nPrognosis. Healthc. Inform. Res. 2010, 40, 1–12. [CrossRef]\\n\\n37. Liang, T.; Yuan, Y.J. Wearable Medical Monitoring Systems Based on Wireless Networks: A Review.\\n\\nIEEE Sens. J. 2016, 16, 8186–8199. [CrossRef]\\n\\n38. Charlton, P.H.; Birrenkott, D.A.; Bonnici, T.; Pimentel, M.A.F.; Johnson, A.E.W.; Alastruey, J.; Tarassenko, L.;\\nWatkinson, P.J.; Beale, R.; Clifton, D.A. Breathing Rate Estimation From the Electrocardiogram and\\nPhotoplethysmogram: A Review. IEEE Sens. J. 2018, 11, 2–20. [CrossRef] [PubMed]\\n\\n39. AL-Khalidi, F.Q.; Saatchi, R.; Burke, D.; Elphick, H.; Tan, S. Respiration rate monitoring methods: A review.\\n\\nPediatr. Pulmonol. 2011, 46, 523–529. [CrossRef] [PubMed]\\n\\n40. Van Loon, K.; Zaane, B.; Bosch, E.J.; Kalkman, C.; Peelen, L.M. Non-Invasive Continuous Respiratory\\nMonitoring on General Hospital Wards: A Systematic Review. PLoS ONE 2015, 10, e0144626. [CrossRef]\\n[PubMed]\\n\\n41. Rajala, S.; Lekkala, J. Film-Type Sensor Materials PVDF and EMFi in Measurement of Cardiorespiratory\\n\\nSignals—A Review. IEEE Sens. J. 2012, 12, 439–446. [CrossRef]\\n\\n42. Massaroni, C.; Zaltieri, M.; Lo Presti, D.; Nicolò, A.; Tosi, D.; Schena, E. Fiber Bragg Grating Sensors for\\n\\n43.\\n\\nCardiorespiratory Monitoring: A Review. IEEE Sens. J. 2020, 1. [CrossRef]\\nIEEE Xplore Search Results Page. Available online: https://ieeexplore.ieee.org/Xplorehelp/searching-ieee-\\nxplore/search-results-page (accessed on 8 September 2020).\\n\\n44. Google Sholar About. Available online: https://scholar.google.com/intl/es/scholar/about.html (accessed on\\n\\n8 September 2020).\\n\\n45. PRISMA. Transparent Reporting of Systematic Reviews and Meta-Analyses. Available online: http:\\n\\n//prisma-statement.org/ (accessed on 14 September 2020).\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n73 of 84\\n\\n46.\\n\\nIgual, R.; Medrano, C.; Plaza, I. Challenges, issues and trends in fall detection systems. Biomed. Eng. Online\\n2013, 12. [CrossRef]\\n\\n47. Warner, M.A.; Patel, B. Mechanical ventilation. In Benumof and Hagberg’s Airway Management; Elsevier:\\n\\n48.\\n\\nAmsterdam, The Netherlands, 2013; pp. 981–997.\\nShao, D.; Yang, Y.; Liu, C.; Tsow, F.; Yu, H.; Tao, N. Noncontact Monitoring Breathing Pattern, Exhalation\\nFlow Rate and Pulse Transit Time. IEEE Trans. Biomed. Eng. 2014, 61, 2760–2767. [CrossRef]\\n\\n49. Massaroni, C.; Saccomandi, P.; Formica, D.; Lo Presti, D.; Caponero, M.A.; Di Tomaso, G.; Giurazza, F.;\\nMuto, M.; Schena, E. Design and Feasibility Assessment of a Magnetic Resonance-Compatible Smart Textile\\nJ. 2016, 16, 8103–8110.\\nBased on Fiber Bragg Grating Sensors for Respiratory Monitoring.\\n[CrossRef]\\n\\nIEEE Sens.\\n\\n50. Nijsure, Y.; Tay, W.P.; Gunawan, E.; Wen, F.; Yang, Z.; Guan, Y.L.; Chua, A.P. An Impulse Radio Ultrawideband\\nSystem for Contactless Noninvasive Respiratory Monitoring. IEEE Trans. Biomed. Eng. 2013, 60, 1509–1517.\\n[CrossRef]\\n\\n51. Bernal, E.A.; Mestha, L.K.; Shilla, E. Non contact monitoring of respiratory function via depth sensing.\\nIn Proceedings of the IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI),\\nValencia, Spain, 1–4 June 2014; pp. 101–104.\\n\\n52. Lee, Y.S.; Pathirana, P.N.; Steinfort, C.L.; Caelli, T. Monitoring and Analysis of Respiratory Patterns Using\\n\\nMicrowave Doppler Radar. IEEE J. Transl. Eng. Health Med. 2014, 2, 1–12. [CrossRef] [PubMed]\\n\\n53. Wang, C.; Hunter, A.; Gravill, N.; Matusiewicz, S. Unconstrained Video Monitoring of Breathing Behavior\\nand Application to Diagnosis of Sleep Apnea. IEEE Trans. Biomed. Eng. 2014, 61, 396–404. [CrossRef]\\n[PubMed]\\n\\n55.\\n\\n54. Huang, X.; Sun, L.; Tian, T.; Huang, Z.; Clancy, E. Real-time non-contact infant respiratory monitoring\\nusing UWB radar. In Proceedings of the 16th IEEE International Conference on Communication Technology,\\nHangzhou, China, 18–21 October 2015; pp. 493–496.\\nIgual, R.; Plaza, I.; Medrano, C.; Rubio, M.A. Personalizable smartphone-based system adapted to assist\\ndependent people. J. Ambient Intell. Smart Environ. 2014, 6, 569–593. [CrossRef]\\nIgual, R.; Plaza, I.; Martín, L.; Corbalan, M.; Medrano, C. Guidelines to Design Smartphone Applications for\\nPeople with Intellectual Disability: A Practical Experience. In Ambient Intelligence—Software and Applications;\\nAdvances in Intelligent Systems and Computing; Springer: Heidelberg, Germany, 2013; Volume 219,\\nISBN 9783319005652.\\n\\n56.\\n\\n57. Aitkulov, A.; Tosi, D. Optical ﬁber sensor based on plastic optical ﬁber and smartphone for measurement of\\n\\nthe breathing rate. IEEE Sens. J. 2019, 19, 3282–3287. [CrossRef]\\n\\n58. Aitkulov, A.; Tosi, D. Design of an all-POF-ﬁber smartphone multichannel breathing sensor with\\n\\ncamera-division multiplexing. IEEE Sens. Lett. 2019, 3, 1–4. [CrossRef]\\n\\n59. Balasubramaniyam, H.; Vignesh, M.S.; Abhirami, A.; Abanah, A. Design and Development of a IoT based\\nFlexible and Wearable T-Shirt for Monitoring Breathing Rate.\\nIn Proceedings of the 3rd International\\nConference on Computing Methodologies and Communication (ICCMC), Erode, India, 27–29 March 2019;\\npp. 376–379.\\n\\n60. Bricout, A.; Fontecave-Jallon, J.; Colas, D.; Gerard, G.; Pépin, J.-L.; Guméry, P.-Y. Adaptive Accelerometry\\nDerived Respiration: Comparison with Respiratory Inductance Plethysmography during Sleep.\\nIn Proceedings of the 41st Annual International Conference of the IEEE Engineering in Medicine and\\nBiology Society (EMBC), Berlin, Germany, 23–27 July 2019; pp. 6714–6717.\\n\\n61. Chu, M.; Nguyen, T.; Pandey, V.; Zhou, Y.; Pham, H.N.; Bar-Yoseph, R.; Radom-Aizik, S.; Jain, R.; Cooper, D.M.;\\nKhine, M. Respiration rate and volume measurements using wearable strain sensors. NPJ Digit. Med. 2019,\\n2, 1–9. [CrossRef]\\n\\n62. Elfaramawy, T.; Fall, C.L.; Arab, S.; Morissette, M.; Lellouche, F.; Gosselin, B. A Wireless Respiratory\\n\\n63.\\n\\nMonitoring System Using a Wearable Patch Sensor Network. IEEE Sens. J. 2019, 19, 650–657. [CrossRef]\\nFajkus, M.; Nedoma, J.; Martinek, R.; Brablik, J.; Vanus, J.; Novak, M.; Zabka, S.; Vasinek, V.; Hanzlikova, P.;\\nVojtisek, L. MR fully compatible and safe FBG breathing sensor: A practical solution for respiratory triggering.\\nIEEE Access 2019, 7, 123013–123025. [CrossRef]\\n\\n64. Hurtado, D.E.; Abusleme, A.; Chávez, J.A.P. Non-invasive continuous respiratory monitoring using\\n\\ntemperature-based sensors. J. Clin. Monit. Comput. 2019, 1–9. [CrossRef]\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n74 of 84\\n\\n65.\\n\\nJayarathna, T.; Gargiulo, G.D.; Breen, P.P. Polymer sensor embedded, IOT enabled t-shirt for long-term\\nmonitoring of sleep disordered breathing. In Proceedings of the IEEE 5th World Forum on Internet of Things\\n(WF-IoT), Limerick, UK, 15–18 April 2019; pp. 139–143.\\n\\n66. Kano, S.; Yamamoto, A.; Ishikawa, A.; Fujii, M. Respiratory rate on exercise measured by nanoparticle-based\\nhumidity sensor. In Proceedings of the 41st Annual International Conference of the IEEE Engineering in\\nMedicine and Biology Society (EMBC), Berlin, Germany, 23–27 July 2019; pp. 3567–3570.\\n\\n67. Karacocuk, G.; Höﬂinger, F.; Zhang, R.; Reindl, L.M.; Laufer, B.; Möller, K.; Röell, M.; Zdzieblik, D. Inertial\\n\\nsensor-based respiration analysis. IEEE Trans. Instrum. Meas. 2019, 68, 4268–4275. [CrossRef]\\n\\n68. Massaroni, C.; Nicolò, A.; Girardi, M.; La Camera, A.; Schena, E.; Sacchetti, M.; Silvestri, S.; Taﬀoni, F.\\nValidation of a wearable device and an algorithm for respiratory monitoring during exercise. IEEE Sens. J.\\n2019, 19, 4652–4659. [CrossRef]\\n\\n69. Massaroni, C.; Di Tocco, J.; Presti, D.L.; Longo, U.G.; Miccinilli, S.; Sterzi, S.; Formica, D.; Saccomandi, P.;\\nSchena, E. Smart textile based on piezoresistive sensing elements for respiratory monitoring. IEEE Sens. J.\\n2019, 19, 7718–7725. [CrossRef]\\n\\n70. Nguyen, T.-V.; Ichiki, M. MEMS-Based Sensor for Simultaneous Measurement of Pulse Wave and Respiration\\n\\nRate. Sensors 2019, 19, 4942. [CrossRef] [PubMed]\\n\\n71. Presti, D.L.; Massaroni, C.; Di Tocco, J.; Schena, E.; Carnevale, A.; Longo, U.G.; D’Abbraccio, J.; Massari, L.;\\nOddo, C.M.; Caponero, M.A. Single-plane neck movements and respiratory frequency monitoring: A smart\\nsystem for computer workers. In Proceedings of the 2019 II Workshop on Metrology for Industry 4.0 and IoT\\n(MetroInd4. 0&IoT), Naples, Italy, 4–6 June 2019; pp. 167–170.\\n\\n72. Presti, D.L.; Massaroni, C.; D’Abbraccio, J.; Massari, L.; Caponero, M.; Longo, U.G.; Formica, D.; Oddo, C.M.;\\nSchena, E. Wearable system based on ﬂexible FBG for respiratory and cardiac monitoring. IEEE Sens. J. 2019,\\n19, 7391–7398. [CrossRef]\\n\\n73. Puranik, K.A.; Kanthi, M. Wearable Device for Yogic Breathing. In Proceedings of the 2019 Amity International\\n\\n74.\\n\\nConference on Artiﬁcial Intelligence (AICAI), Dubai, UAE, 4–6 February 2019; pp. 605–610.\\nSoomro, A.M.; Jabbar, F.; Ali, M.; Lee, J.-W.; Mun, S.W.; Choi, K.H. All-range ﬂexible and biocompatible\\nhumidity sensor based on poly lactic glycolic acid (PLGA) and its application in human breathing for\\nwearable health monitoring. J. Mater. Sci. Mater. Electron. 2019, 30, 9455–9465. [CrossRef]\\n\\n75. Xiao, S.; Nie, J.; Tan, R.; Duan, X.; Ma, J.; Li, Q.; Wang, T. Fast-response ionogel humidity sensor for real-time\\n\\nmonitoring of breathing rate. Mater. Chem. Front. 2019, 3, 484–491. [CrossRef]\\n\\n76. Yuasa, Y.; Suzuki, K. Wearable device for monitoring respiratory phases based on breathing sound and chest\\n\\nmovement. Adv. Biomed. Eng. 2019, 8, 85–91. [CrossRef]\\n\\n77. Zhang, H.; Zhang, J.; Hu, Z.; Quan, L.; Shi, L.; Chen, J.; Xuan, W.; Zhang, Z.; Dong, S.; Luo, J. Waist-wearable\\n\\nwireless respiration sensor based on triboelectric eﬀect. Nano Energy 2019, 59, 75–83. [CrossRef]\\n\\n78. Dan, G.; Zhao, J.; Chen, Z.; Yang, H.; Zhu, Z. A Novel Signal Acquisition System for Wearable Respiratory\\n\\nMonitoring. IEEE Access 2018, 6, 34365–34371. [CrossRef]\\n\\n79. Koyama, Y.; Nishiyama, M.; Watanabe, K. Smart Textile Using Hetero-Core Optical Fiber for Heartbeat and\\n\\nRespiration Monitoring. IEEE Sens. J. 2018, 18, 6175–6180. [CrossRef]\\n\\n80. Malik, S.; Ahmad, M.; Punjiya, M.; Sadeqi, A.; Baghini, M.S.; Sonkusale, S. Respiration Monitoring Using\\na Flexible Paper-Based Capacitive Sensor. In Proceedings of the 2018 IEEE Sensors, New Delhi, India,\\n28–31 October 2018; pp. 1–4.\\n\\n81. Martin, A.; Voix, J. In-Ear Audio Wearable: Measurement of Heart and Breathing Rates for Health and Safety\\n\\nMonitoring. IEEE Trans. Biomed. Eng. 2018, 65, 1256–1263. [CrossRef] [PubMed]\\n\\n82. Pang, Y.; Jian, J.; Tu, T.; Yang, Z.; Ling, J.; Li, Y.; Wang, X.; Qiao, Y.; Tian, H.; Yang, Y.; et al. Wearable humidity\\nsensor based on porous graphene network for respiration monitoring. Biosens. Bioelectron. 2018, 116, 123–129.\\n[CrossRef] [PubMed]\\nFajkus, M.; Nedoma, J.; Martinek, R.; Vasinek, V.; Nazeran, H.; Siska, P. A non-invasive multichannel hybrid\\nﬁber-optic sensor system for vital sign monitoring. Sensors 2017, 17, 111. [CrossRef] [PubMed]\\n\\n83.\\n\\n84. Gorgutsa, S.; Bellemare-Rousseau, S.; Guay, P.; Miled, A.; Messaddeq, Y. Smart T-shirt with wireless\\nrespiration sensor. In Proceedings of the 2017 IEEE Sensors, Glasgow, UK, 29 October–1 November 2017;\\npp. 1–3.\\n\\n85. Guay, P.; Gorgutsa, S.; LaRochelle, S.; Messaddeq, Y. Wearable contactless respiration sensor based on\\n\\nmulti-material ﬁbers integrated into textile. Sensors 2017, 17, 1050. [CrossRef] [PubMed]\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n75 of 84\\n\\n86. Kam, W.; Mohammed, W.S.; Leen, G.; O’Sullivan, K.; O’Keeﬀe, M.; O’Keeﬀe, S.; Lewis, E. All plastic\\noptical ﬁber-based respiration monitoring sensor. In Proceedings of the 2017 IEEE Sensors, Glasgow, UK,\\n29 October–1 November 2017; pp. 1–3.\\n\\n87. Kam, W.; Mohammed, W.S.; Leen, G.; O’Keeﬀe, M.; O’Sullivan, K.; O’Keeﬀe, S.; Lewis, E. Compact and\\nLow-Cost Optical Fiber Respiratory Monitoring Sensor Based on Intensity Interrogation. J. Light. Technol.\\n2017, 35, 4567–4573. [CrossRef]\\n\\n88. Kam, W.; Mohammed, W.S.; O’Keeﬀe, S.; Lewis, E. Portable 3-D Printed Plastic Optical Fibre Motion Sensor\\nfor Monitoring of Breathing Pattern and Respiratory Rate. In Proceedings of the IEEE 5th World Forum on\\nInternet of Things (WF-IoT), Limerick, UK, 15–18 April 2019; pp. 144–148.\\n\\n89. Kano, S.; Fujii, M. Battery-powered wearable respiration sensor chip with nanocrystal thin ﬁlm. In Proceedings\\n\\nof the 2017 IEEE Sensors, Glasgow, UK, 29 October–1 November 2017; pp. 1–3.\\n\\n90. Koch, E.; Dietzel, A. Stretchable sensor array for respiratory monitoring.\\n\\nIn Proceedings of the 19th\\nInternational Conference on Solid-State Sensors, Actuators and Microsystems (TRANSDUCERS), Kaohsiung,\\nTaiwan, 18–22 June 2017; pp. 2227–2230.\\n\\n91. Milici, S.; Lorenzo, J.; Lázaro, A.; Villarino, R.; Girbau, D. Wireless Breathing Sensor Based on Wearable\\n\\nModulated Frequency Selective Surface. IEEE Sens. J. 2017, 17, 1285–1292. [CrossRef]\\n\\n92. Nakazumi, R.; Inoue, M.; Yoshimi, T.; Fuchiyama, S.; Tsuchiya, H. Development of a respiration monitoring\\nsensor for diving worker. In Proceedings of the 56th Annual Conference of the Society of Instrument and\\nControl Engineers of Japan (SICE), Kanazawa, Japan, 19–22 September 2017; pp. 206–208.\\n\\n93. Park, S.W.; Das, P.S.; Chhetry, A.; Park, J.Y. A Flexible Capacitive Pressure Sensor for Wearable Respiration\\n\\nMonitoring System. IEEE Sens. J. 2017, 17, 6558–6564. [CrossRef]\\n\\n94. Presti, D.L.; Massaroni, C.; Formica, D.; Saccomandi, P.; Giurazza, F.; Caponero, M.A.; Schena, E. Smart\\nTextile Based on 12 Fiber Bragg Gratings Array for Vital Signs Monitoring. IEEE Sens. J. 2017, 17, 6037–6043.\\n[CrossRef]\\n\\n95. Valipour, A.; Abbasi-Kesbi, R. A heartbeat and respiration rate sensor based on phonocardiogram for\\nhealthcare applications. In Proceedings of the Iranian Conference on Electrical Engineering (ICEE), Tehran,\\nIran, 2–4 May 2017; pp. 45–48.\\n\\n96. White, N.M.; Ash, J.; Wei, Y.; Akerman, H. A Planar Respiration Sensor Based on a Capaciﬂector Structure.\\n\\nIEEE Sens. Lett. 2017, 1, 1–4. [CrossRef]\\n\\n97. Yan, H.; Zhang, L.; Yu, P.; Mao, L. Sensitive and fast humidity sensor based on a redox conducting\\nsupramolecular ionic material for respiration monitoring. Anal. Chem. 2017, 89, 996–1001. [CrossRef]\\n98. Mahbub, I.; Wang, H.; Islam, S.K.; Pullano, S.A.; Fiorillo, A.S. A low power wireless breathing monitoring\\nsystem using piezoelectric transducer. In Proceedings of the IEEE International Symposium on Medical\\nMeasurements and Applications (MeMeA), Benevento, Italy, 15–18 May 2016; pp. 1–5.\\n\\n99. Mahbub, I.; Pullano, S.A.; Wang, H.; Islam, S.K.; Fiorillo, A.S.; To, G.; Mahfouz, M.R. A low-power wireless\\npiezoelectric sensor-based respiration monitoring system realized in CMOS process. IEEE Sens. J. 2017, 17,\\n1858–1864. [CrossRef]\\n\\n100. Chethana, K.; Guru Prasad, A.S.; Omkar, S.N.; Asokan, S. Fiber bragg grating sensor based device for\\nsimultaneous measurement of respiratory and cardiac activities. J. Biophotonics 2017, 10, 278–285. [CrossRef]\\n[PubMed]\\n\\n101. Güder, F.; Ainla, A.; Redston, J.; Mosadegh, B.; Glavan, A.; Martin, T.J.; Whitesides, G.M. Paper-based\\n\\nelectrical respiration sensor. Angew. Chem. Int. Ed. 2016, 55, 5727–5732. [CrossRef] [PubMed]\\n\\n102. Lepine, N.N.; Tajima, T.; Ogasawara, T.; Kasahara, R.; Koizumi, H. Robust respiration rate estimation using\\nadaptive Kalman ﬁltering with textile ECG sensor and accelerometer. In Proceedings of the 38th Annual\\nInternational Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Orlando, FL,\\nUSA, 16–20 August 2016; pp. 3797–3800.\\n\\n103. Massaroni, C.; Ciocchetti, M.; Di Tomaso, G.; Saccomandi, P.; Caponero, M.A.; Polimadei, A.; Formica, D.;\\nSchena, E. Design and preliminary assessment of a smart textile for respiratory monitoring based on an array\\nof Fiber Bragg Gratings. In Proceedings of the of the 38th Annual International Conference of the IEEE\\nEngineering in Medicine and Biology Society (EMBC), Orlando, FL, USA, 16–20 August 2016; pp. 6054–6057.\\n104. Moradian, S.; Abdolvand, R. MEMS-based passive wireless respiration proﬁle sensor. In Proceedings of the\\n\\n2016 IEEE Sensors, Orlando, FL, USA, 30 October–3 November 2016; pp. 1–3.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n76 of 84\\n\\n105. Nag, A.; Mukhopadhyay, S.C.; Kosel, J. Flexible carbon nanotube nanocomposite sensor for multiple\\n\\nphysiological parameter monitoring. Sens. Actuators A Phys. 2016, 251, 148–155. [CrossRef]\\n\\n106. Nam, Y.; Reyes, B.A.; Chon, K.H. Estimation of Respiratory Rates Using the Built-in Microphone of a\\n\\nSmartphone or Headset. IEEE J. Biomed. Health Inform. 2016, 20, 1493–1501. [CrossRef] [PubMed]\\n\\n107. Raji, A.; Kanchana Devi, P.; Golda Jeyaseeli, P.; Balaganesh, N. Respiratory monitoring system for asthma\\npatients based on IoT. In Proceedings of the Online International Conference on Green Engineering and\\nTechnologies (IC-GET), Coimbatore, India, 19 November 2016; pp. 1–6.\\n\\n108. Ramos-Garcia, R.I.; Da Silva, F.; Kondi, Y.; Sazonov, E.; Dunne, L.E. Analysis of a coverstitched stretch sensor\\nfor monitoring of breathing. In Proceedings of the 10th International Conference on Sensing Technology\\n(ICST), Nanjing, China, 11–13 November 2016; pp. 1–6.\\n\\n109. Rotariu, C.; Cristea, C.; Arotaritei, D.; Bozomitu, R.G.; Pasarica, A. Continuous respiratory monitoring device\\nfor detection of sleep apnea episodes. In Proceedings of the IEEE 22nd International Symposium for Design\\nand Technology in Electronic Packaging (SIITME), Oradea, Romania, 20–23 October 2016; pp. 106–109.\\n110. Atalay, O.; Kennon, W.R.; Demirok, E. Weft-Knitted Strain Sensor for Monitoring Respiratory Rate and Its\\n\\nElectro-Mechanical Modeling. IEEE Sens. J. 2015, 15, 110–122. [CrossRef]\\n\\n111. Ciocchetti, M.; Massaroni, C.; Saccomandi, P.; Caponero, M.A.; Polimadei, A.; Formica, D.; Schena, E. Smart\\ntextile based on ﬁber bragg grating sensors for respiratory monitoring: Design and preliminary trials.\\nBiosensors 2015, 5, 602–615. [CrossRef]\\n\\n112. Estrada, L.; Torres, A.; Sarlabous, L.; Jané, R. Respiratory signal derived from the smartphone built-in\\naccelerometer during a Respiratory Load Protocol.\\nIn Proceedings of the 37th Annual International\\nConference of the IEEE Engineering in Medicine and Biology Society (EMBC), Milan, Italy, 25–29 August\\n2015; pp. 6768–6771.\\n\\n113. Gargiulo, G.D.; Gunawardana, U.; O’Loughlin, A.; Sadozai, M.; Varaki, E.S.; Breen, P.P. A wearable contactless\\nsensor suitable for continuous simultaneous monitoring of respiration and cardiac activity. J. Sens. 2015,\\n2015, 151859. [CrossRef]\\n\\n114. Grlica, J.; Martinovi´c, T.; Džapo, H. Capacitive sensor for respiration monitoring. In Proceedings of the IEEE\\n\\nSensors Applications Symposium (SAS), Zadar, Croatia, 13–15 April 2015; pp. 1–6.\\n\\n115. Hernandez, J.; McDuﬀ, D.; Picard, R.W. Biowatch: Estimation of heart and breathing rates from wrist motions.\\nIn Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare\\n(PervasiveHealth), Istanbul, Turkey, 20–23 May 2015; pp. 169–176.\\n\\n116. Jiang, P.; Zhao, S.; Zhu, R. Smart Sensing Strip Using Monolithically Integrated Flexible Flow Sensor for\\n\\nNoninvasively Monitoring Respiratory Flow. Sensors 2015, 15, 31738–31750. [CrossRef]\\n\\n117. Karlen, W.; Garde, A.; Myers, D.; Scheﬀer, C.; Ansermino, J.M.; Dumont, G.A. Estimation of Respiratory Rate\\nFrom Photoplethysmographic Imaging Videos Compared to Pulse Oximetry. IEEE J. Biomed. Health Inform.\\n2015, 19, 1331–1338. [CrossRef]\\n\\n118. Kazmi, S.A.; Shah, M.H.; Khan, S.; Khalifa, O.O. Respiratory rate (RR) based analysis of PPG signal for\\ndiﬀerent physiological conditions. In Proceedings of the International Conference on Smart Sensors and\\nApplication (ICSSA), Kuala Lumpur, Malaysia, 26–28 May 2015; pp. 166–171.\\n\\n119. Teichmann, D.; De Matteis, D.; Bartelt, T.; Walter, M.; Leonhardt, S. A Bendable and Wearable Cardiorespiratory\\nMonitoring Device Fusing Two Noncontact Sensor Principles. IEEE J. Biomed. Health Inform. 2015, 19,\\n784–793. [CrossRef] [PubMed]\\n\\n120. Wei, C.; Lin, Y.; Chen, T.; Lin, R.; Liu, T. Respiration Detection Chip with Integrated Temperature-Insensitive\\nMEMS Sensors and CMOS Signal Processing Circuits. IEEE Trans. Biomed. Circuits Syst. 2015, 9, 105–112.\\n[CrossRef] [PubMed]\\n\\n121. Bifulco, P.; Gargiulo, G.D.; d’Angelo, G.; Liccardo, A.; Romano, M.; Clemente, F.; Cesarelli, M.; Angelo, G.;\\nLiccardo, A.; Romano, M.; et al. Monitoring of respiration, seismocardiogram and heart sounds by a PVDF\\npiezo ﬁlm sensor. Measurement 2014, 11, 786–789.\\n\\n122. Fekr, A.R.; Radecka, K.; Zilic, Z. Tidal volume variability and respiration rate estimation using a wearable\\naccelerometer sensor. In Proceedings of the 4th International Conference on Wireless Mobile Communication\\nand Healthcare—Transforming Healthcare Through Innovations in Mobile and Wireless Technologies\\n(MOBIHEALTH), Athens, Greece, 3–5 November 2014; pp. 1–6.\\n\\n123. Agcayazi, T.; Yokus, M.A.; Gordon, M.; Ghosh, T.; Bozkurt, A. A stitched textile-based capacitive respiration\\nsensor. In Proceedings of the 2017 IEEE Sensors, Glasgow, UK, 29 October–1 November 2017; pp. 1–3.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n77 of 84\\n\\n124. Hesse, M.; Christ, P.; Hörmann, T.; Rückert, U. A respiration sensor for a chest-strap based wireless body\\n\\nsensor. In Proceedings of the 2014 IEEE Sensors, Valencia, Spain, 2–5 November 2014; pp. 490–493.\\n\\n125. Krehel, M.; Schmid, M.; Rossi, R.; Boesel, L.; Bona, G.-L.; Scherer, L. An Optical Fibre-Based Sensor for\\n\\nRespiratory Monitoring. Sensors 2014, 14, 13088–13101. [CrossRef]\\n\\n126. Min, S.D.; Yun, Y.; Shin, H. Simpliﬁed Structural Textile Respiration Sensor Based on Capacitive Pressure\\n\\nSensing Method. IEEE Sens. J. 2014, 14, 3245–3251. [CrossRef]\\n\\n127. Petrovi´c, M.D.; Petrovic, J.; Daniˇci´c, A.; Vukˇcevi´c, M.; Bojovi´c, B.; Hadžievski, L.; Allsop, T.; Lloyd, G.;\\nWebb, D.J. Non-invasive respiratory monitoring using long-period ﬁber grating sensors. Biomed. Opt. Express\\n2014, 5, 1136–1144. [CrossRef]\\n\\n128. Sanchez, P.; Zamarreno, C.R.; Zamarreo, C.R.; Hernaez, M.; Matias, I.R.; Arregui, F.J. Exhaled breath optical\\nﬁber sensor based on LMRs for respiration monitoring. In Proceedings of the 2014 IEEE Sensors, Valencia,\\nSpain, 2–5 November 2014; pp. 1142–1145.\\n\\n129. Wo, J.; Wang, H.; Sun, Q.; Shum, P.P.; Liu, D. Noninvasive respiration movement sensor based on distributed\\nBragg reﬂector ﬁber laser with beat frequency interrogation. J. Biomed. Opt. 2014, 19, 17003. [CrossRef]\\n130. Yang, C.M.; Yang, T.L.; Wu, C.C.; Hung, S.H.; Liao, M.H.; Su, M.J.; Hsieh, H.C. Textile-based capacitive sensor\\nfor a wireless wearable breath monitoring system. In Proceedings of the IEEE International Conference on\\nConsumer Electronics (ICCE), Las Vegas, NV, USA, 11–14 January 2014; pp. 232–233.\\n\\n131. Yoon, J.-W.; Noh, Y.-S.; Kwon, Y.-S.; Kim, W.-K.; Yoon, H.-R. Improvement of dynamic respiration monitoring\\nthrough sensor fusion of accelerometer and gyro-sensor. J. Electr. Eng. Technol. 2014, 9, 334–343. [CrossRef]\\n132. Chan, A.M.; Selvaraj, N.; Ferdosi, N.; Narasimhan, R. Wireless patch sensor for remote monitoring of heart\\nrate, respiration, activity, and falls. In Proceedings of the 35th Annual international conference of the IEEE\\nengineering in medicine and biology society (EMBC), Osaka, Japan, 3–7 July 2013; pp. 6115–6118.\\n\\n133. Huang, Y.; Huang, K. Monitoring of breathing rate by a piezoﬁlm sensor using pyroelectric eﬀect.\\nIn Proceedings of the 1st International Conference on Orange Technologies (ICOT), Tainan, Taiwan, 12–16\\nMarch 2013; pp. 99–102.\\n\\n134. Aileni, R.M.; Pasca, S.; Strungaru, R.; Valderrama, C. Biomedical signal acquisition for respiration monitoring\\nby ﬂexible analog wearable sensors. In Proceedings of the 2017 E-Health and Bioengineering Conference\\n(EHB), Sinaia, Romania, 22–24 June 2017; pp. 81–84.\\n\\n135. Padasdao, B.; Shahhaidar, E.; Stickley, C.; Boric-Lubecke, O. Electromagnetic Biosensing of Respiratory Rate.\\n\\nIEEE Sens. J. 2013, 13, 4204–4211. [CrossRef]\\n\\n136. Chiu, Y.-Y.; Lin, W.-Y.; Wang, H.-Y.; Huang, S.-B.; Wu, M.-H. Development of a piezoelectric polyvinylidene\\nﬂuoride (PVDF) polymer-based sensor patch for simultaneous heartbeat and respiration monitoring.\\nSens. Actuators A Phys. 2013, 189, 328–334. [CrossRef]\\n\\n137. Favero, F.C.; Pruneri, V.; Villatoro, J. Microstructured optical fiber interferometric breathing sensor. J. Biomed. Opt.\\n\\n2012, 17, 37006. [CrossRef] [PubMed]\\n\\n138. Mathew, J.; Semenova, Y.; Farrell, G. A miniature optical breathing sensor. Biomed. Opt. Express 2012, 3,\\n\\n3325–3331. [CrossRef] [PubMed]\\n\\n139. Scully, C.G.; Lee, J.; Meyer, J.; Gorbach, A.M.; Granquist-Fraser, D.; Mendelson, Y.; Chon, K.H. Physiological\\nParameter Monitoring from Optical Recordings With a Mobile Phone. IEEE Trans. Biomed. Eng. 2012, 59,\\n303–306. [CrossRef] [PubMed]\\n\\n140. Trobec, R.; Rashkovska, A.; Avbelj, V. Two proximal skin electrodes—A body sensor for respiration rate.\\n\\nSensors 2012, 12, 13813–13828. [CrossRef] [PubMed]\\n\\n141. Witt, J.; Narbonneau, F.; Schukar, M.; Krebber, K.; De Jonckheere, J.; Jeanne, M.; Kinet, D.; Paquet, B.;\\nDepre, A.; D’Angelo, L.T.; et al. Medical Textiles with Embedded Fiber Optic Sensors for Monitoring of\\nRespiratory Movement. IEEE Sens. J. 2012, 12, 246–254. [CrossRef]\\n\\n142. Zi˛eba, J.; Frydrysiak, M.; Błaszczyk, J. Textronic clothing with resistance textile sensor to monitoring frequency\\nof human breathing. In Proceedings of the IEEE International Symposium on Medical Measurements and\\nApplications Proceedings, Budapest, Hungary, 18–19 May 2012; pp. 1–6.\\n\\n143. Carlos, R.; Coyle, S.; Corcoran, B.; Diamond, D.; Tomas, W.; Aaron, M.; Stroiescu, F.; Daly, K. Web-based\\nsensor streaming wearable for respiratory monitoring applications. In Proceedings of the 2011 IEEE Sensors,\\nLimerick, UK, 28–31 October 2011; pp. 901–903.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n78 of 84\\n\\n144. Ciobotariu, R.; Rotariu, C.; Adochiei, F.; Costin, H. Wireless breathing system for long term telemonitoring of\\nrespiratory activity. In Proceedings of the 7th International Symposium on Advanced Topics in Electrical\\n(ATEE), Bucharest, Romania, 12–14 May 2011; pp. 1–4.\\n\\n145. Basra, A.; Mukhopadhayay, B.; Kar, S. Temperature sensor based ultra low cost respiration monitoring\\nsystem. In Proceedings of the 9th International Conference on Communication Systems and Networks\\n(COMSNETS), Bengaluru, India, 4–8 January 2017; pp. 530–535.\\n\\n146. Guo, L.; Berglin, L.; Li, Y.J.; Mattila, H.; Mehrjerdi, A.K.; Skrifvars, M. ’Disappearing Sensor’-Textile Based\\nSensor for Monitoring Breathing. In Proceedings of the International Conference on Control, Automation\\nand Systems Engineering (CASE), Singapore, 30–31 July 2011; pp. 1–4.\\n\\n147. Liu, S.; Gao, R.X.; Freedson, P.S. Non-invasive respiration and ventilation prediction using a single abdominal\\nsensor belt. In Proceedings of the 2011 IEEE Signal Processing in Medicine and Biology Symposium (SPMB),\\nNew York, NY, USA, 10 December 2011; pp. 1–5.\\n\\n148. Liu, G.-Z.; Guo, Y.-W.; Zhu, Q.-S.; Huang, B.-Y.; Wang, L. Estimation of respiration rate from three-dimensional\\n\\nacceleration data based on body sensor network. Telemed. E-Health 2011, 17, 705–711. [CrossRef]\\n\\n149. Mann, J.; Rabinovich, R.; Bates, A.; Giavedoni, S.; MacNee, W.; Arvind, D.K. Simultaneous Activity and\\nRespiratory Monitoring Using an Accelerometer. In Proceedings of the 2011 International Conference on\\nBody Sensor Networks, Dallas, TX, USA, 23–25 May 2011; pp. 139–143.\\n\\n150. Ono, T.; Takegawa, H.; Ageishi, T.; Takashina, M.; Numasaki, H.; Matsumoto, M.; Teshima, T. Respiratory\\n\\nmonitoring with an acceleration sensor. Phys. Med. Biol. 2011, 56, 6279–6289. [CrossRef]\\n\\n151. Silva, A.F.; Carmo, J.; Mendes, P.M.; Correia, J.H. Simultaneous cardiac and respiratory frequency\\nmeasurement based on a single ﬁber Bragg grating sensor. Meas. Sci. Technol. Meas. Sci. Technol.\\n2011, 22, 75801. [CrossRef]\\n\\n152. Yang, C.M.; Yang, T.; Wu, C.C.; Chu, N.N.Y. A breathing game with capacitive textile sensors. In Proceedings\\nof the IEEE International Games Innovation Conference (IGIC), Orange, CA, USA, 2–3 November 2011;\\npp. 134–136.\\n\\n153. Yoo, W.J.; Jang, K.W.; Seo, J.K.; Heo, J.Y.; Moon, J.S.; Jun, J.H.; Park, J.-Y.; Lee, B. Development of optical\\nﬁber-based respiration sensor for noninvasive respiratory monitoring. Opt. Rev. 2011, 18, 132–138. [CrossRef]\\n154. Yoo, W.-J.; Jang, K.-W.; Seo, J.-K.; Heo, J.-Y.; Moon, J.-S.; Park, J.-Y.; Lee, B.-S. Development of respiration\\nsensors using plastic optical ﬁber for respiratory monitoring inside MRI system. J. Opt. Soc. Korea 2010, 14,\\n235–239. [CrossRef]\\n\\n155. Yoo, W.; Jang, K.; Seo, J.; Heo, J.Y.; Moon, J.S.; Lee, B.; Park, J.-Y. Development of Nasal-cavity-and\\n\\nAbdomen-attached Fiber-optic Respiration Sensors. J. Korean Phys. Soc. 2010, 57, 1550–1554.\\n\\n156. Bhattacharya, R.; Bandyopadhyay, N.; Kalaivani, S. Real time Android app based respiration rate monitor.\\nIn Proceedings of the International Conference of Electronics, Communication and Aerospace Technology\\n(ICECA), Coimbatore, India, 20–22 April 2017; Volume 1, pp. 709–712.\\n\\n157. Ansari, S.; Belle, A.; Najarian, K.; Ward, K. Impedance plethysmography on the arms: Respiration monitoring.\\nIn Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW),\\nHong Kong, China, 18 December 2010; pp. 471–472.\\n\\n158. De Jonckheere, J.; Jeanne, M.; Narbonneau, F.; Witt, J.; Paquet, B.; Kinet, D.; Kreber, K.; Logier, R. OFSETH: A\\nbreathing motions monitoring system for patients under MRI. In Proceedings of the Annual International\\nConference of the IEEE Engineering in Medicine and Biology, Buenos Aires, Argentina, 31 August–4 September\\n2010; pp. 1016–1019.\\n\\n159. Mitchell, E.; Coyle, S.; O’Connor, N.E.; Diamond, D.; Ward, T. Breathing Feedback System with Wearable\\nTextile Sensors. In Proceedings of the International Conference on Body Sensor Networks, Singapore,\\n7–9 June 2010; pp. 56–61.\\n\\n160. Zhang, Z.; Wu, H.; Wang, W.; Wang, B. A smartphone based respiratory biofeedback system. In Proceedings\\nof the 3rd International Conference on Biomedical Engineering and Informatics, Yantai, China, 16–18 October\\n2010; Volume 2, pp. 717–720.\\n\\n161. Kundu, S.K.; Kumagai, S.; Sasaki, M. A wearable capacitive sensor for monitoring human respiratory rate.\\n\\nJpn. J. Appl. Phys. 2013, 52, 04CL05. [CrossRef]\\n\\n162. Das, T.; Guha, S.; Banerjee, N.; Basak, P. Development of thermistor based low cost high sensitive respiration\\nrate measurement system using audio software with audio input. In Proceedings of the Third International\\nConference on Biosignals, Images and Instrumentation (ICBSII), Chennai, India, 16–18 March 2017; pp. 1–3.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n79 of 84\\n\\n163. Al-Wahedi, A.; Al-Shams, M.; Albettar, M.A.; Alawsh, S.; Muqaibel, A. Wireless Monitoring of Respiration and\\nHeart Rates Using Software-Deﬁned-Radio. In Proceedings of the 2019 16th International Multi-Conference\\non Systems, Signals & Devices (SSD), Istanbul, Turkey, 21–24 March 2019; pp. 529–532.\\n\\n164. Chen, Y.; Kaneko, M.; Hirose, S.; Chen, W. Real-time Respiration Measurement during Sleep Using a\\nMicrowave Sensor. In Proceedings of the 41st Annual International Conference of the IEEE Engineering in\\nMedicine and Biology Society (EMBC), Berlin, Germany, 23–27 July 2019; pp. 3791–3794.\\n\\n165. Gunaratne, P.; Tamura, H.; Yoshida, C.; Sakurai, K.; Tanno, K.; Takahashi, N.; Nagata, J. A Study on Breathing\\nand Heartbeat Monitoring System during Sleeping Using Multi-Piezoelectric Elements. In Proceedings\\nof the 2019 Moratuwa Engineering Research Conference (MERCon), Moratuwa, Sri Lanka, 3–5 June 2019;\\npp. 382–387.\\n\\n166. Guo, S.; Zhao, X.; Matsuo, K.; Liu, J.; Mukai, T. Unconstrained Detection of the Respiratory Motions of Chest\\nand Abdomen in Diﬀerent Lying Positions Using a Flexible Tactile Sensor Array. IEEE Sens. J. 2019, 19,\\n10067–10076. [CrossRef]\\n\\n167. Isono, S.; Nozaki-Taguchi, N.; Hasegawa, M.; Kato, S.; Todoroki, S.; Masuda, S.; Iida, N.; Nishimura, T.;\\nNoto, M.; Sato, Y. Contact-free unconstraint respiratory measurements with load cells under the bed in\\nawake healthy volunteers: Breath-by-breath comparison with pneumotachography. J. Appl. Physiol. 2019,\\n126, 1432–1441. [CrossRef]\\n\\n168. Ivanovs, A.; Nikitenko, A.; Di Castro, M.; Torims, T.; Masi, A.; Ferre, M. Multisensor low-cost system for real\\ntime human detection and remote respiration monitoring. In Proceedings of the Third IEEE 7International\\nConference on Robotic Computing (IRC), Naples, Italy, 25–27 February 2019; pp. 254–257.\\n\\n169. Joshi, R.; Bierling, B.; Feijs, L.; van Pul, C.; Andriessen, P. Monitoring the respiratory rate of preterm infants\\nusing an ultrathin ﬁlm sensor embedded in the bedding: A comparative feasibility study. Physiol. Meas.\\n2019, 40, 45003. [CrossRef]\\n\\n170. Krej, M.; Baran, P.; Dziuda, Ł. Detection of respiratory rate using a classiﬁer of waves in the signal from a\\n\\nFBG-based vital signs sensor. Comput. Methods Programs Biomed. 2019, 177, 31–38. [CrossRef]\\n\\n171. Lorato, I.; Bakkes, T.; Stuijk, S.; Meftah, M.; De Haan, G. Unobtrusive respiratory ﬂow monitoring using a\\n\\nthermopile array: A feasibility study. Appl. Sci. 2019, 9, 2449. [CrossRef]\\n\\n172. Massaroni, C.; Lo Presti, D.; Formica, D.; Silvestri, S.; Schena, E. Non-contact monitoring of breathing pattern\\n\\nand respiratory rate via RGB signal measurement. Sensors 2019, 19, 2758. [CrossRef]\\n\\n173. Park, S.; Choi, H.; Yang, H.C.; Yoon, J.; Shin, H. Force-Sensing-Based Unobtrusive System for Awakening\\n\\nand Respiration Rate Analysis during Sleep. IEEE Sens. J. 2019, 19, 1917–1924. [CrossRef]\\n\\n174. Walterscheid, I.; Biallawons, O.; Berens, P. Contactless Respiration and Heartbeat Monitoring of Multiple\\nPeople Using a 2-D Imaging Radar. In Proceedings of the 2019 41st Annual International Conference of the\\nIEEE Engineering in Medicine and Biology Society (EMBC), Berlin, Germany, 23–27 July 2019; pp. 3720–3725.\\n175. Wang, T.; Zhang, D.; Wang, L.; Zheng, Y.; Gu, T.; Dorizzi, B.; Zhou, X. Contactless respiration monitoring\\nusing ultrasound signal with oﬀ-the-shelf audio devices. IEEE Internet Things J. 2018, 6, 2959–2973. [CrossRef]\\n176. Xu, X.; Yu, J.; Chen, Y.; Zhu, Y.; Kong, L.; Li, M. BreathListener: Fine-grained Breathing Monitoring in Driving\\nEnvironments Utilizing Acoustic Signals. In Proceedings of the 17th Annual International Conference on\\nMobile Systems, Applications, and Services, Breckenridge, CO, USA, 17–20 June 2019; pp. 54–66.\\n\\n177. Yang, Y.; Cao, J.; Liu, X.; Liu, X. Multi-Breath: Separate Respiration Monitoring for Multiple Persons with\\nUWB Radar. In Proceedings of the IEEE 43rd Annual Computer Software and Applications Conference\\n(COMPSAC), Milwaukee, WI, USA, 15–19 July 2019; Volume 1, pp. 840–849.\\n\\n178. Chen, C.; Han, Y.; Chen, Y.; Lai, H.; Zhang, F.; Wang, B.; Liu, K.J.R. TR-BREATH: Time-Reversal Breathing\\n\\nRate Estimation and Detection. IEEE Trans. Biomed. Eng. 2018, 65, 489–501. [CrossRef] [PubMed]\\n\\n179. Chen, S.; Wu, N.; Ma, L.; Lin, S.; Yuan, F.; Xu, Z.; Li, W.; Wang, B.; Zhou, J. Noncontact heartbeat and respiration\\nmonitoring based on a hollow microstructured self-powered pressure sensor. ACS Appl. Mater. Interfaces\\n2018, 10, 3660–3667. [CrossRef] [PubMed]\\n\\n180. Massaroni, C.; Schena, E.; Silvestri, S.; Taﬀoni, F.; Merone, M. Measurement system based on RBG camera\\nsignal for contactless breathing pattern and respiratory rate monitoring.\\nIn Proceedings of the IEEE\\nInternational Symposium on Medical Measurements and Applications (MeMeA), Rome, Italy, 11–13 June\\n2018; pp. 1–6.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n80 of 84\\n\\n181. Massaroni, C.; Lo Presti, D.; Saccomandi, P.; Caponero, M.A.; D’Amato, R.; Schena, E. Fiber Bragg Grating\\nProbe for Relative Humidity and Respiratory Frequency Estimation: Assessment During Mechanical\\nVentilation. IEEE Sens. J. 2018, 18, 2125–2130. [CrossRef]\\n\\n182. Sadek, I.; Seet, E.; Biswas, J.; Abdulrazak, B.; Mokhtari, M. Nonintrusive Vital Signs Monitoring for Sleep\\n\\nApnea Patients: A Preliminary Study. IEEE Access 2018, 6, 2506–2514. [CrossRef]\\n\\n183. Azimi, H.; Soleimani Gilakjani, S.; Bouchard, M.; Bennett, S.; Goubran, R.A.; Knoefel, F. Breathing signal\\ncombining for respiration rate estimation in smart beds. In Proceedings of the IEEE International Symposium\\non Medical Measurements and Applications (MeMeA), Rochester, MN, USA, 7–10 May 2017; pp. 303–307.\\n184. Cho, Y.; Bianchi-Berthouze, N.; Julier, S.J.; Marquardt, N. ThermSense: Smartphone-based breathing sensing\\nplatform using noncontact low-cost thermal camera. In Proceedings of the 2017 7th International Conference\\non Aﬀective Computing and Intelligent Interaction Workshops and Demos (ACIIW), San Antonio, TX, USA,\\n23–26 October 2017; pp. 83–84.\\n\\n185. Leicht, L.; Vetter, P.; Leonhardt, S.; Teichmann, D. The PhysioBelt: A safety belt integrated sensor system\\nfor heart activity and respiration. In Proceedings of the 2017 IEEE International Conference on Vehicular\\nElectronics and Safety (ICVES), Vienna, Austria, 27–28 June 2017; pp. 191–195.\\n\\n186. Li, K.; Xu, W.; Zhan, N.; Wan, K.; Yu, C.; Yu, C. Non-wearable respiration monitoring based on Mach-Zehnder\\ninterferometer. In Proceedings of the Conference on Lasers and Electro-Optics Paciﬁc Rim (CLEO-PR),\\nSingapore, 31 July–4 August 2017; pp. 1–2.\\n\\n187. Li, M.H.; Yadollahi, A.; Taati, B. Noncontact Vision-Based Cardiopulmonary Monitoring in Diﬀerent Sleeping\\n\\nPositions. IEEE J. Biomed. Health Inform. 2017, 21, 1367–1375. [CrossRef]\\n\\n188. Procházka, A.; Charvátová, H.; Vyšata, O.; Kopal, J.; Chambers, J. Breathing Analysis Using Thermal and\\n\\nDepth Imaging Camera Video Records. Sensors 2017, 17, 1408. [CrossRef] [PubMed]\\n\\n189. Wang, X.; Huang, R.; Mao, S. SonarBeat: Sonar Phase for Breathing Beat Monitoring with Smartphones.\\nIn Proceedings of the 26th International Conference on Computer Communication and Networks (ICCCN),\\nVancouver, BC, Canada, 31 July–3 August 2017; pp. 1–8.\\n\\n190. Kukkapalli, R.; Banerjee, N.; Robucci, R.; Kostov, Y. Micro-radar wearable respiration monitor. In Proceedings\\n\\nof the 2016 IEEE Sensors, Orlando, FL, USA, 30 October–3 November 2016; pp. 1–3.\\n\\n191. Procházka, A.; Schätz, M.; Vyšata, O.; Vališ, M. Microsoft Kinect Visual and Depth Sensors for Breathing and\\n\\nHeart Rate Analysis. Sensors 2016, 16, 996. [CrossRef]\\n\\n192. Tveit, D.M.; Engan, K.; Austvoll, I.; Meinich-Bache, Ø. Motion based detection of respiration rate in infants\\nusing video. In Proceedings of the IEEE International Conference on Image Processing (ICIP), Phoenix, AZ,\\nUSA, 25–28 September 2016; pp. 1225–1229.\\n\\n193. Erden, F.; Alkar, A.Z.; Cetin, A.E. Contact-free measurement of respiratory rate using infrared and vibration\\n\\nsensors. Infrared Phys. Technol. 2015, 73, 88–94. [CrossRef]\\n\\n194. Liu, J.J.; Huang, M.; Xu, W.; Zhang, X.; Stevens, L.; Alshurafa, N.; Sarrafzadeh, M. BreathSens: A Continuous\\nOn-Bed Respiratory Monitoring System With Torso Localization Using an Unobtrusive Pressure Sensing\\nArray. IEEE J. Biomed. Health Inform. 2015, 19, 1682–1688. [CrossRef]\\n\\n195. Pereira, C.B.; Yu, X.; Blazek, V.; Leonhardt, S. Robust remote monitoring of breathing function by using\\ninfrared thermography. In Proceedings of the 37th Annual International Conference of the IEEE Engineering\\nin Medicine and Biology Society (EMBC), Milan, Italy, 25–29 August 2015; pp. 4250–4253.\\n\\n196. Ravichandran, R.; Saba, E.; Chen, K.-Y.; Goel, M.; Gupta, S.; Patel, S.N. WiBreathe: Estimating respiration rate\\nusing wireless signals in natural settings in the home. In Proceedings of the IEEE International Conference on\\nPervasive Computing and Communications (PerCom), St. Louis, MO, USA, 23–27 March 2015; pp. 131–139.\\n197. Sasaki, E.; Kajiwara, A. Multiple Respiration Monitoring by Stepped-FM UWB Sensor. In Proceedings of the\\n2015 IEEE International Conference on Computational Intelligence Communication Technology, Ghaziabad,\\nIndia, 13–14 February 2015; pp. 406–409.\\n\\n198. Zakrzewski, M.; Vehkaoja, A.; Joutsen, A.S.; Palovuori, K.T.; Vanhala, J.J. Noncontact Respiration Monitoring\\n\\nDuring Sleep with Microwave Doppler Radar. IEEE Sens. J. 2015, 15, 5683–5693. [CrossRef]\\n\\n199. Arlotto, P.; Grimaldi, M.; Naeck, R.; Ginoux, J.-M. An ultrasonic contactless sensor for breathing monitoring.\\n\\nSensors 2014, 14, 15371–15386. [CrossRef] [PubMed]\\n\\n200. Bernacchia, N.; Scalise, L.; Casacanditella, L.; Ercoli, I.; Marchionni, P.; Tomasini, E.P. Non contact measurement\\nof heart and respiration rates based on KinectTM. In Proceedings of the 2014 IEEE International Symposium\\non Medical Measurements and Applications (MeMeA), Lisboa, Portugal, 11–12 June 2014; pp. 1–5.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n81 of 84\\n\\n201. Chen, Z.; Lau, D.; Teo, J.T.; Ng, S.H.; Yang, X.; Kei, P.L. Simultaneous measurement of breathing rate and heart\\n\\nrate using a microbend multimode ﬁber optic sensor. J. Biomed. Opt. 2014, 19, 1–11. [CrossRef] [PubMed]\\n\\n202. Luis, J.; Roa Romero, L.M.; Galan, J.A.; Naranjo, D.; Estudillo-Valderrama, M.; Barbarov-Rostán, G.;\\nRubia-Marcos, C. Design and Implementation of a Smart Sensor for Respiratory Rate Monitoring. Sensors\\n2014, 14, 3019–3032. [CrossRef] [PubMed]\\n\\n203. Mukai, T.; Matsuo, K.; Kato, Y.; Shimizu, A.; Guo, S. Determination of locations on a tactile sensor suitable for\\nrespiration and heartbeat measurement of a person on a bed. In Proceedings of the 36th Annual International\\nConference of the IEEE Engineering in Medicine and Biology Society, Chicago, IL, USA, 26–30 August 2014;\\npp. 66–69.\\n\\n204. Nukaya, S.; Sugie, M.; Kurihara, Y.; Hiroyasu, T.; Watanabe, K.; Tanaka, H. A noninvasive heartbeat,\\nrespiration, and body movement monitoring system for neonates. Artif. Life Robot. 2014, 19, 414–419.\\n[CrossRef]\\n\\n205. Patwari, N.; Brewer, L.; Tate, Q.; Kaltiokallio, O.; Bocca, M. Breathﬁnding: A Wireless Network That Monitors\\n\\nand Locates Breathing in a Home. IEEE J. Sel. Top. Signal Process. 2014, 8, 30–42. [CrossRef]\\n\\n206. Patwari, N.; Wilson, J.; Ananthanarayanan, S.; Kasera, S.K.; Westenskow, D.R. Monitoring Breathing via\\n\\nSignal Strength in Wireless Networks. IEEE Trans. Mob. Comput. 2014, 13, 1774–1786. [CrossRef]\\n\\n207. Taheri, T.; Sant’Anna, A. Non-invasive breathing rate detection using a very low power ultra-wide-band\\nradar. In Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM),\\nBelfast, UK, 2–5 November 2014; pp. 78–83.\\n\\n208. Bartula, M.; Tigges, T.; Muehlsteﬀ, J. Camera-based system for contactless monitoring of respiration.\\nIn Proceedings of the 35th Annual International Conference of the IEEE Engineering in Medicine and Biology\\nSociety (EMBC), Osaka, Japan, 3–7 July 2013; pp. 2672–2675.\\n\\n209. Chen, R.; Formenti, F.; Obeid, A.; Hahn, C.E.W.; Farmery, A. A ﬁbre-optic oxygen sensor for monitoring\\n\\nhuman breathing. Physiol. Meas. 2013, 34, N71–N81. [CrossRef]\\n\\n210. Dziuda, Ł.; Krej, M.; Skibniewski, F.W. Fiber Bragg Grating Strain Sensor Incorporated to Monitor Patient\\n\\nVital Signs during MRI. IEEE Sens. J. 2013, 13, 4986–4991. [CrossRef]\\n\\n211. Klap, T.; Shinar, Z. Using piezoelectric sensor for continuous-contact-free monitoring of heart and respiration\\nrates in real-life hospital settings. In Proceedings of the Computing in Cardiology, Zaragoza, Spain, 22–25\\nSeptember 2013; pp. 671–674.\\n\\n212. Šprager, S.; Zazula, D. Detection of heartbeat and respiration from optical interferometric signal by using\\n\\nwavelet transform. Comput. Methods Programs Biomed. 2013, 111, 41–51. [CrossRef]\\n\\n213. Vinci, G.; Lindner, S.; Barbon, F.; Mann, S.; Hofmann, M.; Duda, A.; Weigel, R.; Koelpin, A. Six-port radar\\nsensor for remote respiration rate and heartbeat vital-sign monitoring. IEEE Trans. Microw. Theory Tech. 2013,\\n61, 2093–2100. [CrossRef]\\n\\n214. Yavari, E.; Jou, H.; Lubecke, V.; Boric-Lubecke, O. Doppler radar sensor for occupancy monitoring.\\nIn Proceedings of the IEEE Topical Conference on Power Ampliﬁers for Wireless and Radio Applications,\\nSanta Clara, CA, USA, 20 January 2013; pp. 145–147.\\n\\n215. Aoki, H.; Miyazaki, M.; Nakamura, H.; Furukawa, R.; Sagawa, R.; Kawasaki, H. Non-contact respiration\\nmeasurement using structured light 3-D sensor. In Proceedings of the SICE Annual Conference (SICE), Akita,\\nJapan, 20–23 August 2012; pp. 614–618.\\n\\n216. Boccanfuso, L.; O’Kane, J.M. Remote measurement of breathing rate in real time using a high precision,\\nsingle-point infrared temperature sensor. In Proceedings of the 4th IEEE RAS EMBS International Conference\\non Biomedical Robotics and Biomechatronics (BioRob), Rome, Italy, 24–27 June 2012; pp. 1704–1709.\\n217. Brüser, C.; Kerekes, A.; Winter, S.; Leonhardt, S. Multi-channel optical sensor-array for measuring\\nballistocardiograms and respiratory activity in bed. In Proceedings of the Annual International Conference\\nof the IEEE Engineering in Medicine and Biology Society, San Diego, CA, USA, 28 August–1 September 2012;\\npp. 5042–5045.\\n\\n218. Chen, Z.; Teo, J.T.; Ng, S.H.; Yang, X. Plastic optical ﬁber microbend sensor used as breathing sensor.\\n\\nIn Proceedings of the 2012 IEEE Sensors, Taipei, Taiwan, 28–31 October 2012; pp. 1–4.\\n\\n219. Gu, C.; Li, R.; Zhang, H.; Fung, A.Y.C.; Torres, C.; Jiang, S.B.; Li, C. Accurate respiration measurement\\nusing DC-coupled continuous-wave radar sensor for motion-adaptive cancer radiotherapy. IEEE Trans.\\nBiomed. Eng. 2012, 59, 3117–3123. [PubMed]\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n82 of 84\\n\\n220. Lokavee, S.; Puntheeranurak, T.; Kerdcharoen, T.; Watthanwisuth, N.; Tuantranont, A. Sensor pillow and\\nbed sheet system: Unconstrained monitoring of respiration rate and posture movements during sleep.\\nIn Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC), Seoul, Korea,\\n14–17 October 2012; pp. 1564–1568.\\n\\n221. Shimomura, N.; Otsu, M.; Kajiwara, A. Empirical study of remote respiration monitoring sensor\\nusing wideband system. In Proceedings of the 6th International Conference on Signal Processing and\\nCommunication Systems, Gold Coast, Australia, 12–14 December 2012; pp. 1–5.\\n\\n222. Xia, J.; Siochi, R.A. A real-time respiratory motion monitoring system using KINECT: Proof of concept.\\n\\nMed. Phys. 2013, 39, 2682–2685. [CrossRef] [PubMed]\\n\\n223. Lai, J.C.Y.; Xu, Y.; Gunawan, E.; Chua, E.C.; Maskooki, A.; Guan, Y.L.; Low, K.; Soh, C.B.; Poh, C. Wireless\\nSensing of Human Respiratory Parameters by Low-Power Ultrawideband Impulse Radio Radar. IEEE Trans.\\nInstrum. Meas. 2011, 60, 928–938. [CrossRef]\\n\\n224. Otsu, M.; Nakamura, R.; Kajiwara, A. Remote respiration monitoring sensor using stepped-FM. In Proceedings\\n\\nof the IEEE Sensors Applications Symposium, San Antonio, TX, USA, 22–24 February 2011; pp. 155–158.\\n\\n225. Postolache, O.; Girão, P.S.; Postolache, G.; Gabriel, J. Cardio-respiratory and daily activity monitor based on\\nFMCW Doppler radar embedded in a wheelchair. In Proceedings of the Annual International Conference of\\nthe IEEE Engineering in Medicine and Biology Society, Boston, MA, USA, 30 August–3 September 2011;\\npp. 1917–1920.\\n\\n226. Zito, D.; Pepe, D.; Mincica, M.; Zito, F.; Tognetti, A.; Lanata, A.; De Rossi, D. SoC CMOS UWB pulse radar\\nsensor for contactless respiratory rate monitoring. IEEE Trans. Biomed. Circuits Syst. 2011, 5, 503–510.\\n[CrossRef]\\n\\n227. Heise, D.; Skubic, M. Monitoring pulse and respiration with a non-invasive hydraulic bed sensor.\\nIn Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology,\\nBuenos Aires, Argentina, 31 August–4 September 2010; pp. 2119–2123.\\n\\n228. Min, S.D.; Kim, J.K.; Shin, H.S.; Yun, Y.H.; Lee, C.K.; Lee, M. Noncontact Respiration Rate Measurement\\n\\nSystem Using an Ultrasonic Proximity Sensor. IEEE Sens. J. 2010, 10, 1732–1739. [CrossRef]\\n\\n229. Mostov, K.; Liptsen, E.; Boutchko, R. Medical applications of shortwave FM radar: Remote monitoring of\\n\\ncardiac and respiratory motion. Med. Phys. 2010, 37, 1332–1338. [CrossRef]\\n\\n230. Nishiyama, M.; Miyamoto, M.; Watanabe, K. Respiration rhythm monitoring in sleep based on weight\\nmovement using hetero-core ﬁber optic sensors. In Proceedings of the ICCAS 2010, Gyeonggi-do, Korea,\\n27–30 October 2010; pp. 205–208.\\n\\n231. Nishyama, M.; Miyamoto, M.; Watanabe, K. Respiration and body movement analysis during sleep in bed\\nusing hetero-core ﬁber optic pressure sensors without constraint to human activity. J. Biomed. Opt. 2011,\\n16, 17002. [CrossRef]\\n\\n232. Scalise, L.; Marchionni, P.; Ercoli, I. Optical method for measurement of respiration rate. In Proceedings\\nof the IEEE International Workshop on Medical Measurements and Applications, Ottawa, ON, Canada,\\n30 April–1 May 2010; pp. 19–22.\\n\\n233. Silvious, J.; Tahmoush, D. UHF measurement of breathing and heartbeat at a distance. In Proceedings of the\\nIEEE Radio and Wireless Symposium (RWS), New Orleans, LA, USA, 10–14 January 2010; pp. 567–570.\\n234. Tan, K.S.; Saatchi, R.; Elphick, H.; Burke, D. Real-time vision based respiration monitoring system.\\nIn Proceedings of the 7th International Symposium on Communication Systems, Networks Digital Signal\\nProcessing (CSNDSP 2010), Newcastle upon Tyne, UK, 21–23 July 2010; pp. 770–774.\\n\\n235. Brady, S.; Dunne, L.E.; Tynan, R.; Diamond, D.; Smyth, B.; O’Hare, G.M.P. Garment-based monitoring of\\nrespiration rate using a foam pressure sensor. In Proceedings of the Ninth IEEE International Symposium on\\nWearable Computers (ISWC’05), Osaka, Japan, 18–21 October 2005; pp. 214–215.\\n\\n236. Dziuda, L.; Skibniewski, F.; Rozanowski, K.; Krej, M.; Lewandowski, J. Fiber-optic sensor for monitoring\\nrespiration and cardiac activity. In Proceedings of the 2011 IEEE Sensors, Limerick, UK, 28–31 October 2011;\\npp. 413–416.\\n\\n237. Gutierrez Pascual, M.D. Indoor Location Systems Based on Zigbee Networks. Bachelor’s Thesis, Faculty of\\n\\nComputing, Karlskrona, Sweden, 2012.\\n\\n238. Wei, Y.-H.; Leng, Q.; Han, S.; Mok, A.K.; Zhang, W.; Tomizuka, M. RT-WiFi: Real-time high-speed\\ncommunication protocol for wireless cyber-physical control applications. In Proceedings of the IEEE 34th\\nReal-Time Systems Symposium, Vancouver, BC, Canada, 3–6 December 2013; pp. 140–149.\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n83 of 84\\n\\n239. Bettstetter, C.; Vogel, H.-J.; Eberspacher, J. GSM phase 2+ general packet radio service GPRS: Architecture,\\n\\nprotocols, and air interface. IEEE Commun. Surv. 1999, 2, 2–14. [CrossRef]\\n\\n240. Delnavaz, A.; Voix, J. Electromagnetic micro-power generator for energy harvesting from breathing.\\nIn Proceedings of the IECON 38th Annual Conference on IEEE Industrial Electronics Society, Montreal, QC,\\nCanada, 25–28 October 2012; pp. 984–988.\\n\\n241. Goreke, U.; Habibiabad, S.; Azgin, K.; Beyaz, M.I. A MEMS turbine prototype for respiration harvesting.\\n\\nProc. J. Phys. Conf. Ser. 2015, 660, 12059. [CrossRef]\\n\\n242. Shahhaidar, E.; Padasdao, B.; Romine, R.; Stickley, C.; Boric-Lubecke, O. Piezoelectric and electromagnetic\\nrespiratory eﬀort energy harvesters. In Proceedings of the 35th Annual International Conference of the IEEE\\nEngineering in Medicine and Biology Society (EMBC), Osaka, Japan, 3–7 July 2013; pp. 3439–3442.\\n\\n243. Li, K.; He, Q.; Wang, J.; Zhou, Z.; Li, X. Wearable energy harvesters generating electricity from low-frequency\\n\\nhuman limb movement. Microsyst. Nanoeng. 2018, 4, 1–13. [CrossRef]\\n\\n244. Wang, J.-J.; Su, H.-J.; Hsu, C.-I.; Su, Y.-C. Composite piezoelectric rubber band for energy harvesting from\\n\\nbreathing and limb motion. Proc. J. Phys. Conf. Ser. 2014, 557, 12022. [CrossRef]\\n\\n245. Sun, C.; Shi, J.; Bayerl, D.J.; Wang, X. PVDF microbelts for harvesting energy from respiration. Energy Environ. Sci.\\n\\n2011, 4, 4508–4512. [CrossRef]\\n\\n246. Zhang, Z.; Zhang, J.; Zhang, H.; Wang, H.; Hu, Z.; Xuan, W.; Dong, S.; Luo, J. A Portable Triboelectric\\nNanogenerator for Real-Time Respiration Monitoring. Nanoscale Res. Lett. 2019, 14, 354. [CrossRef] [PubMed]\\nJia, W.; Sun, M. Triboelectric nanogenerator using\\nmicrodome-patterned PDMS as a wearable respiratory energy harvester. Adv. Mater. Technol. 2017,\\n2, 1700014. [CrossRef]\\n\\n247. Vasandani, P.; Gattu, B.; Wu, J.; Mao, Z.-H.;\\n\\n248. Seo, M.-H.; Choi, D.-H.; Han, C.-H.; Yoo, J.-Y.; Yoon, J.-B. An electrostatic energy harvester exploiting\\nvariable-area water electrode by respiration. In Proceedings of the 28th IEEE International Conference on\\nMicro Electro Mechanical Systems (MEMS), Estoril, Portugal, 18–22 January 2015; pp. 126–129.\\n\\n249. Xue, H.; Yang, Q.; Wang, D.; Luo, W.; Wang, W.; Lin, M.; Liang, D.; Luo, Q. A wearable pyroelectric\\n\\nnanogenerator and self-powered breathing sensor. Nano Energy 2017, 38, 147–154. [CrossRef]\\n\\n250. Fan, F.-R.; Tian, Z.-Q.; Wang, Z.L. Flexible triboelectric generator. Nano Energy 2012, 1, 328–334. [CrossRef]\\n251. Aljadiri, R.T.; Taha, L.Y.; Ivey, P. Electrostatic energy harvesting systems: A better understanding of their\\n\\nsustainability. J. Clean Energy Technol. 2017, 5, 409–416. [CrossRef]\\n\\n252. Nozariasbmarz, A.; Collins, H.; Dsouza, K.; Polash, M.H.; Hosseini, M.; Hyland, M.; Liu, J.; Malhotra, A.;\\nOrtiz, F.M.; Mohaddes, F.; et al. Review of wearable thermoelectric energy harvesting: From body temperature\\nto electronic systems. Appl. Energy 2020, 258, 114069. [CrossRef]\\n\\n253. Enescu, D. Thermoelectric Energy Harvesting: Basic Principles and Applications. In Green Energy Advances;\\n\\nIntechOpen: London, UK, 2019.\\n\\n254. Vanegas, E.; Igual, R.; Plaza, I. Piezoresistive Breathing Sensing System with 3D Printed Wearable Casing.\\n\\nJ. Sens. 2019, 2019. [CrossRef]\\n\\n255. Doerﬀel, D.; Sharkh, S.A. A critical review of using the Peukert equation for determining the remaining\\n\\ncapacity of lead-acid and lithium-ion batteries. J. Power Sources 2006, 155, 395–400. [CrossRef]\\n\\n256. Kirchev, A. Battery management and battery diagnostics. In Electrochemical Energy Storage for Renewable\\n\\nSources and Grid Balancing; Elsevier: Amsterdam, The Netherlands, 2015; pp. 411–435.\\n\\n257. Lee, S.; Kim, J.; Lee, J.; Cho, B.H. State-of-charge and capacity estimation of lithium-ion battery using a new\\n\\nopen-circuit voltage versus state-of-charge. J. Power Sources 2008, 185, 1367–1373. [CrossRef]\\n\\n258. Association, W.M. World Medical Association Declaration of Helsinki. Ethical principles for medical research\\n\\ninvolving human subjects. Bull. World Health Organ. 2001, 79, 373–374.\\n\\n259. Zhu, W.; Zeng, N.; Wang, N. Sensitivity, Speciﬁcity, Accuracy, Associated Conﬁdence Interval and ROC\\n\\nAnalysis with Practical SAS ®Implementations. Health Care Life Sci. 2010, 19, 67.\\n\\n260. The R Foundation. The R Project for Statistical Computing. Available online: https://www.r-project.org/\\n\\n(accessed on 20 March 2020).\\n\\n261. Microsoft C#. Available online: https://docs.microsoft.com/es-es/dotnet/csharp/ (accessed on 3 August 2020).\\n262. Team, O. OpenCV. Available online: https://opencv.org/about/ (accessed on 20 March 2020).\\n263. Microsoft Kinect for Windows. Available online: https://www.microsoft.com/en-us/download/details.aspx?\\n\\nid=40278 (accessed on 20 March 2020).\\n\\n\\x0cSensors 2020, 20, 5446\\n\\n84 of 84\\n\\n264. ADINSTRUMENTS. LabChart Lightning. Available online: https://www.adinstruments.com/products/\\n\\nlabchart (accessed on 20 March 2020).\\n\\n265. Biopac Systems Inc. Acqknowledge Software. Available online: https://www.biopac.com/product/\\n\\nacqknowledge-software/ (accessed on 20 March 2020).\\n\\n266. National Instruments LabWindows/CVI. 2020. Available online: http://sine.ni.com/nips/cds/view/p/lang/es/\\n\\nnid/11104 (accessed on 18 September 2020).\\n\\n267. MathWorks Peak Analysis. Available online: https://es.mathworks.com/help/signal/examples/peak-analysis.\\n\\nhtml (accessed on 1 July 2020).\\n\\n268. Mallat, S. A Wavelet Tour of Signal Processing; Academic Press: Boston, MA, USA, 2009; ISBN 978-0-12-374370-1.\\n269. Jawerth, B.; Sweldens, W. An overview of wavelet based multiresolution analyses. SIAM Rev. 1994, 36,\\n\\n377–412. [CrossRef]\\n\\n270. Welch, G.; Bishop, G. An Introduction to the Kalman Filter; Citeseer: University Park, PA, USA, 1995.\\n271. Chen, A.T.-Y.; Biglari-Abhari, M.; Wang, K.I.-K. Trusting the Computer in Computer Vision: A Privacy-Affirming\\nFramework. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\\nWorkshops, Honolulu, HI, USA, 21–26 July 2017.\\n\\n272. Venkatesh, V.; Morris, M.G.; Davis, G.B.; Davis, F.D. User Acceptance of Information Technology: Toward a\\n\\nUniﬁed View. MIS Q. 2003, 27, 425–478. [CrossRef]\\n\\n273. Sundaravej, T. Empirical Validation of Uniﬁed Theory of Acceptance and Use of Technology Model. J. Glob.\\n\\nInf. Technol. Manag. 2010, 13, 5–27.\\n\\n274. Moon, Y.-J.; Hwang, Y.-H.; Cho, S. An Empirical Study of Impacts of User Intention for Smart Wearable\\n\\nDevices and Use Behavior. Adv. Multimed. Ubiquitous Eng. 2016, 354, 357–365. [CrossRef]\\n\\n275. Wolbring, G.; Leopatra, V. Sensors: Views of Staﬀ of a Disability Service Organization. J. Pers. Med. 2013, 3,\\n\\n23–39. [CrossRef]\\n\\n276. Gao, Y.; Li, H.; Luo, Y. An empirical study of wearable technology acceptance in healthcare. Ind. Manag.\\n\\nData Syst. 2015, 115, 1704–1723. [CrossRef]\\n\\n277. Alam, M.Z.; Hu, W.; Barua, Z. Using the UTAT model to determine factors aﬀecting acceptance and use of\\n\\nmobile health (mHealth) services in Bangladesh. J. Stud. Soc. Sci. 2018, 3, 137–172.\\n\\n278. Lo Presti, D.; Romano, C.; Massaroni, C.; Abbraccio, J.D.; Massari, L.; Caponero, M.A.; Oddo, C.M.;\\nFormica, D.; Schena, E. Cardio-Respiratory Monitoring in Archery Using a Smart Textile Based on Flexible\\nFiber Bragg Grating Sensors. Sensors 2019, 19, 3581. [CrossRef] [PubMed]\\n\\n279. Igual, R.; Medrano, C.; Plaza, I.; Orrite, C. Adaptive tracking algorithms to improve the use of computing\\n\\nresources. IET Comput. Vis. 2013, 7, 415–424. [CrossRef]\\n\\n280. Kim, J.D.; Lee, W.H.; Lee, Y.; Lee, H.J.; Cha, T.; Kim, S.H.; Song, K.-M.; Lim, Y.-H.; Cho, S.H.; Cho, S.H.; et al.\\nNon-contact respiration monitoring using impulse radio ultrawideband radar in neonates. R. Soc. Open Sci.\\n2019, 6, 190149. [CrossRef] [PubMed]\\n\\n281. Giavarina, D. Understanding Bland Altman analysis. Biochem. Med. 2015, 141–151. [CrossRef]\\n282. Barré, A.; Deguilhem, B.; Grolleau, S.; Gérard, M.; Suard, F.; Riu, D. A review on lithium-ion battery ageing\\n\\nmechanisms and estimations for automotive applications. J. Power Sources 2013, 241, 680–689. [CrossRef]\\n\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\\n\\n\\x0c\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('all_papers.txt', 'a+') as f:\n",
    "    f.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
